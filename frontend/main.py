from fastapi import FastAPI, UploadFile, Request, Form, Body, Path, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import os
import shutil
import subprocess
import pandas as pd
import csv
import sys
import json
from typing import List, Dict, Any, Optional
import io
import math
import re
import numpy as np
import logging
from datetime import datetime
import config # <--- –î–û–ë–ê–í–ò–¢–¨, –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
from pydantic import BaseModel # <--- –î–û–ë–ê–í–õ–ï–ù –ò–ú–ü–û–†–¢
# --- –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ Excel ---
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, PatternFill, Border, Side # <<< –î–û–ë–ê–í–õ–ï–ù–´ Border, Side
# --- –ö–æ–Ω–µ—Ü –∏–º–ø–æ—Ä—Ç–æ–≤ –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ ---
# --- –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è XLSX ---
import zipfile
import tempfile

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ñ–∞–π–ª–∞ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
from geocoder import geocode_address
# --- –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π --- 
import route_distance 
# --- –î–û–ë–ê–í–õ–ï–ù –ò–ú–ü–û–†–¢ get_api_key --- 
from utils import ensure_data_dirs, get_api_key 
# --- –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø ---

app = FastAPI()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.abspath(os.path.join(BASE_DIR, ".."))
UPLOAD_FOLDER = os.path.join(BASE_DIR, "uploaded")
DATA_FOLDER = os.path.join(BASE_DIR, "data")
PROJECT_DATA_FOLDER = os.path.join(ROOT_DIR, "data")
GEOCODED_RESULTS_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "geocoded_results")
ROUTE_RESULTS_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "route_results")
PARSED_ADDRESSES_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "parsed_addresses")
SUMMARY_CSV_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "summary_csv")

# –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(DATA_FOLDER, exist_ok=True)
os.makedirs(GEOCODED_RESULTS_FOLDER, exist_ok=True)
os.makedirs(ROUTE_RESULTS_FOLDER, exist_ok=True)
os.makedirs(PARSED_ADDRESSES_FOLDER, exist_ok=True)
os.makedirs(SUMMARY_CSV_FOLDER, exist_ok=True)

app.mount("/static", StaticFiles(directory=os.path.join(BASE_DIR, "static")), name="static")
templates = Jinja2Templates(directory=os.path.join(BASE_DIR, "templates"))

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
def sanitize_filename(filename):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
    if not isinstance(filename, str):
        return "unnamed"
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    s = filename.strip().replace(' ', '_')
    return s if s else "unnamed"

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π
def sanitize_data_for_json(data):
    if isinstance(data, dict):
        return {k: sanitize_data_for_json(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [sanitize_data_for_json(item) for item in data]
    elif isinstance(data, float):
        if math.isnan(data) or math.isinf(data):
            return None # –ó–∞–º–µ–Ω—è–µ–º NaN/inf –Ω–∞ None
        return data
    else:
        return data

# --- –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞ sharedStrings.xml (–∏–∑ test_excel_read.py) ---
def fix_xlsx_casing(original_path):
    """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é XLSX, –µ—Å–ª–∏ sharedStrings.xml –∏–º–µ–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –∫–æ–ø–∏–∏ –∏–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å. None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    expected = 'xl/sharedStrings.xml'
    incorrect_candidate = 'xl/SharedStrings.xml'
    fixed_path = original_path
    
    try:
        with zipfile.ZipFile(original_path, 'r') as zin:
            archive_files = zin.namelist()
            if expected in archive_files:
                return original_path # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ –Ω—É–∂–Ω–æ
            
            if incorrect_candidate not in archive_files:
                 # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å, —Ç.–∫. –ø—Ä–æ–±–ª–µ–º–∞ –Ω–µ –≤ —Ä–µ–≥–∏—Å—Ç—Ä–µ –∏–ª–∏ —Ñ–∞–π–ª –Ω–µ xlsx
                 return original_path 
            
            # --- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è ---
            print(f"INFO: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞ {incorrect_candidate}...")
            temp_fd, fixed_path = tempfile.mkstemp(suffix='.xlsx')
            os.close(temp_fd) # –ó–∞–∫—Ä—ã–≤–∞–µ–º –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä, –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –ø—É—Ç—å

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–π with –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –∑–∞–∫—Ä—ã—Ç–∏—è
            with zipfile.ZipFile(fixed_path, 'w', zipfile.ZIP_DEFLATED) as zout, \
                 zipfile.ZipFile(original_path, 'r') as zin_inner:
                for item in zin_inner.infolist():
                    buffer = zin_inner.read(item.filename)
                    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏
                    target_name = expected if item.filename == incorrect_candidate else item.filename
                    # –°–æ–∑–¥–∞–µ–º ZipInfo —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º/–∏—Å—Ö–æ–¥–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
                    target_info = zipfile.ZipInfo(target_name, date_time=item.date_time)
                    target_info.compress_type = item.compress_type
                    target_info.external_attr = item.external_attr 
                    target_info.internal_attr = item.internal_attr
                    zout.writestr(target_info, buffer)
            print(f"INFO: –°–æ–∑–¥–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {fixed_path}")
            return fixed_path

    except zipfile.BadZipFile:
        print(f"WARNING: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {original_path} –∫–∞–∫ ZIP-–∞—Ä—Ö–∏–≤.")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, —á—Ç–æ–±—ã —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–± –æ—à–∏–±–∫–µ —á—Ç–µ–Ω–∏—è –∫–∞–∫ XLSX
        return None 
    except Exception as e:
        print(f"ERROR: –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {original_path} –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞: {e}")
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ, –µ—Å–ª–∏ –æ–Ω —Å–æ–∑–¥–∞–ª—Å—è
        if fixed_path != original_path and os.path.exists(fixed_path):
             try: os.remove(fixed_path)
             except Exception: pass
        return None # –í —Å–ª—É—á–∞–µ —Å–µ—Ä—å–µ–∑–Ω–æ–π –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
# --- –ö–æ–Ω–µ—Ü —É—Ç–∏–ª–∏—Ç—ã --- 

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø (–º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ utils.py –µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ---
def format_distance_data_from_segments(segments_data):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤."""
    total_distance_meters = 0
    total_duration_seconds = 0
    formatted_segments = [] # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥—É
    
    for segment in segments_data:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get —Å 0 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        distance = segment.get('distance', 0)
        duration = segment.get('duration', 0)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –æ—à–∏–±–∫–∞–º–∏ (–≥–¥–µ distance/duration –º–æ–≥–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è 0 –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ API)
        if segment.get('status') != "OK":
            print(f"  - Warning: Skipping segment {segment.get('from_index', '?')}->{segment.get('to_index', '?')} due to status: {segment.get('status')}")
            continue # –ù–µ —É—á–∏—Ç—ã–≤–∞–µ–º –æ—à–∏–±–æ—á–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Å—É–º–º–µ
            
        if isinstance(distance, (int, float)):
            total_distance_meters += distance
        if isinstance(duration, (int, float)):
            total_duration_seconds += duration
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç –≤ —Å–ø–∏—Å–æ–∫ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        # formatted_segments.append({...}) 

    # –û–∫—Ä—É–≥–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –ö–ú (–∫–∞–∫ –≤ get_route_data_endpoint)
    total_distance_km_rounded = round(total_distance_meters / 1000) if total_distance_meters is not None else 0
    formatted_distance = f"{total_distance_km_rounded} –∫–º"

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è
    hours = total_duration_seconds // 3600
    minutes = (total_duration_seconds % 3600) // 60
    formatted_duration = f"{hours} —á {minutes} –º–∏–Ω" if hours > 0 else f"{minutes} –º–∏–Ω"
    if total_duration_seconds == 0: # –ï—Å–ª–∏ –≤—Ä–µ–º—è 0, –ø–æ–∫–∞–∑–∞—Ç—å 0 –º–∏–Ω
        formatted_duration = "0 –º–∏–Ω" 

    return {
        "segments": segments_data, # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        "total_distance": total_distance_km_rounded, # –û–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–µ –ö–ú
        "total_duration": total_duration_seconds,  # –°–µ–∫—É–Ω–¥—ã
        "formatted_distance": formatted_distance,
        "formatted_duration": formatted_duration
    }
# --- –ö–û–ù–ï–¶ –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ô –§–£–ù–ö–¶–ò–ò ---

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class RouteData:
    def __init__(self):
        self.routes = {}  # –ö–ª—é—á: sanitized_name
        self.summary = {} # –ö–ª—é—á: sanitized_name, –ó–Ω–∞—á–µ–Ω–∏–µ: {...}
        self.drivers = {} # <--- –ù–û–í–û–ï –ü–û–õ–ï: –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–æ–¥–∏—Ç–µ–ª–µ–π {sanitized_name: driver_name}
        self.current_file = ""  # –ò–º—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        self.global_service_time_minutes = 0 # <--- –ù–û–í–û–ï –ì–õ–û–ë–ê–õ–¨–ù–û–ï –ü–û–õ–ï (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)
        self.report_date_str: Optional[str] = None # <--- –î–û–ë–ê–í–õ–ï–ù–û –ü–û–õ–ï –î–õ–Ø –î–ê–¢–´ –û–¢–ß–ï–¢–ê

    def add_route(self, name, data):
        sanitized_name = sanitize_filename(name)
        if not sanitized_name: return

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞ (geocoder_output, route_points, distance_data)
        self.routes[sanitized_name] = data

        distance_data = data.get("distance_data", {})
        distance_km = distance_data.get("total_distance") # –û–∂–∏–¥–∞–µ–º –æ–∫—Ä—É–≥–ª–µ–Ω–Ω–æ–µ –¥–æ —Ü–µ–ª—ã—Ö –∫–º
        duration_sec = distance_data.get("total_duration") # –û–∂–∏–¥–∞–µ–º —Å–µ–∫—É–Ω–¥—ã
        duration_formatted = distance_data.get("formatted_duration", "–ù/–î")
        # --- –ò–ó–ú–ï–ù–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å ---
        # –°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞: num_intermediate_stops = len(data.get("route_points", []))
        # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞: 
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å 'number_of_stops' –∏–∑ –≤—Ö–æ–¥—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö (—ç—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫–æ–ª-–≤–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ç–æ—á–µ–∫)
        num_intermediate_stops = data.get("number_of_stops") 
        if num_intermediate_stops is None:
             # –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –∫–∞–∫ fallback, –Ω–æ –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π
             # (—Ç.–∫. route_points –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–∞—Ä—Ç/—Ñ–∏–Ω–∏—à)
             print(f"[add_route] WARNING: 'number_of_stops' not provided in data for route '{name}'. Falling back to len(route_points). This might be incorrect.")
             # –ü—ã—Ç–∞–µ–º—Å—è —É–≥–∞–¥–∞—Ç—å: –µ—Å–ª–∏ –≤ route_points –µ—Å—Ç—å —Å—Ç–∞—Ä—Ç/—Ñ–∏–Ω–∏—à, –≤—ã—á–∏—Ç–∞–µ–º 2
             # –≠—Ç–æ –ù–ï–Ω–∞–¥–µ–∂–Ω–æ, –ª—É—á—à–µ –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å number_of_stops!
             route_points_list = data.get("route_points", [])
             if len(route_points_list) >= 2 and route_points_list[0] == route_points_list[-1]: # –ü—Ä–æ—Å—Ç–æ–π —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç
                 num_intermediate_stops = len(route_points_list) - 2
             else:
                 num_intermediate_stops = len(route_points_list)
        # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ---

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ summary
        if sanitized_name not in self.summary:
            self.summary[sanitized_name] = {
                "original_name": name,
                "distance": distance_km if distance_km is not None else "–ù/–î",
                "duration_seconds": duration_sec, # –•—Ä–∞–Ω–∏–º —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–Ω–∏—Ü—ã –∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ
                "duration_formatted": duration_formatted, # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏
                "number_of_stops": num_intermediate_stops, # <--- –ù–û–í–û–ï –ü–û–õ–ï: –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫
                "report_distance": None,
                "report_duration_hours": None,
                "report_duration_minutes": None,
                "distance_difference": None,
                "time_difference_formatted": None,
                "total_route_time_seconds": None, # <--- –ù–û–í–û–ï –ü–û–õ–ï: –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤ —Å–µ–∫
                "total_route_time_formatted": None # <--- –ù–û–í–û–ï –ü–û–õ–ï: –æ–±—â–µ–µ –≤—Ä–µ–º—è —Ñ–æ—Ä–º–∞—Ç.
            }
        else:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
            self.summary[sanitized_name]["distance"] = distance_km if distance_km is not None else "–ù/–î"
            self.summary[sanitized_name]["duration_seconds"] = duration_sec
            self.summary[sanitized_name]["duration_formatted"] = duration_formatted
            self.summary[sanitized_name]["number_of_stops"] = num_intermediate_stops # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø–æ–ª—è, –≤–∫–ª—é—á–∞—è –Ω–æ–≤–æ–µ "–í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ"
        self._recalculate_summary_fields(sanitized_name)

    def get_route_names(self):
        return [data.get("original_name", key) for key, data in self.summary.items()]

    def get_route(self, name):
        sanitized_name = sanitize_filename(name)
        return self.routes.get(sanitized_name, {})

    def update_summary_item(self, name, report_distance=None, report_hours=None, report_minutes=None, comment=None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ –≤ —Å–≤–æ–¥–∫–µ (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É)."""
        sanitized_name = sanitize_filename(name)
        if not sanitized_name or sanitized_name not in self.summary:
            print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–∞—Ä—à—Ä—É—Ç –≤ —Å–≤–æ–¥–∫–µ: {name} (sanitized: {sanitized_name})")
            return False

        summary_item = self.summary[sanitized_name]
        updated = False

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Ç—á–µ—Ç—É
        if report_distance is not None:
            try:
                report_distance_float = float(report_distance) if str(report_distance).strip() != "" else None
                if summary_item.get("report_distance") != report_distance_float:
                    summary_item["report_distance"] = report_distance_float
                    updated = True
            except (ValueError, TypeError):
                if summary_item.get("report_distance") is not None:
                     summary_item["report_distance"] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –µ—Å–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–≤–æ–¥
                     updated = True

        # --- –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ –æ—Ç—á–µ—Ç—É ---
        new_report_h = None
        new_report_m = None
        try:
            if report_hours is not None and str(report_hours).strip() != "":
                new_report_h = int(report_hours)
            if report_minutes is not None and str(report_minutes).strip() != "":
                new_report_m = int(report_minutes)

            if summary_item.get("report_duration_hours") != new_report_h or \
               summary_item.get("report_duration_minutes") != new_report_m:
                summary_item["report_duration_hours"] = new_report_h
                summary_item["report_duration_minutes"] = new_report_m
                updated = True
                print(f"   Updated report time in summary_item: h={new_report_h}, m={new_report_m}")

        except (ValueError, TypeError):
            if summary_item.get("report_duration_hours") is not None or \
               summary_item.get("report_duration_minutes") is not None:
                summary_item["report_duration_hours"] = None
                summary_item["report_duration_minutes"] = None
                updated = True
                print(f"   Reset report time in summary_item due to conversion error")
                
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        if comment is not None and summary_item.get("comment") != comment:
            summary_item["comment"] = comment
            updated = True

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–ª—è (–≤–∫–ª—é—á–∞—è –≤—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ) –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ–±–Ω–æ–≤–∏–ª–æ—Å—å
        if updated:
            self._recalculate_summary_fields(sanitized_name) # –ü–µ—Ä–µ—Å—á–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç –Ω–æ–≤–æ–µ –ø–æ–ª–µ
            self.save_to_disk()
            return True

        return False # –ù–∏—á–µ–≥–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å

    def _recalculate_summary_fields(self, sanitized_name, summary_dict=None):
        """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω–∏—Ü—É –≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏, –≤—Ä–µ–º–µ–Ω–∏ –∏ –æ–±—â–µ–µ –≤—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ."""
        target_summary = summary_dict if summary_dict is not None else self.summary

        if sanitized_name not in target_summary:
            return

        item = target_summary[sanitized_name]
        original_name = item.get("original_name", sanitized_name)
        print(f"-- Recalculating fields for: {original_name}")

        # --- –†–∞–∑–Ω–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π ---
        report_dist = item.get("report_distance")
        route_dist = item.get("distance")
        if report_dist is not None and isinstance(route_dist, (int, float)):
            try:
                item["distance_difference"] = round(route_dist - float(report_dist), 2)
            except (ValueError, TypeError):
                item["distance_difference"] = None
        else:
            item["distance_difference"] = None
        # print(f"   Distance diff calculated: {item['distance_difference']}") # –£–±—Ä–∞–ª –ª–æ–≥ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏

        # --- –†–∞—Å—á–µ—Ç –û–±—â–µ–≥–æ –í—Ä–µ–º–µ–Ω–∏ –Ω–∞ –ú–∞—Ä—à—Ä—É—Ç–µ (–ü–†–ê–í–ò–õ–¨–ù–û–ï –ú–ï–°–¢–û) ---
        total_route_time_seconds = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        route_sec = item.get("duration_seconds") # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏
        service_time_sec = 0
        if self.global_service_time_minutes is not None:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get —Å –¥–µ—Ñ–æ–ª—Ç–æ–º 0 –¥–ª—è number_of_stops
                service_time_sec = int(self.global_service_time_minutes) * 60 * item.get("number_of_stops", 0)
            except (ValueError, TypeError):
                 service_time_sec = 0

        if route_sec is not None:
            try:
                total_route_time_seconds = int(route_sec) + service_time_sec # <-- –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
                item["total_route_time_seconds"] = total_route_time_seconds # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ item
                hours = total_route_time_seconds // 3600
                minutes = (total_route_time_seconds % 3600) // 60
                item["total_route_time_formatted"] = f"{hours} —á {minutes} –º–∏–Ω" # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            except (ValueError, TypeError) as e:
                print(f"   Error calculating total route time for {original_name}: {e}")
                item["total_route_time_seconds"] = None
                item["total_route_time_formatted"] = None
        else:
            item["total_route_time_seconds"] = None
            item["total_route_time_formatted"] = None
            # print(f"   Skipping total route time calculation (route_sec={route_sec})") # –ú–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

        # --- –†–∞–∑–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏ (–æ—Ç—á–µ—Ç vs –û–ë–©–ï–ï –í–†–ï–ú–Ø –ù–ê –ú–ê–†–®–†–£–¢–ï) ---
        report_h = item.get("report_duration_hours")
        report_m = item.get("report_duration_minutes")
        # route_sec –ë–û–õ–¨–®–ï –ù–ï –ù–£–ñ–ï–ù –ó–î–ï–°–¨, –∏—Å–ø–æ–ª—å–∑—É–µ–º total_route_time_seconds

        # ... (–ª–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ time_difference_formatted –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–µ–π) ...
        try:
            report_h_int = int(report_h) if report_h is not None and str(report_h).strip() != "" else 0
            report_m_int = int(report_m) if report_m is not None and str(report_m).strip() != "" else 0
            is_report_time_valid = not (report_h_int == 0 and report_m_int == 0 and (report_h is None or str(report_h).strip() == "") and (report_m is None or str(report_m).strip() == ""))
        except (ValueError, TypeError):
             is_report_time_valid = False

        calculate_time_diff = False
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –û–ë–©–ï–ï –≤—Ä–µ–º—è —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ
        if total_route_time_seconds is not None:
            if is_report_time_valid:
                 calculate_time_diff = True
            elif report_h_int == 0 and report_m_int == 0: # –ï—Å–ª–∏ –≤—Ä–µ–º—è –æ—Ç—á–µ—Ç–∞ –Ω–µ –≤–≤–µ–¥–µ–Ω–æ (0—á 0–º), —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É
                 calculate_time_diff = True # <-- –ò–ó–ú–ï–ù–ï–ù–û: –°—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É, –¥–∞–∂–µ –µ—Å–ª–∏ –≤—Ä–µ–º—è –æ—Ç—á–µ—Ç–∞ 0, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω–æ–µ –≤—Ä–µ–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü—É

        if calculate_time_diff:
            try:
                report_total_seconds = report_h_int * 3600 + report_m_int * 60
                # –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–ë–©–ï–ï –í–†–ï–ú–Ø –ù–ê –ú–ê–†–®–†–£–¢–ï –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–Ω–∏—Ü—ã
                time_diff_value_seconds = total_route_time_seconds - report_total_seconds # <-- –†–ï–ê–õ–¨–ù–û–ï –ó–ù–ê–ß–ï–ù–ò–ï –†–ê–ó–ù–ò–¶–´
                sign = "+" if time_diff_value_seconds >= 0 else "-"
                diff_seconds_abs = abs(time_diff_value_seconds) # –ò—Å–ø–æ–ª—å–∑—É–µ–º abs() –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                diff_hours = diff_seconds_abs // 3600
                diff_minutes = (diff_seconds_abs % 3600) // 60
                item["time_difference_formatted"] = f"{sign}{diff_hours} —á {diff_minutes} –º–∏–Ω"
                item["time_difference_seconds"] = time_diff_value_seconds # <-- –°–û–•–†–ê–ù–Ø–ï–ú –ó–ù–ê–ß–ï–ù–ò–ï –í –°–ï–ö–£–ù–î–ê–•
            except (ValueError, TypeError) as e:
                print(f"   Error calculating time diff for {original_name}: {e}")
                item["time_difference_formatted"] = None
                item["time_difference_seconds"] = None # <-- –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏ —Å–µ–∫—É–Ω–¥—ã
        else:
            item["time_difference_formatted"] = None
            item["time_difference_seconds"] = None # <-- –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏ —Å–µ–∫—É–Ω–¥—ã

    def get_summary(self):
        try:
            with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
                original_names_data = json.load(f)
                original_names = original_names_data.get("routes", [])
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å original_route_names.json: {e}")
            original_names = []

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ self.summary
        saved_user_input = {}
        for norm_name, data in self.summary.items():
            saved_user_input[norm_name] = {
                "report_distance": data.get("report_distance"),
                "report_duration_hours": data.get("report_duration_hours"),
                "report_duration_minutes": data.get("report_duration_minutes"),
                "comment": data.get("comment", "")
            }

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—É—â–∏–π summary –ø–µ—Ä–µ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        current_summary = {} # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("--- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–≤–æ–¥–∫–∏ --- ")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –º–∞—Ä—à—Ä—É—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö
        for original_name in original_names:
            sanitized_name = sanitize_filename(original_name)
            if not sanitized_name: continue
            
            print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞: {original_name}...")
            try:
                # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞ (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, —Ç–æ—á–∫–∏ –∏ —Ç.–¥.)
                route_data_response = get_route_data_endpoint(original_name)
                
                if route_data_response and not route_data_response.get("error"):
                    distance_data = route_data_response.get("distance_data", {})
                    distance_km = distance_data.get("total_distance") # –û–∂–∏–¥–∞–µ–º –∫–º
                    duration_sec = distance_data.get("total_duration") # –û–∂–∏–¥–∞–µ–º —Å–µ–∫
                    duration_formatted = distance_data.get("formatted_duration", "–ù/–î")
                    number_of_stops = route_data_response.get("number_of_stops", 0)
                    
                    # --- –ü–û–õ–£–ß–ï–ù–ò–ï –§–ò–û –í–û–î–ò–¢–ï–õ–Ø --- 
                    driver_name = self.drivers.get(sanitized_name, "‚Äî") # –ü–æ–ª—É—á–∞–µ–º –∏–∑ self.drivers, –¥–µ—Ñ–æ–ª—Ç "‚Äî"
                    print(f"    -> –í–æ–¥–∏—Ç–µ–ª—å –¥–ª—è {original_name}: {driver_name}")
                    # -----------------------------------
                    
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –ù–û–í–û–ô —Å–≤–æ–¥–∫–µ
                    current_summary[sanitized_name] = {
                        "original_name": original_name,
                        "driver_name": driver_name, # <--- –î–û–ë–ê–í–õ–ï–ù–û –ü–û–õ–ï
                        "distance": distance_km if distance_km is not None else "–ù/–î",
                        "duration_seconds": duration_sec,
                        "duration_formatted": duration_formatted,
                        "number_of_stops": number_of_stops, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ
                        "report_distance": None, # –ë—É–¥—É—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –Ω–∏–∂–µ
                        "report_duration_hours": None,
                        "report_duration_minutes": None,
                        "distance_difference": None,
                        "time_difference_formatted": None,
                        "time_difference_seconds": None, # <-- –î–û–ë–ê–í–õ–ï–ù–û
                        "total_route_time_seconds": None, # –ë—É–¥—É—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –Ω–∏–∂–µ
                        "total_route_time_formatted": None
                    }

                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤—ã—à–µ)
                    if sanitized_name in saved_user_input:
                        for field in ["report_distance", "report_duration_hours", "report_duration_minutes", "comment"]:
                            if field in saved_user_input[sanitized_name]:
                                current_summary[sanitized_name][field] = saved_user_input[sanitized_name][field]
                        
                    # --- –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ï–†–ï–°–ß–ï–¢ –ü–û–õ–ï–ô –î–õ–Ø –ö–ê–ñ–î–û–ô –ó–ê–ü–ò–°–ò --- 
                    self._recalculate_summary_fields(sanitized_name, summary_dict=current_summary) # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
                        
                    print(f"    ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–≤–æ–¥–∫–∏ –ø–æ–ª—É—á–µ–Ω—ã –∏ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã: {original_name}")
                else:
                    error_msg = route_data_response.get('message') if route_data_response else '–î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã'
                    print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_name}: {error_msg}")
            except Exception as e:
                print(f"    ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä—à—Ä—É—Ç–∞ {original_name} –¥–ª—è —Å–≤–æ–¥–∫–∏: {e}")
                # import traceback
                # traceback.print_exc()

        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π summary –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        self.summary = current_summary
        self.save_to_disk() 
        print("--- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ --- ")
        return self.summary

    def save_to_disk(self):
         data = {
             "routes": self.routes,
             "summary": self.summary,
             "drivers": self.drivers, 
             "current_file": self.current_file,
             "global_service_time_minutes": self.global_service_time_minutes,
             "report_date_str": self.report_date_str # <--- –°–û–•–†–ê–ù–Ø–ï–ú –î–ê–¢–£
         }
         # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º (—É–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ)
         # sanitized_data = sanitize_data_for_json(data) # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, json.dump —Å–∞–º —Å–ø—Ä–∞–≤–∏—Ç—Å—è —Å None
         with open(os.path.join(DATA_FOLDER, "route_data.json"), "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2) # –ò—Å–ø–æ–ª—å–∑—É–µ–º data –Ω–∞–ø—Ä—è–º—É—é

    def load_from_disk(self):
        try:
            with open(os.path.join(DATA_FOLDER, "route_data.json"), "r", encoding="utf-8") as f:
                data = json.load(f)
                self.routes = data.get("routes", {})
                self.summary = data.get("summary", {})
                self.drivers = data.get("drivers", {}) 
                self.current_file = data.get("current_file", "")
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è, –∏–ª–∏ 0 –µ—Å–ª–∏ –Ω–µ—Ç
                self.global_service_time_minutes = data.get("global_service_time_minutes", 0) 
                self.report_date_str = data.get("report_date_str", None) # <--- –ó–ê–ì–†–£–ñ–ê–ï–ú –î–ê–¢–£

                print(f"üíæ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ú–∞—Ä—à—Ä—É—Ç–æ–≤: {len(self.routes)}, –ó–∞–ø–∏—Å–µ–π –≤ —Å–≤–æ–¥–∫–µ: {len(self.summary)}, –í–æ–¥–∏—Ç–µ–ª–µ–π: {len(self.drivers)}, –í—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É: {self.global_service_time_minutes} –º–∏–Ω, –î–∞—Ç–∞ –æ—Ç—á–µ—Ç–∞: {self.report_date_str}") # <-- –î–æ–±–∞–≤–ª–µ–Ω –≤—ã–≤–æ–¥ –¥–∞—Ç—ã

                # –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ summary, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç)
                needs_recalculation = False
                for key, summary_item in self.summary.items():
                    if summary_item.setdefault("number_of_stops", None) is None:
                         # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –∏–∑ routes, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                         route_entry = self.routes.get(key)
                         if route_entry and "route_points" in route_entry:
                             summary_item["number_of_stops"] = len(route_entry["route_points"])
                             needs_recalculation = True
                             print(f"   –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è {key}: {summary_item['number_of_stops']}")
                         else:
                             summary_item["number_of_stops"] = 0 # –ò–ª–∏ —Å—Ç–∞–≤–∏–º 0, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏
                             print(f"   –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è {key}, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 0")
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º None, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
                    if summary_item.setdefault("total_route_time_seconds", None) is None: needs_recalculation = True
                    if summary_item.setdefault("total_route_time_formatted", None) is None: needs_recalculation = True
                    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ä–æ–µ –ø–æ–ª–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                    summary_item.pop("service_time_per_stop_minutes", None)

                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                    summary_item.setdefault("report_duration_hours", None)
                    summary_item.setdefault("report_duration_minutes", None)
                    summary_item.setdefault("time_difference_formatted", None)
                    summary_item.setdefault("duration_seconds", None)
                    summary_item.setdefault("distance_difference", None)


                # –ï—Å–ª–∏ –¥–æ–±–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–µ –ø–æ–ª—è –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫, –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º –≤—Å–µ
                if needs_recalculation:
                    print("   –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –∏–ª–∏ –±—ã–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç —Å–≤–æ–¥–∫–∏...")
                    for key in list(self.summary.keys()): # –ò—Å–ø–æ–ª—å–∑—É–µ–º list, —á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å —Å–ª–æ–≤–∞—Ä—å –≤–æ –≤—Ä–µ–º—è –∏—Ç–µ—Ä–∞—Ü–∏–∏
                        self._recalculate_summary_fields(key)
                    self.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

                return True
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å route_data.json: {e}. –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
            self.routes = {}
            self.summary = {}
            self.current_file = ""
            self.global_service_time_minutes = 0 # –°–±—Ä–æ—Å –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
            return False
        except Exception as e: # –õ–æ–≤–∏–º –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ/–º–∏–≥—Ä–∞—Ü–∏–∏
             print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ/–º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö route_data.json: {e}")
             # import traceback # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏
             # traceback.print_exc()
             self.routes = {}
             self.summary = {}
             self.current_file = ""
             self.global_service_time_minutes = 0
             return False

    # <--- –ù–û–í–´–ô –ú–ï–¢–û–î --->
    def set_global_service_time(self, minutes):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ."""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ int, –µ—Å–ª–∏ –Ω–µ None –∏ –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –∏–Ω–∞—á–µ 0
            new_time = int(minutes) if minutes is not None and str(minutes).strip() != "" else 0
            if new_time < 0: new_time = 0 # –í—Ä–µ–º—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º

            if new_time != self.global_service_time_minutes:
                print(f"üîÑ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–æ–≤–æ–≥–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É: {new_time} –º–∏–Ω.")
                self.global_service_time_minutes = new_time
                # –£–ë–†–ê–ù –ù–ï–ú–ï–î–õ–ï–ù–ù–´–ô –ü–ï–†–ï–°–ß–ï–¢
                # recalculated_count = 0
                # for key in list(self.summary.keys()):
                #     self._recalculate_summary_fields(key)
                #     recalculated_count += 1
                # print(f"   –ü–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–æ –º–∞—Ä—à—Ä—É—Ç–æ–≤: {recalculated_count}")
                self.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                return True
            else:
                print(f"‚ÑπÔ∏è –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ({new_time} –º–∏–Ω).")
                return False
        except (ValueError, TypeError):
            print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É: {minutes}. –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ: {self.global_service_time_minutes} –º–∏–Ω.")
            return False

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
route_data = RouteData()
# –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
if not route_data.load_from_disk():
    print("üíæ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç RouteData.")

@app.get("/", response_class=HTMLResponse)
def index(request: Request):
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä—à—Ä—É—Ç "–õ–∏–ø–µ—Ü–∫ 2" –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
    # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # if not os.path.exists(os.path.join(os.path.dirname(BASE_DIR), "geocoded_results_–õ–∏–ø–µ—Ü–∫_2.csv")):
    #     print("‚ö†Ô∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä—à—Ä—É—Ç '–õ–∏–ø–µ—Ü–∫ 2'...")
    #     process_route("–õ–∏–ø–µ—Ü–∫ 2")
    
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/api/health")
def health_check():
    return {"status": "ok"}

@app.get("/api/routes")
def get_routes():
    try:
        with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
            original_names_data = json.load(f)
            return {"routes": sorted(original_names_data.get("routes", []))}
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å original_route_names.json: {e}")
        return {"routes": []}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
def process_route(original_route_name):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    root_dir = os.path.dirname(script_dir)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –ø—É—Ç–µ–π
    file_name = sanitize_filename(original_route_name)
    parsed_path = os.path.join(PROJECT_DATA_FOLDER, "parsed_addresses", f"parsed_addresses_{file_name}.csv")
    geocoded_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{file_name}.csv")
    
    if not os.path.exists(parsed_path):
        print(f"‚ö†Ô∏è –§–∞–π–ª {parsed_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}")
        return False
    
    process_success = False # –§–ª–∞–≥ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –í–°–ï–ì–û –ø—Ä–æ—Ü–µ—Å—Å–∞
    try:
        # –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        with open(parsed_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        
        geocoded_output = []
        for row in rows:
            address = row["normalized_address"]
            result = geocode_address(address)
            result["excel_row"] = row["excel_row"]
            result["route_name"] = original_route_name
            geocoded_output.append(result)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(os.path.dirname(geocoded_path), exist_ok=True)
        
        with open(geocoded_path, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["excel_row", "route_name", "input", "found", "type", "description", "lat", "lon", "error"])
            writer.writeheader()
            writer.writerows(geocoded_output)
        print(f"‚úÖ –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}")
        
        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è {original_route_name}...")
        # –í—ã–∑—ã–≤–∞–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é
        calculation_success = route_distance.calculate_and_save_route(
            route_name=original_route_name, 
            geocoded_file_path=geocoded_path
            # traffic_mode –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –±—Ä–∞—Ç—å –∏–∑ config, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        )
        
        if calculation_success:
            print(f"‚úÖ –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è {original_route_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ (—á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é).")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è {original_route_name} (—á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é).")
            # –ú–æ–∂–Ω–æ —Ä–µ—à–∏—Ç—å, –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –ª–∏ –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å –∏–ª–∏ –Ω–µ—Ç
            # return False # –ü—Ä–µ—Ä–≤–∞—Ç—å, –µ—Å–ª–∏ —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –∫—Ä–∏—Ç–∏—á–µ–Ω

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ route_data
        if calculation_success: # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞—Å—á–µ—Ç –ø—Ä–æ—à–µ–ª
            try:
                route_info = get_route_data_endpoint(original_route_name)
                if route_info and not route_info.get("error"):
                    route_data.add_route(original_route_name, route_info)
                    route_data.save_to_disk()
                    print(f"‚úÖ –ú–∞—Ä—à—Ä—É—Ç {original_route_name} –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–≤–æ–¥–∫—É")
                    process_success = True # –í–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å —É—Å–ø–µ—à–µ–Ω
                else:
                    error_msg = route_info.get("message", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞") if route_info else "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞"
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç {original_route_name} –≤ —Å–≤–æ–¥–∫—É: {error_msg}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name} –≤ —Å–≤–æ–¥–∫—É: {str(e)}")
        else:
             print(f"‚ÑπÔ∏è –ú–∞—Ä—à—Ä—É—Ç {original_route_name} –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–≤–æ–¥–∫—É, —Ç.–∫. —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –Ω–µ —É–¥–∞–ª—Å—è.")

    except Exception as e:
        print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}: {str(e)}")

    return process_success

@app.get("/api/route-data/{route_name}")
def get_route_data_endpoint(route_name: str = Path(...)):
    original_route_name = route_name
    if not original_route_name:
        raise HTTPException(status_code=400, detail="–ò–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ")

    try:
        logging.info(f"Getting route data for '{original_route_name}'")
        file_name = sanitize_filename(original_route_name)
        # --- –ò–ó–ú–ï–ù–ï–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –æ–±–æ–∏–º —Ñ–æ—Ä–º–∞—Ç–∞–º ---
        geocoded_json_file = os.path.join(GEOCODED_RESULTS_FOLDER, f"{file_name}_geocoded.json")
        geocoded_csv_file = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{file_name}.csv")
        distance_data_json_file = os.path.join(ROUTE_RESULTS_FOLDER, f"{file_name}_distance_data.json") # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö
        route_results_json_file = os.path.join(ROUTE_RESULTS_FOLDER, f"route_results_{file_name}.json") # –°—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –æ—Ç process_route
        # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ---
        summary_item = route_data.summary.get(file_name, {}) # –ü–æ–ª—É—á–∞–µ–º –∑–∞—Ä–∞–Ω–µ–µ

        # --- –ò–ó–ú–ï–ù–ï–ù–û: –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç _distance_data.json) ---
        distance_data = {}
        distance_file_to_read = None

        if os.path.exists(distance_data_json_file):
            distance_file_to_read = distance_data_json_file
            logging.info(f"Found distance data file: {distance_file_to_read}")
        elif os.path.exists(route_results_json_file):
            distance_file_to_read = route_results_json_file
            logging.warning(f"Distance data file not found, falling back to route results: {distance_file_to_read}")
        else:
            logging.warning(f"Neither distance_data nor route_results file found for route {original_route_name}")
            distance_data = {"error": True, "error_message": f"–§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {original_route_name}"}

        if distance_file_to_read:
            try:
                with open(distance_file_to_read, 'r', encoding='utf-8') as f:
                    distance_data_loaded = json.load(f) # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ

                # --- –í–ê–ñ–ù–û: –ö–æ–ø–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ distance_data ---
                # –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, —á—Ç–æ–±—ã –¥–∞–ª—å–Ω–µ–π—à–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç–∞–ª–∞
                # —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ–±—ä–µ–∫—Ç–æ–º, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –ø—É—Å—Ç–æ–π.
                if isinstance(distance_data_loaded, dict):
                     distance_data = distance_data_loaded.copy()
                else:
                     # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                     logging.error(f"Invalid format in distance file {distance_file_to_read}. Expected dict, got {type(distance_data_loaded)}.")
                     distance_data = {}

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞ (–æ—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
                if 'total_distance' in distance_data and distance_data['total_distance'] is not None:
                    try:
                        # --- –ò–ó–ú–ï–ù–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∫ –ö–ú, —Ç–∞–∫ –∏ –º–µ—Ç—Ä–æ–≤ ---
                        # total_distance –º–æ–∂–µ—Ç –±—ã—Ç—å —É–∂–µ –≤ –ö–ú (–æ–∫—Ä—É–≥–ª–µ–Ω–Ω—ã—Ö) –∏–ª–∏ –≤ –º–µ—Ç—Ä–∞—Ö
                        distance_val = float(distance_data['total_distance'])
                        # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –±–æ–ª—å—à–æ–µ (>10000), —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ –º–µ—Ç—Ä—ã, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏ –æ–∫—Ä—É–≥–ª—è–µ–º
                        if distance_val > 10000:
                             distance_km_rounded = round(distance_val / 1000)
                             print(f"   [Dist Format] Detected meters ({distance_val}), converting to rounded km: {distance_km_rounded}")
                        else:
                             # –ò–Ω–∞—á–µ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ —É–∂–µ –æ–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–µ –ö–ú
                             distance_km_rounded = int(distance_val)
                             print(f"   [Dist Format] Detected km ({distance_val}), using as int: {distance_km_rounded}")

                        distance_data['formatted_distance'] = f"{distance_km_rounded} –∫–º"
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–µ –ö–ú –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                        distance_data['total_distance'] = distance_km_rounded
                    except (ValueError, TypeError) as e_dist:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å total_distance '{distance_data['total_distance']}': {e_dist}")
                        distance_data['formatted_distance'] = "–û—à–∏–±–∫–∞"
                        distance_data['total_distance'] = None
                else:
                    distance_data['formatted_distance'] = "–ù/–î"
                    distance_data['total_distance'] = None # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ None, –µ—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç

                if 'total_duration' in distance_data and distance_data['total_duration'] is not None:
                    try:
                        total_seconds = int(distance_data['total_duration'])
                        hours = total_seconds // 3600
                        minutes = (total_seconds % 3600) // 60
                        formatted_duration = f"{hours} —á {minutes} –º–∏–Ω" if hours > 0 else f"{minutes} –º–∏–Ω"
                        # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –¥–ª—è 0 —Å–µ–∫—É–Ω–¥
                        if total_seconds == 0: formatted_duration = "0 –º–∏–Ω"
                        distance_data['formatted_duration'] = formatted_duration
                        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ total_duration –æ—Å—Ç–∞–µ—Ç—Å—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                        distance_data['total_duration'] = total_seconds
                    except (ValueError, TypeError) as e_dur:
                         print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å total_duration '{distance_data['total_duration']}': {e_dur}")
                         distance_data['formatted_duration'] = "–û—à–∏–±–∫–∞"
                         distance_data['total_duration'] = None
                else:
                    distance_data['formatted_duration'] = "–ù/–î"
                    distance_data['total_duration'] = None # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ None

            except Exception as e:
                logging.error(f"Error reading distance/route results file {distance_file_to_read} for {original_route_name}: {e}")
                distance_data = {"error": True, "error_message": f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}"}
        # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ß–¢–ï–ù–ò–Ø –§–ê–ô–õ–ê –†–ê–°–°–¢–û–Ø–ù–ò–ô ---

        # --- –ò–ó–ú–ï–ù–ï–ù–û: –ß—Ç–µ–Ω–∏–µ geocoded_data (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç JSON) ---
        geocoded_data = []
        route_points = [] # –ë—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–æ—á–∫–∏ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ lat/lon
        number_of_stops_actual = 0
        geocoded_data_source = None # 'json' –∏–ª–∏ 'csv'

        try:
            # 1. –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å JSON
            if os.path.exists(geocoded_json_file):
                logging.info(f"Attempting to load geocoded data from JSON: {geocoded_json_file}")
                try:
                    with open(geocoded_json_file, 'r', encoding='utf-8') as f_json:
                        loaded_data = json.load(f_json)
                        if isinstance(loaded_data, list) and all(isinstance(item, dict) for item in loaded_data):
                            geocoded_data = loaded_data # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON
                            geocoded_data_source = 'json'
                            print(f"   Successfully loaded {len(geocoded_data)} points from JSON.")
                        else:
                            logging.error(f"Invalid format in {geocoded_json_file}. Expected list of dicts.")
                except Exception as e_json:
                    logging.error(f"Error reading {geocoded_json_file}: {e_json}. Falling back to CSV.")

            # 2. –ï—Å–ª–∏ JSON –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–Ω, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV
            if not geocoded_data and os.path.exists(geocoded_csv_file):
                logging.warning(f"JSON not found or invalid. Attempting to load from CSV: {geocoded_csv_file}")
                try:
                    geocoded_df = pd.read_csv(geocoded_csv_file)
                    geocoded_df.replace([np.nan, np.inf, -np.inf], None, inplace=True) # –ó–∞–º–µ–Ω—è–µ–º NaN/inf –Ω–∞ None
                    geocoded_data = geocoded_df.to_dict('records') # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                    geocoded_data_source = 'csv'
                    print(f"   Successfully loaded {len(geocoded_data)} points from CSV.")
                    # --- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å CSV –≤ JSON ---
                    # try:
                    #     with open(geocoded_json_file, 'w', encoding='utf-8') as f_conv:
                    #         json.dump(geocoded_data, f_conv, ensure_ascii=False, indent=4)
                    #     print(f"   Successfully converted and saved data to {geocoded_json_file}")
                    # except Exception as e_conv:
                    #     logging.warning(f"Could not save converted CSV data to JSON ({geocoded_json_file}): {e_conv}")
                    # --- –ö–æ–Ω–µ—Ü –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ---
                except Exception as e_csv:
                    logging.error(f"Error reading or processing CSV file {geocoded_csv_file}: {e_csv}")
                    geocoded_data = [] # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º –ø—Ä–∏ –æ—à–∏–±–∫–µ CSV

            # 3. –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ JSON, –Ω–∏ CSV
            elif not geocoded_data:
                logging.warning(f"Could not find geocoded file (JSON or CSV) for route {original_route_name}")

            # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö geocoded_data (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
            if geocoded_data:
                 for point_data in geocoded_data:
                     # –î–æ–±–∞–≤–ª—è–µ–º –≤ route_points —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                     if 'lon' in point_data and 'lat' in point_data and point_data['lon'] is not None and point_data['lat'] is not None:
                        try:
                             lat = float(point_data['lat'])
                             lon = float(point_data['lon'])
                             if -90 <= lat <= 90 and -180 <= lon <= 180:
                                route_points.append({
                                     'lon': lon,
                                     'lat': lat,
                                     # –ò—Å–ø–æ–ª—å–∑—É–µ–º description –¥–ª—è –∞–¥—Ä–µ—Å–∞ –Ω–∞ –∫–∞—Ä—Ç–µ, input –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ
                                     'address': point_data.get('description', point_data.get('input', '')),
                                     'original_address': point_data.get('input', '')
                                 })
                             else: # –õ–æ–≥–≥–∏—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                                 print(f"‚ö†Ô∏è Invalid coordinate range in geocoded_data for {original_route_name}: lat={lat}, lon={lon}")
                        except (ValueError, TypeError):
                             print(f"‚ö†Ô∏è Invalid coordinate types in geocoded_data for {original_route_name}: {point_data.get('lat')}, {point_data.get('lon')}")

                 # –°—á–∏—Ç–∞–µ–º —Ç–æ—á–∫–∏ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ (–±–µ–∑ –æ—Ñ–∏—Å–∞, —Ç.–∫. –æ–Ω –µ—â–µ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω)
                 number_of_stops_actual = len(route_points)

                 # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤ summary, –µ—Å–ª–∏ –æ–Ω–æ —Ä–∞—Å—Ö–æ–¥–∏—Ç—Å—è –∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º
                 if file_name in route_data.summary:
                     # --- –ò–ó–ú–ï–ù–ï–ù–û: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å number_of_stops_actual (–±–µ–∑ –æ—Ñ–∏—Å–∞) ---
                     current_summary_stops = route_data.summary[file_name].get("number_of_stops")
                     if current_summary_stops is None or current_summary_stops != number_of_stops_actual:
                         print(f"‚ö†Ô∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–ª-–≤–∞ —Ç–æ—á–µ–∫ –¥–ª—è {original_route_name} —Å {current_summary_stops} –Ω–∞ {number_of_stops_actual}")
                         route_data.summary[file_name]["number_of_stops"] = number_of_stops_actual
                         route_data._recalculate_summary_fields(file_name)
                         route_data.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                         summary_item = route_data.summary.get(file_name, {}) # –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π summary_item
                     # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ---
                 else:
                     logging.warning(f"Route {original_route_name} (sanitized: {file_name}) not found in summary data.")
            else: # –ï—Å–ª–∏ geocoded_data –ø—É—Å—Ç
                 number_of_stops_actual = 0
                 route_points = []

        except Exception as e:
             # –õ–æ–≤–∏–º –æ–±—â—É—é –æ—à–∏–±–∫—É —á—Ç–µ–Ω–∏—è/–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
             logging.error(f"Error processing geocoding data for {original_route_name}: {e}")
             geocoded_data = []
             route_points = []
             number_of_stops_actual = 0
        # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ß–¢–ï–ù–ò–Ø GEOCODED_DATA ---

        # --- –î–û–ë–ê–í–õ–ï–ù–ò–ï –û–§–ò–°–ê –†–¢–ö –í –ù–ê–ß–ê–õ–û –ò –ö–û–ù–ï–¶ –°–ü–ò–°–ö–û–í –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê ---
        # (–≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —Ç.–∫. –æ–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–º–∏ geocoded_data –∏ route_points)
        try:
            office_loc = config.OFFICE_LOCATION
            if office_loc and "lat" in office_loc and "lon" in office_loc:
                office_lat = office_loc["lat"]
                office_lon = office_loc["lon"]
                office_name = office_loc.get("name", "–û—Ñ–∏—Å –†–¢–ö")

                # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã geocoded_data
                office_geocoded_repr = {
                    "excel_row": "–°–¢–ê–†–¢",
                    "route_name": original_route_name,
                    "input": office_name,
                    "found": True,
                    "type": "office",
                    "description": office_name,
                    "lat": office_lat,
                    "lon": office_lon,
                    "error": None
                }
                # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞—Ä—Ç—ã route_points
                office_route_point_repr = {
                    "lat": office_lat,
                    "lon": office_lon,
                    "address": office_name,
                    "original_address": office_name
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ
                geocoded_data.insert(0, office_geocoded_repr)
                route_points.insert(0, office_route_point_repr)

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü (–∫–æ–ø–∏—Ä—É–µ–º, —á—Ç–æ–±—ã excel_row –º–æ–∂–Ω–æ –±—ã–ª–æ –∏–∑–º–µ–Ω–∏—Ç—å)
                office_geocoded_repr_end = office_geocoded_repr.copy()
                office_geocoded_repr_end["excel_row"] = "–§–ò–ù–ò–®"
                geocoded_data.append(office_geocoded_repr_end)
                route_points.append(office_route_point_repr) # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–µ –∂–µ

                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –æ—Ñ–∏—Å –†–¢–ö –≤ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}")

            else:
                print("‚ö†Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã OFFICE_LOCATION –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã –≤ config.py. –û—Ñ–∏—Å –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω.")
        except Exception as e_office:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –æ—Ñ–∏—Å–∞ –†–¢–ö: {e_office}")
        # --- –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø –û–§–ò–°–ê ---


        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∏ –Ω–æ–≤—ã–µ –ø–æ–ª—è
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º number_of_stops_actual (–±–µ–∑ –æ—Ñ–∏—Å–∞) –¥–ª—è –ø–æ–ª—è number_of_stops
        return {
            "route_name": original_route_name,
            "geocoder_output": geocoded_data, # <--- –¢–µ–ø–µ—Ä—å —Å –æ—Ñ–∏—Å–æ–º
            "route_points": route_points,     # <--- –¢–µ–ø–µ—Ä—å —Å –æ—Ñ–∏—Å–æ–º
            "distance_data": distance_data,
            "number_of_stops": summary_item.get("number_of_stops", number_of_stops_actual), # –ë–µ—Ä–µ–º –∏–∑ summary –∏–ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ (–±–µ–∑ –æ—Ñ–∏—Å–∞)
            "total_route_time_formatted": summary_item.get("total_route_time_formatted", "–ù/–î"),
            "global_service_time_minutes": route_data.global_service_time_minutes
        }
    except Exception as e:
        logging.error(f"Error in get_route_data_endpoint for {original_route_name}: {e}")
        # import traceback
        # traceback.print_exc()
        return {"error": True, "message": str(e), "route_name": original_route_name}

@app.get("/api/summary")
def get_summary_endpoint():
    summary = route_data.get_summary() # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Ç–µ–ø–µ—Ä—å —Å–∞–º –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç
    result = []
    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π route_data.summary –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ get_summary()
    for norm_name, data in route_data.summary.items():
        result.append({
            "route_name": data.get("original_name", norm_name),
            "driver_name": data.get("driver_name", "‚Äî"),
            "distance": data.get("distance", "–ù/–î"),
            "duration_seconds": data.get("duration_seconds"), # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏ (—Å–µ–∫)
            "duration": data.get("duration_formatted", "–ù/–î"), # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏ (—Ñ–æ—Ä–º–∞—Ç)
            "report_distance": data.get("report_distance"),
            "report_duration_hours": data.get("report_duration_hours"),
            "report_duration_minutes": data.get("report_duration_minutes"),
            "distance_difference": data.get("distance_difference"),
            "time_difference_formatted": data.get("time_difference_formatted"),
            "time_difference_seconds": data.get("time_difference_seconds"), # <-- –î–û–ë–ê–í–õ–ï–ù–û
            "total_route_time_seconds": data.get("total_route_time_seconds"), # <-- –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            "total_route_time_formatted": data.get("total_route_time_formatted", "–ù/–î"), # –í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ (—Ñ–æ—Ä–º–∞—Ç)
            "number_of_stops": data.get("number_of_stops", "–ù/–î"), # <--- –î–û–ë–ê–í–õ–ï–ù–û –ö–û–õ-–í–û –¢–û–ß–ï–ö
            "comment": data.get("comment", "") # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        })
    # –î–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É –≤ –æ—Ç–≤–µ—Ç
    return {
        "summary": result, # <<< –£–ë–†–ê–ù–ê –°–û–†–¢–ò–†–û–í–ö–ê
        "global_service_time_minutes": route_data.global_service_time_minutes
     }

@app.post("/api/upload")
async def upload_excel(file: UploadFile, 
                     service_time_per_stop_minutes: int = Form(0),
                     report_date: str = Form("")): # <--- –î–û–ë–ê–í–õ–ï–ù –ü–ê–†–ê–ú–ï–¢–† –î–ê–¢–´
    save_path = os.path.join(UPLOAD_FOLDER, file.filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
    route_data.current_file = file.filename
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç—É –æ—Ç—á–µ—Ç–∞
    route_data.report_date_str = report_date # <--- –°–û–•–†–ê–ù–ï–ù–ò–ï –î–ê–¢–´
    print(f"--- Received report date in /api/upload: {report_date} ---") # <-- –õ–æ–≥ –¥–∞—Ç—ã

    # --- –ü–µ—á–∞—Ç–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ ---
    print(f"--- Received time per stop in /api/upload: {service_time_per_stop_minutes} (type: {type(service_time_per_stop_minutes)}) ---")
    # --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

    # --- –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É ---
    route_data.set_global_service_time(service_time_per_stop_minutes)
    # --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

    try:
        # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–®–ê–ì 3.1) --- 
        temp_upload_path = None # –ò—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∑–∫–∏
        corrected_path = None   # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        path_to_read = None     # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —á—Ç–µ–Ω–∏—è
        # --- –ö–æ–Ω–µ—Ü –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ---
        
        # --- –®–ê–ì 3.2 (REVISED): –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª --- 
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            temp_fd, temp_upload_path = tempfile.mkstemp(suffix=os.path.splitext(file.filename)[1])
            os.close(temp_fd) # –ó–∞–∫—Ä—ã–≤–∞–µ–º –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä, –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –ø—É—Ç—å
            print(f"INFO: –°–æ–∑–¥–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—É—Ç—å: {temp_upload_path}")

            # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏ –∏ –∫–æ–ø–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            bytes_written = 0
            with open(temp_upload_path, 'wb') as temp_f_out:
                # !!! –î–æ–±–∞–≤–ª—è–µ–º await file.seek(0) –ø–µ—Ä–µ–¥ —Ü–∏–∫–ª–æ–º —á—Ç–µ–Ω–∏—è !!!
                await file.seek(0) 
                while True:
                    # –ß–∏—Ç–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ—Ä—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–≥–æ —Ñ–∞–π–ª–∞
                    chunk = await file.read(8192) # 8KB chunk size
                    if not chunk:
                        break
                    temp_f_out.write(chunk)
                    bytes_written += len(chunk)
            # –§–∞–π–ª temp_f_out –∑–∞–∫—Ä—ã–≤–∞–µ—Ç—Å—è –∑–¥–µ—Å—å –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ with
            print(f"INFO: –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—É—Ç—å: {temp_upload_path} ({bytes_written} –±–∞–π—Ç)")
            
            # –î–æ–±–∞–≤–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
            if bytes_written == 0:
                 raise ValueError("–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –æ–∫–∞–∑–∞–ª—Å—è –ø—É—Å—Ç—ã–º.")
                 
        except Exception as e_save:
             print(f"ERROR: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e_save}")
             # –ü–æ–ø—ã—Ç–∫–∞ —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω —á–∞—Å—Ç–∏—á–Ω–æ
             if temp_upload_path and os.path.exists(temp_upload_path):
                 try: os.remove(temp_upload_path)
                 except Exception: pass
             raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e_save}")
        # --- –ö–æ–Ω–µ—Ü –®–∞–≥–∞ 3.2 (REVISED) ---
        
        # --- –®–ê–ì 3.3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª --- 
        path_to_read = fix_xlsx_casing(temp_upload_path)
        if path_to_read is None:
            # fix_xlsx_casing –≤–µ—Ä–Ω—É–ª–∞ None, –æ—à–∏–±–∫–∞ (–Ω–∞–ø—Ä. BadZipFile –∏–ª–∏ –¥—Ä—É–≥–∞—è –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏)
            if temp_upload_path and os.path.exists(temp_upload_path):
                 try: os.remove(temp_upload_path)
                 except Exception: pass
            # –¢–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É 400, —Ç.–∫. –ø—Ä–æ–±–ª–µ–º–∞ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤ —Ñ–∞–π–ª–µ
            raise HTTPException(status_code=400, detail="–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π XLSX —Ñ–∞–π–ª.")
        elif path_to_read != temp_upload_path:
            corrected_path = path_to_read # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –ø—É—Ç—å –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
            print(f"INFO: –§–∞–π–ª –±—ã–ª –∏—Å–ø—Ä–∞–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ–≤—ã–π –ø—É—Ç—å: {corrected_path}")
        else:
            print("INFO: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å.")
        # --- –ö–æ–Ω–µ—Ü –®–∞–≥–∞ 3.3 --- 
        
        # --- –ß—Ç–µ–Ω–∏–µ Excel –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–æ–≤ (–®–ê–ì 3.4) --- 
        print(f"--- –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {path_to_read} ---")
        df = pd.read_excel(path_to_read, engine='openpyxl')
        # --- –ö–æ–Ω–µ—Ü –®–∞–≥–∞ 3.4 ---
        
        # --- –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–ª–æ–≤–∞—Ä—å –ª–∏—Å—Ç–æ–≤ –Ω–µ –ø—É—Å—Ç–æ–π (–≤–º–µ—Å—Ç–æ df.empty) --- 
        if df.empty:
             raise ValueError("Excel —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏—Å—Ç–æ–≤ –∏–ª–∏ –ø—É—Å—Ç –ø–æ—Å–ª–µ —á—Ç–µ–Ω–∏—è.")
        # --- –ö–æ–Ω–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏ --- 

        all_routes_addresses = {} # –°–ª–æ–≤–∞—Ä—å: route_name -> [(row_num, address), ...]
        route_names = []          # –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω –º–∞—Ä—à—Ä—É—Ç–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Ö –ø–æ—è–≤–ª–µ–Ω–∏—è
        current_route = None
        seen_kontragents_in_route = set() # <-- –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ –≤ –¢–ï–ö–£–©–ï–ú –º–∞—Ä—à—Ä—É—Ç–µ
        
        # --- –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª --- 
        if df.empty:
             raise ValueError("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π Excel —Ñ–∞–π–ª –ø—É—Å—Ç.")
        # --- –ö–æ–Ω–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏ --- 

        # --- –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ parsing_route.py) --- 
        region_col_name = None
        address_col_name = "–ê–¥—Ä–µ—Å –¥–æ—Å—Ç–∞–≤–∫–∏"
        kontragent_col_name = None # <-- –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤
        driver_col_name = None # <--- –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ –≤–æ–¥–∏—Ç–µ–ª—è
        
        for col in df.columns:
            col_str = str(col).strip()
            if region_col_name is None and col_str.startswith("–†–µ–≥–∏–æ–Ω/–ú–∞—Ä—à—Ä—É—Ç"):
                region_col_name = col_str
            if kontragent_col_name is None and col_str.startswith("–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤"):
                 kontragent_col_name = col_str
            if driver_col_name is None and col_str.startswith("–í–æ–¥–∏—Ç–µ–ª—å"): # <--- –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É –í–æ–¥–∏—Ç–µ–ª—å
                 driver_col_name = col_str
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        missing_cols = []
        if region_col_name is None: missing_cols.append("–∫–æ–ª–æ–Ω–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å '–†–µ–≥–∏–æ–Ω/–ú–∞—Ä—à—Ä—É—Ç'")
        if address_col_name not in df.columns: missing_cols.append(f"–∫–æ–ª–æ–Ω–∫–∞ '{address_col_name}'")
        if kontragent_col_name is None: missing_cols.append("–∫–æ–ª–æ–Ω–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å '–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤'")
        if driver_col_name is None: missing_cols.append("–∫–æ–ª–æ–Ω–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å '–í–æ–¥–∏—Ç–µ–ª—å'") # <--- –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–æ–Ω–∫—É –í–æ–¥–∏—Ç–µ–ª—å
        
        if missing_cols:
             raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: { ' –∏ '.join(missing_cols) }.")
        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: '{region_col_name}', '{address_col_name}', '{kontragent_col_name}', '{driver_col_name}'") # <--- –î–æ–±–∞–≤–∏–ª–∏ –≤ –ª–æ–≥
        # --- –ö–æ–Ω–µ—Ü –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ --- 
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –≤–æ–¥–∏—Ç–µ–ª—è—Ö –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        route_data.drivers = {}
        print("  ‚ÑπÔ∏è –°–ª–æ–≤–∞—Ä—å –≤–æ–¥–∏—Ç–µ–ª–µ–π –æ—á–∏—â–µ–Ω –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞.")

        for idx, row in df.iterrows():
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
            region = row.get(region_col_name)
            address = row.get(address_col_name)
            kontragent = row.get(kontragent_col_name) # <-- –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞
            driver = row.get(driver_col_name) # <--- –ü–æ–ª—É—á–∞–µ–º –≤–æ–¥–∏—Ç–µ–ª—è
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
            is_new_route_marker = False
            if pd.notna(region) and isinstance(region, str) and region.strip():
                potential_new_route = region.strip()
                if pd.isna(address) or not str(address).strip() or current_route is None or potential_new_route != current_route:
                     is_new_route_marker = True
                     current_route = potential_new_route
                     if current_route not in route_names: # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è –ù–ï–ü–£–°–¢–´–• –º–∞—Ä—à—Ä—É—Ç–æ–≤
                         route_names.append(current_route)
                     if current_route not in all_routes_addresses:
                         all_routes_addresses[current_route] = []
                     seen_kontragents_in_route.clear() # <-- –û—á–∏—â–∞–µ–º —Å–µ—Ç –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
                     # driver_found_for_current_route = False # <-- –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ (–ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–¥—Ä–µ—Å –∫ –¢–ï–ö–£–©–ï–ú–£ –º–∞—Ä—à—Ä—É—Ç—É, –µ—Å–ª–∏:
            # 1. –ú–∞—Ä—à—Ä—É—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
            # 2. –ê–¥—Ä–µ—Å –µ—Å—Ç—å
            # 3. –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –µ—Å—Ç—å –∏ –æ–Ω –µ—â–µ –ù–ï –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –≤ –≠–¢–û–ú –º–∞—Ä—à—Ä—É—Ç–µ
            if current_route and pd.notna(address) and isinstance(address, str) and address.strip():
                excel_row = idx + 2 # +1 –∑–∞ 0-–∏–Ω–¥–µ–∫—Å, +1 –∑–∞ —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞
                if pd.notna(kontragent) and isinstance(kontragent, str) and kontragent.strip():
                    kontragent_key = kontragent.strip()
                    if kontragent_key not in seen_kontragents_in_route:
                        seen_kontragents_in_route.add(kontragent_key) # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ –≤ —Å–µ—Ç
                        all_routes_addresses[current_route].append((excel_row, address.strip()))
                        
                        # --- –°–û–•–†–ê–ù–ï–ù–ò–ï –í–û–î–ò–¢–ï–õ–Ø --- 
                        sanitized_route_name = sanitize_filename(current_route)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–¥–∏—Ç–µ–ª—å –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ –ò —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–æ–¥–∏—Ç–µ–ª—è –≤–∞–ª–∏–¥–Ω–æ
                        if sanitized_route_name and sanitized_route_name not in route_data.drivers:
                            if pd.notna(driver) and isinstance(driver, str) and driver.strip():
                                driver_name = driver.strip()
                                route_data.drivers[sanitized_route_name] = driver_name
                                print(f"    üßë –ù–∞–π–¥–µ–Ω –≤–æ–¥–∏—Ç–µ–ª—å –¥–ª—è '{current_route}': {driver_name}")
                        # --- –ö–û–ù–ï–¶ –°–û–•–†–ê–ù–ï–ù–ò–Ø –í–û–î–ò–¢–ï–õ–Ø ---
                        
                    # else: # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                        # print(f"  [upload] –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {excel_row}: –¥—É–±–ª—å –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ '{kontragent_key}' –≤ '{current_route}'")
                # else: # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                     # print(f"  [upload] –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {excel_row}: –Ω–µ—Ç –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ –≤ '{current_route}'")
        
        # –£–¥–∞–ª—è–µ–º –º–∞—Ä—à—Ä—É—Ç—ã –±–µ–∑ –∞–¥—Ä–µ—Å–æ–≤ –∏–∑ –æ–±–æ–∏—Ö —Å–ø–∏—Å–∫–æ–≤
        route_names = [r for r in route_names if all_routes_addresses.get(r)]
        all_routes_addresses = {r: adds for r, adds in all_routes_addresses.items() if adds}

        if not route_names:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ —Å –∞–¥—Ä–µ—Å–∞–º–∏ –≤ —Ñ–∞–π–ª–µ.")
            
        print(f"‚úÖ –í —Ñ–∞–π–ª–µ –Ω–∞–π–¥–µ–Ω–æ –º–∞—Ä—à—Ä—É—Ç–æ–≤ —Å –∞–¥—Ä–µ—Å–∞–º–∏: {len(route_names)}")
        
        # --- –°–æ—Ö—Ä–∞–Ω—è–µ–º route_data —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –≤–æ–¥–∏—Ç–µ–ª—è–º–∏ –ü–ï–†–ï–î –∑–∞–ø—É—Å–∫–æ–º –ø–∞—Ä—Å–∏–Ω–≥–∞ --- 
        if route_data.drivers: # –°–æ—Ö—Ä–∞–Ω—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –≤–æ–¥–∏—Ç–µ–ª—è
            print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º route_data —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–æ–¥–∏—Ç–µ–ª—è—Ö...")
            route_data.save_to_disk()
        # -----------------------------------------------------------------------------
        
        # --- –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –∫–µ—à–∞ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ --- 
        print("\nüßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞...")
        routes_cleaned_count = 0
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—á–∏—Å—Ç–∫—É summary CSV, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        summary_csv_path = os.path.join(SUMMARY_CSV_FOLDER, "current_summary.csv")
        # –û—á–∏—â–∞–µ–º –µ–≥–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ –¥–æ —ç—Ç–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞
        # (–õ—É—á—à–µ –æ—á–∏—â–∞—Ç—å –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤)
        # if os.path.exists(summary_csv_path):
        #     try:
        #         os.remove(summary_csv_path)
        #         print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–≤–æ–¥–∫–∏: {os.path.basename(summary_csv_path)}")
        #     except OSError as e:
        #         print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {summary_csv_path}: {e}")

        for route_name_to_clean in route_names:
            file_name = sanitize_filename(route_name_to_clean)
            if not file_name:
                 continue
                 
            # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            parsed_path = os.path.join(PARSED_ADDRESSES_FOLDER, f"parsed_addresses_{file_name}.csv")
            geocoded_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{file_name}.csv")
            route_results_path = os.path.join(ROUTE_RESULTS_FOLDER, f"route_results_{file_name}.json")
            # --- –î–û–ë–ê–í–õ–ï–ù–û: –ü—É—Ç–∏ –∫ JSON —Ñ–∞–π–ª–∞–º –æ—Ç –ø–µ—Ä–µ—Å—á–µ—Ç–∞ ---
            geocoded_recalc_json_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"{file_name}_geocoded.json")
            distance_recalc_json_path = os.path.join(ROUTE_RESULTS_FOLDER, f"{file_name}_distance_data.json")
            # --- –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø ---
            
            files_to_delete = [
                 parsed_path,
                 geocoded_path,
                 route_results_path,
                 geocoded_recalc_json_path, # –î–æ–±–∞–≤–ª—è–µ–º JSON –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                 distance_recalc_json_path # –î–æ–±–∞–≤–ª—è–µ–º JSON –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            ]
            deleted_something_for_route = False

            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
            for file_path in files_to_delete:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {os.path.basename(file_path)} (–¥–ª—è '{route_name_to_clean}')")
                        deleted_something_for_route = True
                except OSError as e:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –∫–µ—à–∞ (summary –∏ routes)
            cache_key = sanitize_filename(route_name_to_clean) # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ –∂–µ —Å–∞–º–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            route_popped = route_data.routes.pop(cache_key, None)
            summary_popped = route_data.summary.pop(cache_key, None)
            
            if route_popped is not None:
                 print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å –∏–∑ route_data.routes –¥–ª—è '{route_name_to_clean}'")
                 deleted_something_for_route = True
            if summary_popped is not None:
                 print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å –∏–∑ route_data.summary –¥–ª—è '{route_name_to_clean}'")
                 deleted_something_for_route = True
                 
            if deleted_something_for_route:
                routes_cleaned_count += 1

        if routes_cleaned_count > 0:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π route_data...")
            route_data.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–µ—à–µ (—É–¥–∞–ª–µ–Ω–∏–µ)
        else:
            print("‚ÑπÔ∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—á–∏—Å—Ç–∫–∏.")
            
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ï –∏–º–µ–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ –¢–ï–ö–£–©–ï–ì–û —Ñ–∞–π–ª–∞
        routes_file = os.path.join(DATA_FOLDER, "original_route_names.json")
        with open(routes_file, 'w', encoding='utf-8') as f:
            json.dump({"routes": route_names}, f, ensure_ascii=False, indent=2)
        print(f"üíæ –ê–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {os.path.basename(routes_file)}")
        
        # --- –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ --- 
        all_exceptions = []
        processed_route_names = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤
        parsing_failed_routes = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤, –≥–¥–µ –ø–∞—Ä—Å–∏–Ω–≥ —É–ø–∞–ª
        print("\nüöö –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –º–∞—Ä—à—Ä—É—Ç–æ–≤...")
        
        # --- –®–ê–ì 1: –¢–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥ –∏ —Å–±–æ—Ä –∏—Å–∫–ª—é—á–µ–Ω–∏–π --- 
        for route_name in route_names:
            addresses_with_rows = all_routes_addresses[route_name]
            print(f"\n--- –ü–∞—Ä—Å–∏–Ω–≥ –º–∞—Ä—à—Ä—É—Ç–∞: {route_name} ---")
            
            # 1. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ LLM
            print(f"  üí¨ –ó–∞–ø—É—Å–∫ parsing_route.py...")
            openrouter_key = os.getenv("OPENROUTER_API_KEY", "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")
            if not openrouter_key:
                print("  ‚ùå –û–®–ò–ë–ö–ê: –ö–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω (OPENROUTER_API_KEY).")
                raise ValueError("–ö–ª—é—á OpenRouter API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

            parsing_cmd = [
                 sys.executable, 
                 os.path.abspath(os.path.join(BASE_DIR, "..", "parsing_route.py")),
                 "--excel", path_to_read,
                 "--openrouter_key", openrouter_key, 
                 "--model", "google/gemini-flash-1.5",
                 "--route", route_name
            ]
            cmd_str = ' '.join(parsing_cmd)
            print(f"  –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É: {cmd_str}")
            parsing_result = subprocess.run(parsing_cmd, capture_output=True, text=True, cwd=ROOT_DIR)
            
            if parsing_result.returncode != 0:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è parsing_route.py –¥–ª—è '{route_name}'")
                print(f"  Stderr:\n{parsing_result.stderr}")
                parsing_failed_routes.append(route_name) # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ –ø–∞—Ä—Å–∏–Ω–≥ —É–ø–∞–ª
                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä –∏—Å–∫–ª—é—á–µ–Ω–∏–π –¥–ª—è —ç—Ç–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
            else:
                print(f"  ‚úÖ parsing_route.py –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
                # --- –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê –ò–°–ö–õ–Æ–ß–ï–ù–ò–ô –ò–ó STDOUT --- 
                lines = parsing_result.stdout.splitlines()
                route_exceptions = [] # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                
                for line in lines:
                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ù–û–í–û–ú–£ —Ñ–æ—Ä–º–∞—Ç—É –≤—ã–≤–æ–¥–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                    match = re.match(r"–ú–∞—Ä—à—Ä—É—Ç\s+'(.*?)',\s+–°—Ç—Ä–æ–∫–∞\s+(\d+):\s*(.*)", line.strip(), re.IGNORECASE)
                    if match:
                        route_nm_parsed = match.group(1).strip()
                        row_num_str = match.group(2)
                        original_address_parsed = match.group(3).strip()
                        
                        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –ø–æ –∫—Ä–∞—è–º –∞–¥—Ä–µ—Å–∞
                        if (original_address_parsed.startswith("'") and original_address_parsed.endswith("'")) or \
                           (original_address_parsed.startswith('"') and original_address_parsed.endswith('"')):
                            original_address_parsed = original_address_parsed[1:-1]
                        
                        try:
                            row_num = int(row_num_str)
                            # –ò—â–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≠–¢–û–ì–û –º–∞—Ä—à—Ä—É—Ç–∞
                            # –í–∞–∂–Ω–æ: route_name –∑–¥–µ—Å—å - —ç—Ç–æ –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∏–∑ —Ç–µ–∫—É—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –≤–Ω–µ—à–Ω–µ–≥–æ —Ü–∏–∫–ª–∞!
                            # –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π addresses_with_rows –¥–ª—è route_nm_parsed
                            current_route_addresses_rows = all_routes_addresses.get(route_nm_parsed)
                            if current_route_addresses_rows:
                                original_address_excel = next((addr for r, addr in current_route_addresses_rows if r == row_num), original_address_parsed)
                            else:
                                original_address_excel = original_address_parsed # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞
                                
                            route_exceptions.append({
                                "row": row_num,
                                "address": original_address_excel,
                                "route": route_nm_parsed, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞
                                "corrected": ""
                            })
                            print(f"    ‚úÖ [–ò–∑ stdout] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: –ú–∞—Ä—à—Ä—É—Ç '{route_nm_parsed}', –°—Ç—Ä–æ–∫–∞ {row_num}, –ê–¥—Ä–µ—Å: '{original_address_excel}'")
                        except ValueError:
                            print(f"    ‚ö†Ô∏è [–ò–∑ stdout] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –≤ –∏—Å–∫–ª—é—á–µ–Ω–∏–∏: {line.strip()}")
                        except Exception as e_inner:
                             print(f"    ‚ö†Ô∏è [–ò–∑ stdout] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è '{line.strip()}': {e_inner}")
                             
                # –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–∏–∑ route_exceptions) –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                all_exceptions.extend(route_exceptions)
                # --- –ö–û–ù–ï–¶ –û–ë–ù–û–í–õ–ï–ù–ù–û–ô –õ–û–ì–ò–ö–ò –ü–ê–†–°–ò–ù–ì–ê --- 

        # --- –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏ —Ä–µ—à–µ–Ω–∏–µ --- 
        if all_exceptions:
            print("\n‚ùóÔ∏è –ù–∞–π–¥–µ–Ω—ã –∞–¥—Ä–µ—Å–∞, —Ç—Ä–µ–±—É—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏. –û—Ç–ø—Ä–∞–≤–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥.")
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –ù–ï –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ/—Ä–∞—Å—á–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            return JSONResponse({
                "status": "needs_correction", 
                "exceptions": all_exceptions,
                "routes": route_names # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –∏–º–µ–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤, —á—Ç–æ–±—ã —Å–µ–ª–µ–∫—Ç–æ—Ä –æ–±–Ω–æ–≤–∏–ª—Å—è
            })
        else:
            print("\n‚úÖ –ê–¥—Ä–µ—Å–∞ –Ω–µ —Ç—Ä–µ–±—É—é—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å—á–µ—Ç...")
            # –ï—Å–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –ù–ï–¢, –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å—á–µ—Ç –¥–ª—è –í–°–ï–• –º–∞—Ä—à—Ä—É—Ç–æ–≤
            # (–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ, –≥–¥–µ —É–ø–∞–ª –ø–∞—Ä—Å–∏–Ω–≥, –µ—Å–ª–∏ —Ç–∞–∫–∏–µ –±—ã–ª–∏)
            for route_name in route_names:
                if route_name in parsing_failed_routes:
                    print(f"  ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è/—Ä–∞—Å—á–µ—Ç–∞ –¥–ª—è '{route_name}', —Ç.–∫. –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è.")
                    continue
                
                print(f"\n--- –ì–µ–æ–∫–æ–¥+–†–∞—Å—á–µ—Ç –¥–ª—è: {route_name} ---")
                process_success = process_route(route_name) 
                if process_success:
                    print(f"  ‚úÖ –ú–∞—Ä—à—Ä—É—Ç '{route_name}' —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
                    processed_route_names.append(route_name)
                else:
                    print(f"  ‚ö†Ô∏è –ú–∞—Ä—à—Ä—É—Ç '{route_name}' –Ω–µ –±—ã–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω (–æ—à–∏–±–∫–∞ –≤ process_route).")
            
            # –û—á–∏—â–∞–µ–º CSV —Å–≤–æ–¥–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã
            if processed_route_names and os.path.exists(summary_csv_path):
                 try:
                     os.remove(summary_csv_path)
                     print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–≤–æ–¥–∫–∏: {os.path.basename(summary_csv_path)} (—Ç.–∫. –µ—Å—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)")
                 except OSError as e:
                     print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {summary_csv_path}: {e}")
                     
            print("\nüèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π).")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å processed –∏ —Å–ø–∏—Å–æ–∫ –£–°–ü–ï–®–ù–û –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤
            return JSONResponse({
                "status": "processed", 
                "exceptions": [], # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                "routes": processed_route_names 
            })

    except ValueError as ve:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ (ValueError): {ve}")
        # import traceback # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        # traceback.print_exc()
        return JSONResponse(status_code=400, content={"error": "–û—à–∏–±–∫–∞ –≤ –¥–∞–Ω–Ω—ã—Ö Excel", "details": str(ve)})
    except subprocess.CalledProcessError as cpe:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –ø–æ–¥–ø—Ä–æ—Ü–µ—Å—Å–∞: {cpe}")
        print(f"   Stderr: {cpe.stderr}")
        return JSONResponse(status_code=500, content={"error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä—à—Ä—É—Ç–∞", "details": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–∏–Ω –∏–∑ —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."}) 
    except Exception as e:
        print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        import traceback # –í–∞–∂–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞", "details": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞."}) 
    
    finally:
        # --- –®–ê–ì 3.5: –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ --- 
        print("--- [Finally] –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ --- ")
        # –£–¥–∞–ª—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
        if corrected_path and os.path.exists(corrected_path):
             try:
                 os.remove(corrected_path)
                 print(f"INFO: [Finally] –£–¥–∞–ª–µ–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {corrected_path}")
             except Exception as e_fin_corr:
                 print(f"WARNING: [Finally] –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {corrected_path}: {e_fin_corr}")
        
        # –í—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∑–∫–∏
        if temp_upload_path and os.path.exists(temp_upload_path):
             try:
                 os.remove(temp_upload_path)
                 print(f"INFO: [Finally] –£–¥–∞–ª–µ–Ω –∏—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {temp_upload_path}")
             except Exception as e_fin_orig:
                 print(f"WARNING: [Finally] –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {temp_upload_path}: {e_fin_orig}")
        # --- –ö–æ–Ω–µ—Ü –®–∞–≥–∞ 3.5 --- 

@app.post("/api/submit-corrections")
async def submit_corrections(data: dict = Body(...)):
    corrections = data.get("corrections", [])
    print("üì• –ü–æ–ª—É—á–µ–Ω—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:", corrections)

    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º –ø–æ *–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É* route_name –∏ excel_row
    corrections_map = {}
    original_names_map = {} # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É
    routes_to_process_normalized = set() # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

    for corr in corrections:
        original_route = corr.get("route", "")
        if not original_route:
            continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–µ–∑ –∏–º–µ–Ω–∏ –º–∞—Ä—à—Ä—É—Ç–∞
            
        normalized_route = sanitize_filename(original_route)
        if not normalized_route:
             continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –∏–º—è —Å—Ç–∞–ª–æ –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
             
        routes_to_process_normalized.add(normalized_route)
        original_names_map[normalized_route] = original_route # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è
        
        row_num_str = str(corr["row"])
        if normalized_route not in corrections_map:
            corrections_map[normalized_route] = {}
        corrections_map[normalized_route][row_num_str] = corr["corrected"]

    # --- Loop 1: Modify parsed_addresses_*.csv files --- 
    processed_routes_in_loop1 = set()
    for normalized_route in routes_to_process_normalized:
        original_name = original_names_map[normalized_route]
        parsed_path = os.path.join(PARSED_ADDRESSES_FOLDER, f"parsed_addresses_{normalized_route}.csv")
        
        if not os.path.exists(parsed_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª {parsed_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ '{original_name}' –≤ —Ü–∏–∫–ª–µ 1")
            continue

        try:
            with open(parsed_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                rows = list(reader)
                fieldnames = reader.fieldnames or ["excel_row", "route_name", "normalized_address"]

            # –í–Ω–æ—Å–∏–º –ø—Ä–∞–≤–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
            route_corrections_for_file = corrections_map.get(normalized_route, {})
            modified = False
            for row in rows:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ CSV –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                row_original_name = row.get('route_name')
                if sanitize_filename(row_original_name) == normalized_route:
                    row_num_str = row.get("excel_row")
                    if row_num_str in route_corrections_for_file:
                        corrected_address = route_corrections_for_file[row_num_str]
                        if row.get('normalized_address') != corrected_address:
                             print(f"‚úèÔ∏è [–§–∞–π–ª {original_name}] –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É {row_num_str}: '{row.get('normalized_address')}' -> '{corrected_address}'")
                             row['normalized_address'] = corrected_address
                             modified = True
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            if modified:
                with open(parsed_path, "w", encoding="utf-8", newline="") as f:
                      writer = csv.DictWriter(f, fieldnames=fieldnames)
                      writer.writeheader()
                      writer.writerows(rows)
                      print(f"üíæ –§–∞–π–ª {parsed_path} –æ–±–Ω–æ–≤–ª–µ–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏.")
                 
            processed_routes_in_loop1.add(normalized_route) # –û—Ç–º–µ—á–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {parsed_path}: {e}")

    # --- Loop 2: Geocode and Calculate Distance FOR ALL ROUTES --- 
    print("\n--- –ó–∞–ø—É—Å–∫ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –í–°–ï–• –º–∞—Ä—à—Ä—É—Ç–æ–≤ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π ---")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ü–û–õ–ù–´–ô —Å–ø–∏—Å–æ–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞
    try:
        with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
            original_names_data = json.load(f)
            all_original_route_names = original_names_data.get("routes", [])
            print(f"  –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –º–∞—Ä—à—Ä—É—Ç—ã: {', '.join(all_original_route_names)}")
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ original_route_names.json: {e}")
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å, –ø—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ö–æ—Ç—è –±—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
        all_original_route_names = [original_names_map[norm_name] for norm_name in routes_to_process_normalized if norm_name in original_names_map]
        print(f"  ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤: {', '.join(all_original_route_names)}")
        if not all_original_route_names:
             return JSONResponse(status_code=500, content={"error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏", "details": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π."}) 

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –í–°–ï –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    for original_name in all_original_route_names:
        normalized_route = sanitize_filename(original_name)
        if not normalized_route: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –∏–º—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

        parsed_path = os.path.join(PARSED_ADDRESSES_FOLDER, f"parsed_addresses_{normalized_route}.csv")
        geocoded_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{normalized_route}.csv")

        if not os.path.exists(parsed_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª {os.path.basename(parsed_path)} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ '{original_name}' –≤ —Ü–∏–∫–ª–µ 2. –ü—Ä–æ–ø—É—Å–∫.")
            continue
        
        # –í—ã–∑—ã–≤–∞–µ–º process_route, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∏ –≥–µ–æ–∫–æ–¥, –∏ —Ä–∞—Å—á–µ—Ç, –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ route_data
        print(f"\n--- –û–±—Ä–∞–±–æ—Ç–∫–∞ (process_route): {original_name} ---")
        try:
            process_success = process_route(original_name)
            if process_success:
                 print(f"‚úÖ –ú–∞—Ä—à—Ä—É—Ç '{original_name}' —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —á–µ—Ä–µ–∑ process_route.")
            else:
                 print(f"‚ö†Ô∏è –ú–∞—Ä—à—Ä—É—Ç '{original_name}' –Ω–µ –±—ã–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω —á–µ—Ä–µ–∑ process_route.")
        except Exception as e_proc:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ process_route –¥–ª—è '{original_name}': {e_proc}")
            # import traceback # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏
            # traceback.print_exc()

    # –ü–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞)
    try:
        routes_response = get_routes() # get_routes —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
        routes_list = routes_response.get("routes", [])
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤: {str(e)}")
        routes_list = []
        
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å –æ–± —É—Å–ø–µ—à–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
    return JSONResponse(status_code=200, content={"status": "saved", "routes": routes_list})

@app.post("/api/summary/update")
async def update_summary_endpoint(data: dict = Body(...)):
    original_route_name = data.get("route_name")
    report_distance = data.get("report_distance")
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç—á–µ—Ç–∞
    report_hours = data.get("report_duration_hours")
    report_minutes = data.get("report_duration_minutes")
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
    comment = data.get("comment")

    # !!! –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ service_time_per_stop_minutes –ù–ï –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –∏ –ù–ï –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ update_summary_item !!!
    # –≠—Ç–æ –ø–æ–ª–µ —Ç–µ–ø–µ—Ä—å –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ /api/upload

    # <<< –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö >>>
    print(f"--- Received /api/summary/update for: {original_route_name}")
    print(f"    report_distance: '{report_distance}'")
    print(f"    report_duration_hours: '{report_hours}'")
    print(f"    report_duration_minutes: '{report_minutes}'")
    print(f"    comment: '{comment}'")
    # <<< –ö–æ–Ω–µ—Ü –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è >>>

    if not original_route_name:
        raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞")

    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ route_data, –≤—ã–∑—ã–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—é –¢–û–õ–¨–ö–û —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç—á–µ—Ç–∞
    updated = route_data.update_summary_item(
        name=original_route_name,
        report_distance=report_distance,
        report_hours=report_hours,
        report_minutes=report_minutes,
        comment=comment
        # service_time_per_stop_minutes –ù–ï –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è
    )

    if updated:
        # CSV –ø–æ–∫–∞ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –ø–æ –≤–∞—à–µ–º—É —É–∫–∞–∑–∞–Ω–∏—é
        # csv_path = save_summary_to_csv(route_data.summary)
        # print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {csv_path}")
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è '{original_route_name}' –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ –ø–∞–º—è—Ç–∏.")
    else:
        print(f"‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ '{original_route_name}' –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å.")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ–π —Å–≤–æ–¥–∫–∏
    summary_response = get_summary_endpoint() # –í—ã–∑—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å "ok" –∫ –æ—Ç–≤–µ—Ç—É –æ—Ç get_summary_endpoint
    return {"status": "ok", **summary_response}

# --- –ù–û–í–´–ô ENDPOINT –î–õ–Ø –≠–ö–°–ü–û–†–¢–ê –°–í–û–î–ö–ò --- 
@app.post("/api/export-summary")
async def export_summary_endpoint():
    print("-- Export summary requested --")
    global route_data
    if not route_data or not route_data.summary:
        print("   No summary data found for export.")
        raise HTTPException(status_code=404, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏.")
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ get_summary() —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ route_data
        summary_data = route_data.get_summary() # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Å–∞–º –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ
        print(f"   Got {len(summary_data)} items for summary export.")

        if not summary_data:
             print("   get_summary() returned empty data.")
             raise HTTPException(status_code=404, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏ (–º–µ—Ç–æ–¥ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ).")

        summary_values_list = list(summary_data.values())
        if not summary_values_list:
            print("   Summary dictionary is empty after getting values.")
            raise HTTPException(status_code=404, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏ (—Å–ª–æ–≤–∞—Ä—å –ø—É—Å—Ç).")

        df = pd.DataFrame(summary_values_list)

        # --- –°–û–†–¢–ò–†–û–í–ö–ê DataFrame –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É –º–∞—Ä—à—Ä—É—Ç–æ–≤ --- 
        original_route_order = []
        try:
            with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
                original_names_data = json.load(f)
                original_route_order = original_names_data.get("routes", [])
            
            if original_route_order and 'original_name' in df.columns:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É original_name –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø —Å –Ω—É–∂–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º
                df['original_name'] = pd.Categorical(df['original_name'], categories=original_route_order, ordered=True)
                df = df.sort_values('original_name')
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                df = df.reset_index(drop=True)
                print(f"   DataFrame –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É: {original_route_order}")
            else:
                print("   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DataFrame –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É (—Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç –∏–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ original_name).")
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏/—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ –ø–æ original_route_names.json: {e}")
        # --- –ö–û–ù–ï–¶ –°–û–†–¢–ò–†–û–í–ö–ò --- 

        # --- –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –í–†–ï–ú–ï–ù–ò –û–¢–ß–ï–¢–ê --- 
        def format_report_time(row):
            hours = row.get('report_duration_hours')
            minutes = row.get('report_duration_minutes')
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN/None –∫–∞–∫ 0, –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ None
            has_hours = hours is not None and pd.notna(hours)
            has_minutes = minutes is not None and pd.notna(minutes)
            
            if not has_hours and not has_minutes:
                return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, –µ—Å–ª–∏ –æ–±–∞ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
                
            h = int(hours) if has_hours else 0
            m = int(minutes) if has_minutes else 0
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, —Ö–æ—Ç—è –Ω–∞ –±—ç–∫–µ —É–∂–µ –µ—Å—Ç—å)
            if h < 0: h = 0
            if m < 0: m = 0
            if m >= 60: m = 59 
            
            return f"{h} —á {m} –º–∏–Ω"

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏
        if 'report_duration_hours' in df.columns and 'report_duration_minutes' in df.columns:
            df['report_duration_formatted'] = df.apply(format_report_time, axis=1)
            print("   Column 'report_duration_formatted' created.")
        else:
             print("   Warning: Columns 'report_duration_hours' or 'report_duration_minutes' not found in df. Skipping report time formatting.")
             df['report_duration_formatted'] = None # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ –Ω–∏–∂–µ
        # --- –ö–û–ù–ï–¶ –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø --- 

        # --- –í—ã–±–∏—Ä–∞–µ–º –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ --- 
        columns_to_export = {
            "original_name": "–ú–∞—Ä—à—Ä—É—Ç",
            "driver_name": "–§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è",
            "distance": "–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º)",
            "total_route_time_formatted": "–í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ",
            "report_distance": "–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç—á–µ—Ç)",
            "report_duration_formatted": "–í—Ä–µ–º—è (–æ—Ç—á–µ—Ç)", # <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É
            "distance_difference": "–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)",
            "time_difference_formatted": "–†–∞–∑–Ω–∏—Ü–∞ (–≤—Ä–µ–º—è)",
            "number_of_stops": "–ö–æ–ª-–≤–æ —Ç–æ—á–µ–∫",
            "comment": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –ø–µ—Ä–µ–¥ —ç–∫—Å–ø–æ—Ä—Ç–æ–º
        export_df = pd.DataFrame()
        ordered_columns = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        for original_col, new_name in columns_to_export.items():
            ordered_columns.append(new_name) # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –∫–∞–∫ –æ–Ω–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ
            if original_col in df.columns:
                export_df[new_name] = df[original_col]
            else:
                print(f"   Warning: Column '{original_col}' not found in summary data for export.")
                export_df[new_name] = None # –ò–ª–∏ pd.NA –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ DataFrame
        export_df = export_df[ordered_columns]
        # --- –ö–û–ù–ï–¶ –í–´–ë–û–†–ê –ö–û–õ–û–ù–û–ö --- 
        
        # --- –û—á–∏—Å—Ç–∫–∞ —è—á–µ–µ–∫ —Ä–∞–∑–Ω–∏—Ü—ã, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞ --- 
        export_df_copy = export_df.copy()

        export_df_copy.loc[pd.isna(export_df_copy['–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç—á–µ—Ç)']), '–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)'] = None

        report_time_is_empty_in_source = pd.isna(df['report_duration_hours']) & pd.isna(df['report_duration_minutes'])
        export_df_copy.loc[report_time_is_empty_in_source.values, '–†–∞–∑–Ω–∏—Ü–∞ (–≤—Ä–µ–º—è)'] = None # –ò—Å–ø–æ–ª—å–∑—É–µ–º .values –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
        
        export_df = export_df_copy 
        # --- –ö–æ–Ω–µ—Ü –æ—á–∏—Å—Ç–∫–∏ --- 

        print(f"   DataFrame prepared for export with columns: {list(export_df.columns)}")

        # 2. –°–æ–∑–¥–∞–µ–º Excel –≤ –ø–∞–º—è—Ç–∏
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            export_df.to_excel(writer, index=False, sheet_name='–°–≤–æ–¥–∫–∞')
            
            # --- –°–¢–ò–õ–ò–ó–ê–¶–ò–Ø --- 
            workbook = writer.book
            worksheet = writer.sheets['–°–≤–æ–¥–∫–∞']
            
            # –£—Å–ª–æ–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            light_red_fill = PatternFill(start_color='FFFFCCCC', end_color='FFFFCCCC', fill_type='solid')
            DISTANCE_THRESHOLD = -40
            TIME_THRESHOLD_SECONDS = -5400 # -1 —á–∞—Å 30 –º–∏–Ω—É—Ç
            
            for row_idx in range(2, worksheet.max_row + 1):
                df_idx = row_idx - 2
                try:
                    dist_diff_val = df.loc[df_idx, 'distance_difference']
                    time_diff_sec_val = df.loc[df_idx, 'time_difference_seconds']
                    highlight_row = False
                    if dist_diff_val is not None and pd.notna(dist_diff_val):
                        if float(dist_diff_val) <= DISTANCE_THRESHOLD: highlight_row = True
                    if not highlight_row and time_diff_sec_val is not None and pd.notna(time_diff_sec_val):
                         if int(time_diff_sec_val) <= TIME_THRESHOLD_SECONDS: highlight_row = True
                    if highlight_row:
                        for col_idx in range(1, worksheet.max_column + 1):
                            worksheet.cell(row=row_idx, column=col_idx).fill = light_red_fill
                except (KeyError, IndexError, ValueError, TypeError) as fmt_err:
                     print(f"   Warning: Skipping conditional formatting for row {row_idx} due to error: {fmt_err}")
            print(f"   Conditional formatting applied.")

            # –ì—Ä–∞–Ω–∏—Ü—ã
            thin_black_border = Border(left=Side(style='thin', color='FF000000'), right=Side(style='thin', color='FF000000'), top=Side(style='thin', color='FF000000'), bottom=Side(style='thin', color='FF000000'))
            thin_gray_border = Border(left=Side(style='thin', color='FFA9A9A9'), right=Side(style='thin', color='FFA9A9A9'), top=Side(style='thin', color='FFA9A9A9'), bottom=Side(style='thin', color='FFA9A9A9'))
            for cell in worksheet["1:1"]: cell.border = thin_black_border
            for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column): 
                for cell in row: cell.border = thin_gray_border
            print(f"   Borders applied.")

            # –®–∏—Ä–∏–Ω–∞ –∏ –ø–µ—Ä–µ–Ω–æ—Å
            column_widths_px = {
                '–ú–∞—Ä—à—Ä—É—Ç': 380, '–§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è': 300, '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º)': 140,
                '–í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ': 140, '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç—á–µ—Ç)': 140, '–í—Ä–µ–º—è (–æ—Ç—á–µ—Ç)': 140,
                '–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)': 120, '–†–∞–∑–Ω–∏—Ü–∞ (–≤—Ä–µ–º—è)': 120, '–ö–æ–ª-–≤–æ —Ç–æ—á–µ–∫': 120,
                '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π': 380
            }
            wrap_alignment = Alignment(wrap_text=True, vertical='top')
            for i, column_name in enumerate(export_df.columns):
                column_letter = get_column_letter(i + 1)
                width_px = column_widths_px.get(column_name, 100)
                excel_width = width_px / 9.0 
                worksheet.column_dimensions[column_letter].width = excel_width
            for row in worksheet.iter_rows(): 
                for cell in row: cell.alignment = wrap_alignment
            print(f"   Widths and wrap text applied.")
            # --- –ö–û–ù–ï–¶ –°–¢–ò–õ–ò–ó–ê–¶–ò–ò --- 

        buffer.seek(0)
        print("   Excel buffer created.")

        # 3. –ì–æ—Ç–æ–≤–∏–º –∏–º—è —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç
        # --- –õ–û–ì–ò–ö–ê –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –ò–ú–ï–ù–ò –§–ê–ô–õ–ê (–û–°–¢–ê–í–õ–Ø–ï–ú –ù–û–í–£–Æ) --- 
        filename = "summary_nodata.xlsx" # –ò–º—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        report_date_str = route_data.report_date_str # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –¥–∞—Ç—É
        print(f"   Report date string from route_data: '{report_date_str}'")
        if report_date_str:
            try:
                report_date_obj = datetime.strptime(report_date_str, "%Y-%m-%d") 
                formatted_date = report_date_obj.strftime("%d.%m.%Y")
                filename = f"summary_{formatted_date}.xlsx"
                print(f"   Generated filename with date: {filename}")
            except ValueError as e:
                print(f"   ‚ö†Ô∏è Error parsing report date '{report_date_str}': {e}. Using default filename.")
                filename = "summary_nodata.xlsx"
        else:
             print("   Report date string is empty. Using default filename.")
        # --- –ö–û–ù–ï–¶ –õ–û–ì–ò–ö–ò –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –ò–ú–ï–ù–ò –§–ê–ô–õ–ê ---

        headers = {
            'Content-Disposition': f'attachment; filename="{filename}"' # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
        }
        
        print(f"   Returning file: {filename}")
        return StreamingResponse(
            buffer,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            headers=headers
        )

    except Exception as e:
        import traceback
        print(f"!!! Error during summary export: {e}")
        print(traceback.format_exc()) # –ü–µ—á–∞—Ç–∞–µ–º –ø–æ–ª–Ω—ã–π traceback –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}")

# --- –ö–û–ù–ï–¶ ENDPOINT'–ê –≠–ö–°–ü–û–†–¢–ê ---

# --- –ù–û–í–´–ô –≠–ù–î–ü–û–ò–ù–¢ –î–õ–Ø –û–ë–ù–û–í–õ–ï–ù–ò–Ø –í–†–ï–ú–ï–ù–ò –ù–ê –¢–û–ß–ö–£ ---
class ServiceTimeUpdate(BaseModel):
    service_time: int

@app.post("/api/update-service-time")
async def update_service_time_endpoint(data: ServiceTimeUpdate):
    print(f"--- Received /api/update-service-time with: {data.service_time} min ---")
    try:
        # 1. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤–æ–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è (—Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º)
        time_updated = route_data.set_global_service_time(data.service_time)

        # 2. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ—Å—á–µ—Ç —Å–≤–æ–¥–∫–∏ –∏ –ø–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        # –ú–µ—Ç–æ–¥ get_summary —Ç–µ–ø–µ—Ä—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—é –∏ –ø–µ—Ä–µ—Å—á–µ—Ç
        updated_summary_data = route_data.get_summary()
        
        # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π /api/summary
        result = []
        for norm_name, item_data in updated_summary_data.items():
            result.append({
                "route_name": item_data.get("original_name", norm_name),
                "driver_name": item_data.get("driver_name", "‚Äî"),
                "distance": item_data.get("distance", "–ù/–î"),
                "duration_seconds": item_data.get("duration_seconds"),
                "duration": item_data.get("duration_formatted", "–ù/–î"),
                "report_distance": item_data.get("report_distance"),
                "report_duration_hours": item_data.get("report_duration_hours"),
                "report_duration_minutes": item_data.get("report_duration_minutes"),
                "distance_difference": item_data.get("distance_difference"),
                "time_difference_formatted": item_data.get("time_difference_formatted"),
                "time_difference_seconds": item_data.get("time_difference_seconds"),
                "total_route_time_seconds": item_data.get("total_route_time_seconds"),
                "total_route_time_formatted": item_data.get("total_route_time_formatted", "–ù/–î"),
                "number_of_stops": item_data.get("number_of_stops", "–ù/–î")
            })
        
        return {
            "status": "ok",
            "summary": result,
            "global_service_time_minutes": route_data.global_service_time_minutes
        }

    except Exception as e:
        print(f"‚ùå Error in /api/update-service-time: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É: {e}")
# --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –≠–ù–î–ü–û–ò–ù–¢–ê ---

# --- –ù–û–í–´–ô ENDPOINT –î–õ–Ø –ü–û–õ–£–ß–ï–ù–ò–Ø –í–°–ï–• –î–ê–ù–ù–´–• –ú–ê–†–®–†–£–¢–û–í --- 
@app.get("/api/all-route-data")
def get_all_route_data_endpoint():
    print("--- Request received for /api/all-route-data ---")
    global route_data
    all_routes_data_for_frontend = {}
    route_names = []

    # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω –º–∞—Ä—à—Ä—É—Ç–æ–≤
    try:
        with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
            original_names_data = json.load(f)
            route_names = original_names_data.get("routes", [])
        if not route_names:
             print("  original_route_names.json –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Ä—à—Ä—É—Ç–æ–≤.")
             return {}
        print(f"  –ë—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤: {route_names}")
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è original_route_names.json: {e}")
        raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤.")

    # 2. –ò—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ —Å–ø–∏—Å–∫—É –∏ —Å–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ
    for original_name in route_names:
        sanitized_name = sanitize_filename(original_name)
        if not sanitized_name: continue

        print(f"  -> –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è: {original_name}")
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É get_route_data_endpoint,
            # –Ω–æ –±–µ–∑ HTTP –∏—Å–∫–ª—é—á–µ–Ω–∏–π, —á—Ç–æ–±—ã –æ–¥–Ω–∞ –æ—à–∏–±–∫–∞ –Ω–µ —Å–ª–æ–º–∞–ª–∞ –≤—Å–µ
            single_route_data = get_route_data_endpoint(original_name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–∫–∏ –≤–Ω—É—Ç—Ä–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç get_route_data_endpoint
            if isinstance(single_route_data, dict) and not single_route_data.get("error"): 
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –∫–∞–∫ –∫–ª—é—á –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
                all_routes_data_for_frontend[original_name] = single_route_data
                print(f"     ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è '{original_name}' —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã.")
            else:
                error_msg = single_route_data.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if isinstance(single_route_data, dict) else "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞"
                print(f"     ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è '{original_name}': {error_msg}")
                # –ú–æ–∂–Ω–æ —Ä–µ—à–∏—Ç—å, –¥–æ–±–∞–≤–ª—è—Ç—å –ª–∏ –ø—É—Å—Ç—É—é –∑–∞–ø–∏—Å—å –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å
                # all_routes_data_for_frontend[original_name] = {"name": original_name, "error": True, "message": error_msg}
        except Exception as e_single:
            print(f"     ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è '{original_name}': {e_single}")
            # –ú–æ–∂–Ω–æ —Ä–µ—à–∏—Ç—å, –¥–æ–±–∞–≤–ª—è—Ç—å –ª–∏ –ø—É—Å—Ç—É—é –∑–∞–ø–∏—Å—å –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å
            # all_routes_data_for_frontend[original_name] = {"name": original_name, "error": True, "message": str(e_single)}
            
    print(f"--- /api/all-route-data: –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(all_routes_data_for_frontend)} –º–∞—Ä—à—Ä—É—Ç–æ–≤ --- ")
    return JSONResponse(content=all_routes_data_for_frontend)
# --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û ENDPOINT'–ê --- 

# --- –î–û–ë–ê–í–õ–ï–ù–û: –ú–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ—Å—á–µ—Ç–∞ ---
class RecalculatePoint(BaseModel):
    originalIndex: int
    address: str
    isOffice: bool
    isHidden: bool # –•–æ—Ç—è –∫–ª–∏–µ–Ω—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω –∏—Ö —Å–ª–∞—Ç—å, –ø—Ä–∏–º–µ–º –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    isModified: bool
    lat: Optional[float] = None
    lon: Optional[float] = None

class RecalculateRequest(BaseModel):
    routeId: str # –ò—Å–ø–æ–ª—å–∑—É–µ–º routeId, –∫–æ—Ç–æ—Ä–æ–µ –∫–ª–∏–µ–Ω—Ç –ø—Ä–∏—Å—ã–ª–∞–µ—Ç
    routeName: str # –ò–º—è –º–∞—Ä—à—Ä—É—Ç–∞, –∫–∞–∫ –æ–Ω–æ –µ—Å—Ç—å
    points: List[RecalculatePoint]

# --- –î–û–ë–ê–í–õ–ï–ù –ù–û–í–´–ô –≠–ù–î–ü–û–ò–ù–¢ –î–õ–Ø –ü–ï–†–ï–°–ß–ï–¢–ê ---
@app.post("/api/recalculate-route")
# --- –ò–ó–ú–ï–ù–ï–ù–û: –í–µ—Ä–Ω—É–ª–∏ data: RecalculateRequest --- 
async def recalculate_route_endpoint(data: RecalculateRequest):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–µ—Ä–µ—Å—á–µ—Ç –º–∞—Ä—à—Ä—É—Ç–∞ —Å –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º–∏/–¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏/—É–¥–∞–ª–µ–Ω–Ω—ã–º–∏/—Å–∫—Ä—ã—Ç—ã–º–∏ —Ç–æ—á–∫–∞–º–∏.
    """
    # --- –ò–ó–ú–ï–ù–ï–ù–û: –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞—á–∞–ª–æ –ª–æ–≥–∏–∫–∏ --- 
    print(f"--- Received recalculate request for routeId: {data.routeId} ---")
    # –ü–æ–ª—É—á–∞–µ–º routeName –∏–∑ –∑–∞–ø—Ä–æ—Å–∞, —Ç.–∫. routeId –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –∫–ª—é—á–æ–º
    route_name = data.routeName 
    sanitized_route_name = sanitize_filename(route_name)
    if not sanitized_route_name:
         raise HTTPException(status_code=400, detail="Invalid route name provided.")
    
    # --- –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç—Ç–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ ---
    geocoded_file_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"{sanitized_route_name}_geocoded.json")
    route_points_file_path = os.path.join(ROUTE_RESULTS_FOLDER, f"{sanitized_route_name}_route_points.json")
    distance_data_file_path = os.path.join(ROUTE_RESULTS_FOLDER, f"{sanitized_route_name}_distance_data.json")
    
    # --- –î–æ–±–∞–≤–ª–µ–Ω Print –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ --- 
    print(f">>> Step 1 OK: Route Name = {route_name}, Sanitized = {sanitized_route_name}")
    print(f"    Geocoded file path: {geocoded_file_path}")
    
    # --- –†–ê–°–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ --- 
    current_geocoder_output = [] # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–¥–µ—Å—å
    geocoded_data_loaded = False # –§–ª–∞–≥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏
    
    # --- –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ ---
    if os.path.exists(geocoded_file_path):
        # --- –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ JSON, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å --- 
        try:
            with open(geocoded_file_path, 'r', encoding='utf-8') as f:
                current_geocoder_output = json.load(f)
                if not isinstance(current_geocoder_output, list) or not all(isinstance(item, dict) for item in current_geocoder_output):
                     print(f"ERROR: {geocoded_file_path} does not contain a valid list of dictionaries.")
                     raise HTTPException(status_code=500, detail="Invalid format in geocoded data file (JSON).")
                print(f"Loaded {len(current_geocoder_output)} points from JSON: {geocoded_file_path}")
                geocoded_data_loaded = True
        except Exception as e:
            print(f"ERROR loading {geocoded_file_path}: {e}")
            raise HTTPException(status_code=500, detail=f"Failed to load geocoded data (JSON) for route: {route_name}")
    else:
        # --- –ï—Å–ª–∏ JSON –Ω–µ—Ç, –∏—â–µ–º –∏ —á–∏—Ç–∞–µ–º CSV --- 
        geocoded_csv_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{sanitized_route_name}.csv")
        if os.path.exists(geocoded_csv_path):
            print(f"Warning: JSON geocoded file not found. Attempting to load from CSV: {geocoded_csv_path}")
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pandas –¥–ª—è —á—Ç–µ–Ω–∏—è CSV
                df = pd.read_csv(geocoded_csv_path)
                # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ None –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å JSON/Pydantic
                df.replace({np.nan: None}, inplace=True)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                current_geocoder_output = df.to_dict('records')
                print(f"Loaded {len(current_geocoder_output)} points from CSV: {geocoded_csv_path}")
                geocoded_data_loaded = True
                # TODO: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ JSON –¥–ª—è –±—É–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤?
                # try:
                #     with open(geocoded_file_path, 'w', encoding='utf-8') as f_json:
                #         json.dump(current_geocoder_output, f_json, ensure_ascii=False, indent=4)
                #     print(f"Saved converted geocoded data to JSON: {geocoded_file_path}")
                # except Exception as e_save:
                #     print(f"Warning: Could not save converted CSV data to JSON: {e_save}")
            except Exception as e_csv:
                 print(f"ERROR loading or processing CSV file {geocoded_csv_path}: {e_csv}")
                 raise HTTPException(status_code=500, detail=f"Failed to load or process geocoded data (CSV) for route: {route_name}")
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ JSON, –Ω–∏ CSV
             raise HTTPException(status_code=404, detail=f"Geocoded data file (JSON or CSV) not found for route: {route_name}")
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
    if not geocoded_data_loaded:
         # –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å—Å—è –∏–∑-–∑–∞ HTTPException –≤—ã—à–µ, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
         print("FATAL ERROR: Geocoded data was not loaded, but no exception was raised.")
         raise HTTPException(status_code=500, detail="Internal error loading geocoded data.")

    # --- –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• --- 
    
    # --- –î–æ–±–∞–≤–ª–µ–Ω Print –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ --- 
    print(f">>> Step 2 OK: Successfully loaded geocoded data ({len(current_geocoder_output)} points).")
    
    # --- –†–ê–°–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ—á–µ–∫ –∏ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ --- 
    # --- –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ—á–∫–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ ---
    new_geocoder_output = []
    points_for_route_calculation = [] # –°–ø–∏—Å–æ–∫ (lat, lon) –¥–ª—è route_distance
    modified_indices = set() # –•—Ä–∞–Ω–∏–º –∏–Ω–¥–µ–∫—Å—ã –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    
    print(f"Processing {len(data.points)} points received from client...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ (—Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ä–∞—Å—á–µ—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤)
    # global_service_time = route_data.global_service_time_minutes * 60 # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    
    point_counter = 0
    for point_data in data.points:
        point_counter += 1
        
        if point_data.isHidden:
            print(f"  Skipping hidden point at originalIndex: {point_data.originalIndex}")
            continue
    
        geocoded_point = {
            "input": point_data.address,
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –°–¢–ê–†–¢/–§–ò–ù–ò–® –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ
            "excel_row": "–°–¢–ê–†–¢" if point_data.isOffice and point_counter == 1 else ("–§–ò–ù–ò–®" if point_data.isOffice and point_counter == len(data.points) else ""), 
            "found": None,
            "lat": point_data.lat,
            "lon": point_data.lon,
            "type": None,
            "description": None,
            # –î–æ–±–∞–≤–ª—è–µ–º originalIndex –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ
            "original_index_from_request": point_data.originalIndex 
        }
    
        needs_geocoding = point_data.isModified or (not point_data.isOffice and (point_data.lat is None or point_data.lon is None))
        
        # --- –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è –æ—Ñ–∏—Å–∞ ---
        if point_data.isOffice:
            try:
                office_loc = config.OFFICE_LOCATION
                if office_loc and "lat" in office_loc and "lon" in office_loc:
                    geocoded_point['lat'] = office_loc['lat']
                    geocoded_point['lon'] = office_loc['lon']
                    geocoded_point['found'] = True # –û—Ñ–∏—Å –≤—Å–µ–≥–¥–∞ –Ω–∞–π–¥–µ–Ω
                    geocoded_point['type'] = 'office'
                    geocoded_point['description'] = office_loc.get("name", "–û—Ñ–∏—Å –†–¢–ö")
                    print(f"  Point {point_counter} ('{point_data.address}') is Office. Set coords from config: lat={geocoded_point['lat']}, lon={geocoded_point['lon']}")
                else:
                     print(f"  WARNING: Office point {point_counter} ('{point_data.address}') - OFFICE_LOCATION not configured correctly.")
                     geocoded_point['lat'] = None
                     geocoded_point['lon'] = None
                     geocoded_point['found'] = False
            except Exception as e_office:
                print(f"  ERROR setting office coordinates for point {point_counter}: {e_office}")
                geocoded_point['lat'] = None
                geocoded_point['lon'] = None
                geocoded_point['found'] = False
        # --- –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø ---
        
        if needs_geocoding:
            print(f"  Point {point_counter} ('{point_data.address}') needs geocoding (isModified: {point_data.isModified}, isOffice: {point_data.isOffice}, lat: {point_data.lat}).")
            modified_indices.add(point_data.originalIndex)
            try:
                geocode_result = geocode_address(point_data.address)
                if geocode_result and geocode_result.get('lat') is not None and geocode_result.get('lon') is not None:
                    geocoded_point['lat'] = geocode_result['lat']
                    geocoded_point['lon'] = geocode_result['lon']
                    geocoded_point['type'] = geocode_result.get('type')
                    geocoded_point['description'] = geocode_result.get('description')
                    geocoded_point['found'] = geocode_result.get('found') # –ò—Å–ø–æ–ª—å–∑—É–µ–º found –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≥–µ–æ–∫–æ–¥–µ—Ä–∞
                    print(f"    Geocoded successfully: lat={geocoded_point['lat']}, lon={geocoded_point['lon']}, type={geocoded_point['type']}")
                else:
                    print(f"    WARNING: Geocoding failed or returned incomplete data for address: {point_data.address}")
                    geocoded_point['lat'] = None
                    geocoded_point['lon'] = None
                    geocoded_point['description'] = "‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"
                    geocoded_point['found'] = False # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
            except Exception as e:
                print(f"    ERROR during geocoding for address '{point_data.address}': {e}")
                geocoded_point['lat'] = None
                geocoded_point['lon'] = None
                geocoded_point['description'] = "‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"
                geocoded_point['found'] = False # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        else:
             # –ï—Å–ª–∏ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω—É–∂–Ω–æ, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ç–∏–ø/–æ–ø–∏—Å–∞–Ω–∏–µ –≤ –°–¢–ê–†–´–• –¥–∞–Ω–Ω—ã—Ö –ø–æ –∞–¥—Ä–µ—Å—É
             # –≠—Ç–æ –º–µ–Ω–µ–µ –Ω–∞–¥–µ–∂–Ω–æ, —á–µ–º –ø–æ –∏–Ω–¥–µ–∫—Å—É, –Ω–æ —É –Ω–∞—Å –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≤ current_geocoder_output –∏–∑ CSV
             # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ª—è –∫–∞–∫ –µ—Å—Ç—å (lat/lon –∏–∑ –∑–∞–ø—Ä–æ—Å–∞)
             original_point_from_loaded_data = next((p for p in current_geocoder_output if p.get('input') == point_data.address), None)
             if original_point_from_loaded_data:
                 geocoded_point['found'] = original_point_from_loaded_data.get('found') # –ú–æ–∂–µ—Ç –±—ã—Ç—å True/False/None
                 geocoded_point['type'] = original_point_from_loaded_data.get('type')
                 geocoded_point['description'] = original_point_from_loaded_data.get('description')
             else:
                 print(f"  Point {point_counter} ('{point_data.address}') - geocoding not needed. Using provided coords. Could not find original data by address.")
                 # –ï—Å–ª–∏ –Ω–µ –æ—Ñ–∏—Å, –Ω–æ –Ω–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç - —Å—Ç–∞–≤–∏–º –æ—à–∏–±–∫—É
                 if not point_data.isOffice and (geocoded_point['lat'] is None or geocoded_point['lon'] is None):
                      geocoded_point['description'] = "‚ö†Ô∏è –ù–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"
                      geocoded_point['found'] = False
                 elif point_data.isOffice:
                       geocoded_point['found'] = True # –°—á–∏—Ç–∞–µ–º –æ—Ñ–∏—Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º
    
        new_geocoder_output.append(geocoded_point)
    
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–∞—Ä—à—Ä—É—Ç–∞ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        if geocoded_point.get('lat') is not None and geocoded_point.get('lon') is not None:
            points_for_route_calculation.append({"lat": geocoded_point['lat'], "lon": geocoded_point['lon']})
        else:
            # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –Ω–µ –æ—Ñ–∏—Å –∏ —É –Ω–µ–µ –Ω–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç - —ç—Ç–æ –æ—à–∏–±–∫–∞, –Ω–µ–ª—å–∑—è —Å—á–∏—Ç–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç
            if not point_data.isOffice:
                print(f"ERROR: Point '{point_data.address}' has no coordinates after processing. Route calculation cannot proceed.")
                raise HTTPException(status_code=400, detail=f"–¢–æ—á–∫–∞ '{point_data.address}' –Ω–µ –∏–º–µ–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç.")
    # --- –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –¢–û–ß–ï–ö ---
    
    # --- –î–æ–±–∞–≤–ª–µ–Ω Print –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ --- 
    print(f">>> Step 3 OK: Processed {len(new_geocoder_output)} points. Points for calculation: {len(points_for_route_calculation)}.")
    
    # --- –£–î–ê–õ–ï–ù–û: –¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç --- 
    # return JSONResponse(content={"status": "ok", "message": "Step 3 reached!"})
    
    # --- –†–ê–°–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û: –†–∞—Å—á–µ—Ç –º–∞—Ä—à—Ä—É—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ --- 
    
    # --- –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –º–∞—Ä—à—Ä—É—Ç ---
    print(f"Recalculating route with {len(points_for_route_calculation)} valid points...")
    new_distance_data = None
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–æ—á–µ–∫ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π (–Ω–µ —Ç–æ–ª—å–∫–æ –æ—Ñ–∏—Å —Å—Ç–∞—Ä—Ç/—Ñ–∏–Ω–∏—à)
    if len(points_for_route_calculation) > 1:
        try:
            # –í—ã–∑—ã–≤–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            # TODO: –ü–æ–ª—É—á–∞—Ç—å traffic_mode –∏–∑ config?
            # segments = await route_distance.get_route_segments_async(points_for_route_calculation, traffic_mode='auto') 
            
            # --- –ò–ó–ú–ï–ù–ï–ù–û: –í—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é --- 
            segments = route_distance.get_route_segments(points_for_route_calculation)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–æ–º–æ—â—å—é –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            new_distance_data = format_distance_data_from_segments(segments)
            print(f"Route recalculated. Distance: {new_distance_data.get('formatted_distance')}, Duration: {new_distance_data.get('formatted_duration')}")
            
        except Exception as e:
            print(f"ERROR during route recalculation: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ä–∞—Å—á–µ—Ç–∞ –º–∞—Ä—à—Ä—É—Ç–∞, –≤–µ—Ä–Ω–µ–º –æ—à–∏–±–∫—É –∫–ª–∏–µ–Ω—Ç—É
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å—á–µ—Ç–µ –º–∞—Ä—à—Ä—É—Ç–∞: {e}")
    else:
        print("Skipping route calculation: Not enough valid points.")
        # –ï—Å–ª–∏ —Ç–æ—á–µ–∫ –º–∞–ª–æ, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏
        new_distance_data = {
            "segments": [],
            "total_distance": 0,
            "total_duration": 0,
            "formatted_distance": "0 –∫–º",
            "formatted_duration": "0 –º–∏–Ω"
        }

    # --- –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ --- 
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ù–û–í–´–ô geocoder_output (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π JSON –∏–ª–∏ CSV)
        with open(geocoded_file_path, 'w', encoding='utf-8') as f:
            json.dump(new_geocoder_output, f, ensure_ascii=False, indent=4)
        print(f"Saved updated geocoded data to: {geocoded_file_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ù–û–í–´–ï –¥–∞–Ω–Ω—ã–µ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª distance_data.json, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if os.path.exists(distance_data_file_path):
            os.remove(distance_data_file_path)
            print(f"Removed old distance data file: {distance_data_file_path}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if new_distance_data:
             with open(distance_data_file_path, 'w', encoding='utf-8') as f:
                 json.dump(new_distance_data, f, ensure_ascii=False, indent=4)
             print(f"Saved new distance data to: {distance_data_file_path}")
        
        # TODO: –û–±–Ω–æ–≤–∏—Ç—å route_points.json? –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è. –ú–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π.
        if os.path.exists(route_points_file_path):
            try:
                 os.remove(route_points_file_path)
                 print(f"Removed old route points file: {route_points_file_path}")
            except Exception as e_del_rp:
                 print(f"Warning: could not remove old route_points file: {e_del_rp}")
                 
    except Exception as e_save:
        print(f"ERROR saving updated route data: {e_save}")
        # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É

    # --- –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–º RouteData –∏ summary --- 
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –∫–∞–∫ –∏—Ö —Ö—Ä–∞–Ω–∏—Ç RouteData.add_route
    updated_route_full_data = {
        "route_name": route_name, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è
        "geocoder_output": new_geocoder_output,
        "route_points": points_for_route_calculation, # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ lat/lon
        "distance_data": new_distance_data,
        "number_of_stops": len(points_for_route_calculation) - 2, # –í—ã—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ä—Ç/—Ñ–∏–Ω–∏—à –¥–ª—è —Å–≤–æ–¥–∫–∏
        "total_route_time_formatted": new_distance_data.get("formatted_duration", "–ù/–î"), # –î–ª—è get_route_data_endpoint
        "global_service_time_minutes": route_data.global_service_time_minutes # –î–ª—è get_route_data_endpoint
    }
    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ RouteData (—ç—Ç–æ —Ç–∞–∫–∂–µ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ—Ç summary –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –¥–ª—è add_route
    route_data.add_route(route_name, updated_route_full_data)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (add_route –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–∞–º)
    route_data.save_to_disk()
    print(f"Updated route data in memory and saved for: {route_name}")
    
    # --- –î–û–ë–ê–í–õ–ï–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å–≤–æ–¥–∫—É ---
    try:
        print("Updating overall summary after recalculation...")
        route_data.get_summary() # –≠—Ç–æ—Ç –≤—ã–∑–æ–≤ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç route_summary.json
        print("Overall summary updated.")
    except Exception as e_summary_update:
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –æ—Ç–≤–µ—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É
        print(f"ERROR updating overall summary after recalculation: {e_summary_update}")
    # --- –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø ---

    # --- –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ --- 
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —á—Ç–æ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    final_response = {
        "status": "recalculated",
        "route_name": route_name,
        "geocoder_output": new_geocoder_output, # –ü–µ—Ä–µ–¥–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π geocoder output
        "route_points": points_for_route_calculation, # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–æ—á–∫–∏ –¥–ª—è –∫–∞—Ä—Ç—ã
        "distance_data": new_distance_data, # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏
        # –ë–µ—Ä–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ summary
        "number_of_stops": route_data.summary.get(sanitized_route_name, {}).get("number_of_stops", 0),
        "total_route_time_formatted": route_data.summary.get(sanitized_route_name, {}).get("total_route_time_formatted", "–ù/–î"),
        "global_service_time_minutes": route_data.global_service_time_minutes
    }
    
    return JSONResponse(content=final_response)
    
    # --- –ö–û–ù–ï–¶ –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–ù–û–ì–û –ë–õ–û–ö–ê --- 

if __name__ == "__main__":
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    route_data_store = RouteData() # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ route_data_store)
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)

