from fastapi import FastAPI, UploadFile, Request, Form, Body, Path, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import os
import shutil
import subprocess
import pandas as pd
import csv
import sys
import json
from typing import List, Dict, Any, Optional
import io
import math
import re
import numpy as np
import logging
from datetime import datetime
import config # <--- –î–û–ë–ê–í–ò–¢–¨, –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
# --- –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ Excel ---
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, PatternFill, Border, Side # <<< –î–û–ë–ê–í–õ–ï–ù–´ Border, Side
# --- –ö–æ–Ω–µ—Ü –∏–º–ø–æ—Ä—Ç–æ–≤ –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ ---

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ñ–∞–π–ª–∞ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
from geocoder import geocode_address
# --- –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π --- 
import route_distance 

app = FastAPI()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.abspath(os.path.join(BASE_DIR, ".."))
UPLOAD_FOLDER = os.path.join(BASE_DIR, "uploaded")
DATA_FOLDER = os.path.join(BASE_DIR, "data")
PROJECT_DATA_FOLDER = os.path.join(ROOT_DIR, "data")
GEOCODED_RESULTS_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "geocoded_results")
ROUTE_RESULTS_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "route_results")
PARSED_ADDRESSES_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "parsed_addresses")
SUMMARY_CSV_FOLDER = os.path.join(PROJECT_DATA_FOLDER, "summary_csv")

# –°–æ–∑–¥–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(DATA_FOLDER, exist_ok=True)
os.makedirs(GEOCODED_RESULTS_FOLDER, exist_ok=True)
os.makedirs(ROUTE_RESULTS_FOLDER, exist_ok=True)
os.makedirs(PARSED_ADDRESSES_FOLDER, exist_ok=True)
os.makedirs(SUMMARY_CSV_FOLDER, exist_ok=True)

app.mount("/static", StaticFiles(directory=os.path.join(BASE_DIR, "static")), name="static")
templates = Jinja2Templates(directory=os.path.join(BASE_DIR, "templates"))

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
def sanitize_filename(filename):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
    if not isinstance(filename, str):
        return "unnamed"
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    s = filename.strip().replace(' ', '_')
    return s if s else "unnamed"

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π
def sanitize_data_for_json(data):
    if isinstance(data, dict):
        return {k: sanitize_data_for_json(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [sanitize_data_for_json(item) for item in data]
    elif isinstance(data, float):
        if math.isnan(data) or math.isinf(data):
            return None # –ó–∞–º–µ–Ω—è–µ–º NaN/inf –Ω–∞ None
        return data
    else:
        return data

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class RouteData:
    def __init__(self):
        self.routes = {}  # –ö–ª—é—á: sanitized_name
        self.summary = {} # –ö–ª—é—á: sanitized_name, –ó–Ω–∞—á–µ–Ω–∏–µ: {...}
        self.drivers = {} # <--- –ù–û–í–û–ï –ü–û–õ–ï: –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–æ–¥–∏—Ç–µ–ª–µ–π {sanitized_name: driver_name}
        self.current_file = ""  # –ò–º—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        self.global_service_time_minutes = 0 # <--- –ù–û–í–û–ï –ì–õ–û–ë–ê–õ–¨–ù–û–ï –ü–û–õ–ï (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)

    def add_route(self, name, data):
        sanitized_name = sanitize_filename(name)
        if not sanitized_name: return

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞ (geocoder_output, route_points, distance_data)
        self.routes[sanitized_name] = data

        distance_data = data.get("distance_data", {})
        distance_km = distance_data.get("total_distance") # –û–∂–∏–¥–∞–µ–º –æ–∫—Ä—É–≥–ª–µ–Ω–Ω–æ–µ –¥–æ —Ü–µ–ª—ã—Ö –∫–º
        duration_sec = distance_data.get("total_duration") # –û–∂–∏–¥–∞–µ–º —Å–µ–∫—É–Ω–¥—ã
        duration_formatted = distance_data.get("formatted_duration", "–ù/–î")
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ç–æ—á–µ–∫ (–≤—Å–µ —Ç–æ—á–∫–∏ –∏–∑ geocoded_file)
        num_intermediate_stops = len(data.get("route_points", []))

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ summary
        if sanitized_name not in self.summary:
            self.summary[sanitized_name] = {
                "original_name": name,
                "distance": distance_km if distance_km is not None else "–ù/–î",
                "duration_seconds": duration_sec, # –•—Ä–∞–Ω–∏–º —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–Ω–∏—Ü—ã –∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ
                "duration_formatted": duration_formatted, # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏
                "number_of_stops": num_intermediate_stops, # <--- –ù–û–í–û–ï –ü–û–õ–ï: –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫
                "report_distance": None,
                "report_duration_hours": None,
                "report_duration_minutes": None,
                "distance_difference": None,
                "time_difference_formatted": None,
                "total_route_time_seconds": None, # <--- –ù–û–í–û–ï –ü–û–õ–ï: –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤ —Å–µ–∫
                "total_route_time_formatted": None # <--- –ù–û–í–û–ï –ü–û–õ–ï: –æ–±—â–µ–µ –≤—Ä–µ–º—è —Ñ–æ—Ä–º–∞—Ç.
            }
        else:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
            self.summary[sanitized_name]["distance"] = distance_km if distance_km is not None else "–ù/–î"
            self.summary[sanitized_name]["duration_seconds"] = duration_sec
            self.summary[sanitized_name]["duration_formatted"] = duration_formatted
            self.summary[sanitized_name]["number_of_stops"] = num_intermediate_stops # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø–æ–ª—è, –≤–∫–ª—é—á–∞—è –Ω–æ–≤–æ–µ "–í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ"
        self._recalculate_summary_fields(sanitized_name)

    def get_route_names(self):
        return [data.get("original_name", key) for key, data in self.summary.items()]

    def get_route(self, name):
        sanitized_name = sanitize_filename(name)
        return self.routes.get(sanitized_name, {})

    def update_summary_item(self, name, report_distance=None, report_hours=None, report_minutes=None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ –≤ —Å–≤–æ–¥–∫–µ (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É)."""
        sanitized_name = sanitize_filename(name)
        if not sanitized_name or sanitized_name not in self.summary:
            print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–∞—Ä—à—Ä—É—Ç –≤ —Å–≤–æ–¥–∫–µ: {name} (sanitized: {sanitized_name})")
            return False

        summary_item = self.summary[sanitized_name]
        updated = False

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Ç—á–µ—Ç—É
        if report_distance is not None:
            try:
                report_distance_float = float(report_distance) if str(report_distance).strip() != "" else None
                if summary_item.get("report_distance") != report_distance_float:
                    summary_item["report_distance"] = report_distance_float
                    updated = True
            except (ValueError, TypeError):
                if summary_item.get("report_distance") is not None:
                     summary_item["report_distance"] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –µ—Å–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–≤–æ–¥
                     updated = True

        # --- –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ –æ—Ç—á–µ—Ç—É ---
        new_report_h = None
        new_report_m = None
        try:
            if report_hours is not None and str(report_hours).strip() != "":
                new_report_h = int(report_hours)
            if report_minutes is not None and str(report_minutes).strip() != "":
                new_report_m = int(report_minutes)

            if summary_item.get("report_duration_hours") != new_report_h or \
               summary_item.get("report_duration_minutes") != new_report_m:
                summary_item["report_duration_hours"] = new_report_h
                summary_item["report_duration_minutes"] = new_report_m
                updated = True
                print(f"   Updated report time in summary_item: h={new_report_h}, m={new_report_m}")

        except (ValueError, TypeError):
            if summary_item.get("report_duration_hours") is not None or \
               summary_item.get("report_duration_minutes") is not None:
                summary_item["report_duration_hours"] = None
                summary_item["report_duration_minutes"] = None
                updated = True
                print(f"   Reset report time in summary_item due to conversion error")

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–ª—è (–≤–∫–ª—é—á–∞—è –≤—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ) –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ–±–Ω–æ–≤–∏–ª–æ—Å—å
        if updated:
            self._recalculate_summary_fields(sanitized_name) # –ü–µ—Ä–µ—Å—á–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç –Ω–æ–≤–æ–µ –ø–æ–ª–µ
            self.save_to_disk()
            return True

        return False # –ù–∏—á–µ–≥–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å

    def _recalculate_summary_fields(self, sanitized_name, summary_dict=None):
        """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω–∏—Ü—É –≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏, –≤—Ä–µ–º–µ–Ω–∏ –∏ –æ–±—â–µ–µ –≤—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ."""
        target_summary = summary_dict if summary_dict is not None else self.summary

        if sanitized_name not in target_summary:
            return

        item = target_summary[sanitized_name]
        original_name = item.get("original_name", sanitized_name)
        print(f"-- Recalculating fields for: {original_name}")

        # --- –†–∞–∑–Ω–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π ---
        report_dist = item.get("report_distance")
        route_dist = item.get("distance")
        if report_dist is not None and isinstance(route_dist, (int, float)):
            try:
                item["distance_difference"] = round(route_dist - float(report_dist), 2)
            except (ValueError, TypeError):
                item["distance_difference"] = None
        else:
            item["distance_difference"] = None
        # print(f"   Distance diff calculated: {item['distance_difference']}") # –£–±—Ä–∞–ª –ª–æ–≥ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏

        # --- –†–∞—Å—á–µ—Ç –û–±—â–µ–≥–æ –í—Ä–µ–º–µ–Ω–∏ –Ω–∞ –ú–∞—Ä—à—Ä—É—Ç–µ (–ü–†–ê–í–ò–õ–¨–ù–û–ï –ú–ï–°–¢–û) ---
        total_route_time_seconds = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        route_sec = item.get("duration_seconds") # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏
        service_time_sec = 0
        if self.global_service_time_minutes is not None:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get —Å –¥–µ—Ñ–æ–ª—Ç–æ–º 0 –¥–ª—è number_of_stops
                service_time_sec = int(self.global_service_time_minutes) * 60 * item.get("number_of_stops", 0)
            except (ValueError, TypeError):
                 service_time_sec = 0

        if route_sec is not None:
            try:
                total_route_time_seconds = int(route_sec) + service_time_sec # <-- –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
                item["total_route_time_seconds"] = total_route_time_seconds # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ item
                hours = total_route_time_seconds // 3600
                minutes = (total_route_time_seconds % 3600) // 60
                item["total_route_time_formatted"] = f"{hours} —á {minutes} –º–∏–Ω" # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            except (ValueError, TypeError) as e:
                print(f"   Error calculating total route time for {original_name}: {e}")
                item["total_route_time_seconds"] = None
                item["total_route_time_formatted"] = None
        else:
            item["total_route_time_seconds"] = None
            item["total_route_time_formatted"] = None
            # print(f"   Skipping total route time calculation (route_sec={route_sec})") # –ú–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

        # --- –†–∞–∑–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏ (–æ—Ç—á–µ—Ç vs –û–ë–©–ï–ï –í–†–ï–ú–Ø –ù–ê –ú–ê–†–®–†–£–¢–ï) ---
        report_h = item.get("report_duration_hours")
        report_m = item.get("report_duration_minutes")
        # route_sec –ë–û–õ–¨–®–ï –ù–ï –ù–£–ñ–ï–ù –ó–î–ï–°–¨, –∏—Å–ø–æ–ª—å–∑—É–µ–º total_route_time_seconds

        # ... (–ª–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ time_difference_formatted –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–µ–π) ...
        try:
            report_h_int = int(report_h) if report_h is not None and str(report_h).strip() != "" else 0
            report_m_int = int(report_m) if report_m is not None and str(report_m).strip() != "" else 0
            is_report_time_valid = not (report_h_int == 0 and report_m_int == 0 and (report_h is None or str(report_h).strip() == "") and (report_m is None or str(report_m).strip() == ""))
        except (ValueError, TypeError):
             is_report_time_valid = False

        calculate_time_diff = False
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –û–ë–©–ï–ï –≤—Ä–µ–º—è —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ
        if total_route_time_seconds is not None:
            if is_report_time_valid:
                 calculate_time_diff = True
            elif report_h_int == 0 and report_m_int == 0: # –ï—Å–ª–∏ –≤—Ä–µ–º—è –æ—Ç—á–µ—Ç–∞ –Ω–µ –≤–≤–µ–¥–µ–Ω–æ (0—á 0–º), —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É
                 calculate_time_diff = True # <-- –ò–ó–ú–ï–ù–ï–ù–û: –°—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É, –¥–∞–∂–µ –µ—Å–ª–∏ –≤—Ä–µ–º—è –æ—Ç—á–µ—Ç–∞ 0, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω–æ–µ –≤—Ä–µ–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü—É

        if calculate_time_diff:
            try:
                report_total_seconds = report_h_int * 3600 + report_m_int * 60
                # –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–ë–©–ï–ï –í–†–ï–ú–Ø –ù–ê –ú–ê–†–®–†–£–¢–ï –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–Ω–∏—Ü—ã
                time_diff_value_seconds = total_route_time_seconds - report_total_seconds # <-- –†–ï–ê–õ–¨–ù–û–ï –ó–ù–ê–ß–ï–ù–ò–ï –†–ê–ó–ù–ò–¶–´
                sign = "+" if time_diff_value_seconds >= 0 else "-"
                diff_seconds_abs = abs(time_diff_value_seconds) # –ò—Å–ø–æ–ª—å–∑—É–µ–º abs() –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                diff_hours = diff_seconds_abs // 3600
                diff_minutes = (diff_seconds_abs % 3600) // 60
                item["time_difference_formatted"] = f"{sign}{diff_hours} —á {diff_minutes} –º–∏–Ω"
                item["time_difference_seconds"] = time_diff_value_seconds # <-- –°–û–•–†–ê–ù–Ø–ï–ú –ó–ù–ê–ß–ï–ù–ò–ï –í –°–ï–ö–£–ù–î–ê–•
            except (ValueError, TypeError) as e:
                print(f"   Error calculating time diff for {original_name}: {e}")
                item["time_difference_formatted"] = None
                item["time_difference_seconds"] = None # <-- –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏ —Å–µ–∫—É–Ω–¥—ã
        else:
            item["time_difference_formatted"] = None
            item["time_difference_seconds"] = None # <-- –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏ —Å–µ–∫—É–Ω–¥—ã

    def get_summary(self):
        try:
            with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
                original_names_data = json.load(f)
                original_names = original_names_data.get("routes", [])
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å original_route_names.json: {e}")
            original_names = []

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ self.summary
        saved_user_input = {}
        for norm_name, data in self.summary.items():
            saved_user_input[norm_name] = {
                "report_distance": data.get("report_distance"),
                "report_duration_hours": data.get("report_duration_hours"),
                "report_duration_minutes": data.get("report_duration_minutes")
            }

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—É—â–∏–π summary –ø–µ—Ä–µ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        current_summary = {} # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("--- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–≤–æ–¥–∫–∏ --- ")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –º–∞—Ä—à—Ä—É—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö
        for original_name in original_names:
            sanitized_name = sanitize_filename(original_name)
            if not sanitized_name: continue
            
            print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞: {original_name}...")
            try:
                # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞ (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, —Ç–æ—á–∫–∏ –∏ —Ç.–¥.)
                route_data_response = get_route_data_endpoint(original_name)
                
                if route_data_response and not route_data_response.get("error"):
                    distance_data = route_data_response.get("distance_data", {})
                    distance_km = distance_data.get("total_distance") # –û–∂–∏–¥–∞–µ–º –∫–º
                    duration_sec = distance_data.get("total_duration") # –û–∂–∏–¥–∞–µ–º —Å–µ–∫
                    duration_formatted = distance_data.get("formatted_duration", "–ù/–î")
                    number_of_stops = route_data_response.get("number_of_stops", 0)
                    
                    # --- –ü–û–õ–£–ß–ï–ù–ò–ï –§–ò–û –í–û–î–ò–¢–ï–õ–Ø --- 
                    driver_name = self.drivers.get(sanitized_name, "‚Äî") # –ü–æ–ª—É—á–∞–µ–º –∏–∑ self.drivers, –¥–µ—Ñ–æ–ª—Ç "‚Äî"
                    print(f"    -> –í–æ–¥–∏—Ç–µ–ª—å –¥–ª—è {original_name}: {driver_name}")
                    # -----------------------------------
                    
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –ù–û–í–û–ô —Å–≤–æ–¥–∫–µ
                    current_summary[sanitized_name] = {
                        "original_name": original_name,
                        "driver_name": driver_name, # <--- –î–û–ë–ê–í–õ–ï–ù–û –ü–û–õ–ï
                        "distance": distance_km if distance_km is not None else "–ù/–î",
                        "duration_seconds": duration_sec,
                        "duration_formatted": duration_formatted,
                        "number_of_stops": number_of_stops, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ
                        "report_distance": None, # –ë—É–¥—É—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –Ω–∏–∂–µ
                        "report_duration_hours": None,
                        "report_duration_minutes": None,
                        "distance_difference": None,
                        "time_difference_formatted": None,
                        "time_difference_seconds": None, # <-- –î–û–ë–ê–í–õ–ï–ù–û
                        "total_route_time_seconds": None, # –ë—É–¥—É—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –Ω–∏–∂–µ
                        "total_route_time_formatted": None
                    }

                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞
                    if sanitized_name in saved_user_input:
                        current_summary[sanitized_name]["report_distance"] = saved_user_input[sanitized_name]["report_distance"]
                        current_summary[sanitized_name]["report_duration_hours"] = saved_user_input[sanitized_name]["report_duration_hours"]
                        current_summary[sanitized_name]["report_duration_minutes"] = saved_user_input[sanitized_name]["report_duration_minutes"]
                        
                    # --- –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ï–†–ï–°–ß–ï–¢ –ü–û–õ–ï–ô –î–õ–Ø –ö–ê–ñ–î–û–ô –ó–ê–ü–ò–°–ò --- 
                    self._recalculate_summary_fields(sanitized_name, summary_dict=current_summary) # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
                        
                    print(f"    ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–≤–æ–¥–∫–∏ –ø–æ–ª—É—á–µ–Ω—ã –∏ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã: {original_name}")
                else:
                    error_msg = route_data_response.get('message') if route_data_response else '–î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã'
                    print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_name}: {error_msg}")
            except Exception as e:
                print(f"    ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä—à—Ä—É—Ç–∞ {original_name} –¥–ª—è —Å–≤–æ–¥–∫–∏: {e}")
                # import traceback
                # traceback.print_exc()

        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π summary –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        self.summary = current_summary
        self.save_to_disk() 
        print("--- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ --- ")
        return self.summary

    def save_to_disk(self):
         data = {
             "routes": self.routes,
             "summary": self.summary,
             "drivers": self.drivers, # <--- –°–û–•–†–ê–ù–Ø–ï–ú
             "current_file": self.current_file,
             "global_service_time_minutes": self.global_service_time_minutes # <--- –°–û–•–†–ê–ù–Ø–ï–ú
         }
         # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º (—É–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ)
         # sanitized_data = sanitize_data_for_json(data) # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, json.dump —Å–∞–º —Å–ø—Ä–∞–≤–∏—Ç—Å—è —Å None
         with open(os.path.join(DATA_FOLDER, "route_data.json"), "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2) # –ò—Å–ø–æ–ª—å–∑—É–µ–º data –Ω–∞–ø—Ä—è–º—É—é

    def load_from_disk(self):
        try:
            with open(os.path.join(DATA_FOLDER, "route_data.json"), "r", encoding="utf-8") as f:
                data = json.load(f)
                self.routes = data.get("routes", {})
                self.summary = data.get("summary", {})
                self.drivers = data.get("drivers", {}) # <--- –ó–ê–ì–†–£–ñ–ê–ï–ú
                self.current_file = data.get("current_file", "")
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è, –∏–ª–∏ 0 –µ—Å–ª–∏ –Ω–µ—Ç
                self.global_service_time_minutes = data.get("global_service_time_minutes", 0) # <--- –ó–ê–ì–†–£–ñ–ê–ï–ú

                print(f"üíæ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ú–∞—Ä—à—Ä—É—Ç–æ–≤: {len(self.routes)}, –ó–∞–ø–∏—Å–µ–π –≤ —Å–≤–æ–¥–∫–µ: {len(self.summary)}, –í–æ–¥–∏—Ç–µ–ª–µ–π: {len(self.drivers)}, –í—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É: {self.global_service_time_minutes} –º–∏–Ω.")

                # –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ summary, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç)
                needs_recalculation = False
                for key, summary_item in self.summary.items():
                    if summary_item.setdefault("number_of_stops", None) is None:
                         # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –∏–∑ routes, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                         route_entry = self.routes.get(key)
                         if route_entry and "route_points" in route_entry:
                             summary_item["number_of_stops"] = len(route_entry["route_points"])
                             needs_recalculation = True
                             print(f"   –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è {key}: {summary_item['number_of_stops']}")
                         else:
                             summary_item["number_of_stops"] = 0 # –ò–ª–∏ —Å—Ç–∞–≤–∏–º 0, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏
                             print(f"   –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è {key}, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 0")
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º None, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
                    if summary_item.setdefault("total_route_time_seconds", None) is None: needs_recalculation = True
                    if summary_item.setdefault("total_route_time_formatted", None) is None: needs_recalculation = True
                    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ä–æ–µ –ø–æ–ª–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                    summary_item.pop("service_time_per_stop_minutes", None)

                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                    summary_item.setdefault("report_duration_hours", None)
                    summary_item.setdefault("report_duration_minutes", None)
                    summary_item.setdefault("time_difference_formatted", None)
                    summary_item.setdefault("duration_seconds", None)
                    summary_item.setdefault("distance_difference", None)


                # –ï—Å–ª–∏ –¥–æ–±–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–µ –ø–æ–ª—è –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ –∫–æ–ª-–≤–æ —Ç–æ—á–µ–∫, –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º –≤—Å–µ
                if needs_recalculation:
                    print("   –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –∏–ª–∏ –±—ã–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç —Å–≤–æ–¥–∫–∏...")
                    for key in list(self.summary.keys()): # –ò—Å–ø–æ–ª—å–∑—É–µ–º list, —á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å —Å–ª–æ–≤–∞—Ä—å –≤–æ –≤—Ä–µ–º—è –∏—Ç–µ—Ä–∞—Ü–∏–∏
                        self._recalculate_summary_fields(key)
                    self.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

                return True
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å route_data.json: {e}. –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
            self.routes = {}
            self.summary = {}
            self.current_file = ""
            self.global_service_time_minutes = 0 # –°–±—Ä–æ—Å –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
            return False
        except Exception as e: # –õ–æ–≤–∏–º –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ/–º–∏–≥—Ä–∞—Ü–∏–∏
             print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ/–º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö route_data.json: {e}")
             # import traceback # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏
             # traceback.print_exc()
             self.routes = {}
             self.summary = {}
             self.current_file = ""
             self.global_service_time_minutes = 0
             return False

    # <--- –ù–û–í–´–ô –ú–ï–¢–û–î --->
    def set_global_service_time(self, minutes):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É –∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –º–∞—Ä—à—Ä—É—Ç—ã."""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ int, –µ—Å–ª–∏ –Ω–µ None –∏ –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –∏–Ω–∞—á–µ 0
            new_time = int(minutes) if minutes is not None and str(minutes).strip() != "" else 0
            if new_time < 0: new_time = 0 # –í—Ä–µ–º—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º

            if new_time != self.global_service_time_minutes:
                print(f"üîÑ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–æ–≤–æ–≥–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É: {new_time} –º–∏–Ω.")
                self.global_service_time_minutes = new_time
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –º–∞—Ä—à—Ä—É—Ç—ã –≤ —Å–≤–æ–¥–∫–µ
                recalculated_count = 0
                for key in list(self.summary.keys()):
                    self._recalculate_summary_fields(key)
                    recalculated_count += 1
                print(f"   –ü–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–æ –º–∞—Ä—à—Ä—É—Ç–æ–≤: {recalculated_count}")
                self.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                return True
            else:
                print(f"‚ÑπÔ∏è –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ({new_time} –º–∏–Ω).")
                return False
        except (ValueError, TypeError):
            print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–æ—á–∫—É: {minutes}. –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ: {self.global_service_time_minutes} –º–∏–Ω.")
            return False

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
route_data = RouteData()
# –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
if not route_data.load_from_disk():
    print("üíæ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç RouteData.")

@app.get("/", response_class=HTMLResponse)
def index(request: Request):
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä—à—Ä—É—Ç "–õ–∏–ø–µ—Ü–∫ 2" –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
    # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # if not os.path.exists(os.path.join(os.path.dirname(BASE_DIR), "geocoded_results_–õ–∏–ø–µ—Ü–∫_2.csv")):
    #     print("‚ö†Ô∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Ä—à—Ä—É—Ç '–õ–∏–ø–µ—Ü–∫ 2'...")
    #     process_route("–õ–∏–ø–µ—Ü–∫ 2")
    
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/api/health")
def health_check():
    return {"status": "ok"}

@app.get("/api/routes")
def get_routes():
    try:
        with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
            original_names_data = json.load(f)
            return {"routes": sorted(original_names_data.get("routes", []))}
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å original_route_names.json: {e}")
        return {"routes": []}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
def process_route(original_route_name):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    root_dir = os.path.dirname(script_dir)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –ø—É—Ç–µ–π
    file_name = sanitize_filename(original_route_name)
    parsed_path = os.path.join(PROJECT_DATA_FOLDER, "parsed_addresses", f"parsed_addresses_{file_name}.csv")
    geocoded_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{file_name}.csv")
    
    if not os.path.exists(parsed_path):
        print(f"‚ö†Ô∏è –§–∞–π–ª {parsed_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}")
        return False
    
    process_success = False # –§–ª–∞–≥ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –í–°–ï–ì–û –ø—Ä–æ—Ü–µ—Å—Å–∞
    try:
        # –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        with open(parsed_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        
        geocoded_output = []
        for row in rows:
            address = row["normalized_address"]
            result = geocode_address(address)
            result["excel_row"] = row["excel_row"]
            result["route_name"] = original_route_name
            geocoded_output.append(result)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(os.path.dirname(geocoded_path), exist_ok=True)
        
        with open(geocoded_path, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["excel_row", "route_name", "input", "found", "type", "description", "lat", "lon", "error"])
            writer.writeheader()
            writer.writerows(geocoded_output)
        print(f"‚úÖ –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}")
        
        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è {original_route_name}...")
        # –í—ã–∑—ã–≤–∞–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é
        calculation_success = route_distance.calculate_and_save_route(
            route_name=original_route_name, 
            geocoded_file_path=geocoded_path
            # traffic_mode –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –±—Ä–∞—Ç—å –∏–∑ config, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        )
        
        if calculation_success:
            print(f"‚úÖ –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è {original_route_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ (—á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é).")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è {original_route_name} (—á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é).")
            # –ú–æ–∂–Ω–æ —Ä–µ—à–∏—Ç—å, –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –ª–∏ –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å –∏–ª–∏ –Ω–µ—Ç
            # return False # –ü—Ä–µ—Ä–≤–∞—Ç—å, –µ—Å–ª–∏ —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –∫—Ä–∏—Ç–∏—á–µ–Ω

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ route_data
        if calculation_success: # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞—Å—á–µ—Ç –ø—Ä–æ—à–µ–ª
            try:
                route_info = get_route_data_endpoint(original_route_name)
                if route_info and not route_info.get("error"):
                    route_data.add_route(original_route_name, route_info)
                    route_data.save_to_disk()
                    print(f"‚úÖ –ú–∞—Ä—à—Ä—É—Ç {original_route_name} –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–≤–æ–¥–∫—É")
                    process_success = True # –í–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å —É—Å–ø–µ—à–µ–Ω
                else:
                    error_msg = route_info.get("message", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞") if route_info else "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç–∞"
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç {original_route_name} –≤ —Å–≤–æ–¥–∫—É: {error_msg}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name} –≤ —Å–≤–æ–¥–∫—É: {str(e)}")
        else:
             print(f"‚ÑπÔ∏è –ú–∞—Ä—à—Ä—É—Ç {original_route_name} –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–≤–æ–¥–∫—É, —Ç.–∫. —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –Ω–µ —É–¥–∞–ª—Å—è.")

    except Exception as e:
        print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}: {str(e)}")

    return process_success

@app.get("/api/route-data/{route_name}")
def get_route_data_endpoint(route_name: str = Path(...)):
    original_route_name = route_name
    if not original_route_name:
        raise HTTPException(status_code=400, detail="–ò–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ")

    try:
        logging.info(f"Getting route data for '{original_route_name}'")
        file_name = sanitize_filename(original_route_name)
        geocoded_file = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{file_name}.csv")
        route_results_file = os.path.join(ROUTE_RESULTS_FOLDER, f"route_results_{file_name}.json")
        summary_item = route_data.summary.get(file_name, {}) # –ü–æ–ª—É—á–∞–µ–º –∑–∞—Ä–∞–Ω–µ–µ

        # –ò—â–µ–º —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        distance_data = {}
        if os.path.exists(route_results_file):
            logging.info(f"Found route results file: {route_results_file}")
            try:
                with open(route_results_file, 'r', encoding='utf-8') as f:
                    distance_data = json.load(f)

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
                if 'total_distance' in distance_data and distance_data['total_distance'] is not None:
                    try:
                        distance_meters = float(distance_data['total_distance'])
                        distance_km_rounded = round(distance_meters / 1000)
                        distance_data['formatted_distance'] = f"{distance_km_rounded} –∫–º"
                        distance_data['total_distance'] = distance_km_rounded
                    except (ValueError, TypeError):
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å total_distance: {distance_data['total_distance']}")
                        distance_data['formatted_distance'] = "–û—à–∏–±–∫–∞"
                        distance_data['total_distance'] = None
                else:
                    distance_data['formatted_distance'] = "–ù/–î"
                    distance_data['total_distance'] = None

                if 'total_duration' in distance_data and distance_data['total_duration'] is not None:
                    try:
                        total_seconds = int(distance_data['total_duration'])
                        hours = total_seconds // 3600
                        minutes = (total_seconds % 3600) // 60
                        formatted_duration = f"{hours} —á {minutes} –º–∏–Ω" if hours > 0 else f"{minutes} –º–∏–Ω"
                        distance_data['formatted_duration'] = formatted_duration
                        distance_data['total_duration'] = total_seconds
                    except (ValueError, TypeError):
                         print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å total_duration: {distance_data['total_duration']}")
                         distance_data['formatted_duration'] = "–û—à–∏–±–∫–∞"
                         distance_data['total_duration'] = None
                else:
                    distance_data['formatted_duration'] = "–ù/–î"
                    distance_data['total_duration'] = None
            except Exception as e:
                logging.error(f"Error reading route results for {original_route_name}: {e}")
                distance_data = {"error": True, "error_message": f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}"}
        else:
            logging.warning(f"Route results file not found for route {original_route_name}")
            distance_data = {"error": True, "error_message": f"Route results file not found for {original_route_name}"}


        # –ß—Ç–µ–Ω–∏–µ geocoded_data
        geocoded_data = []
        route_points = [] # –ë—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–æ—á–∫–∏ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ lat/lon
        number_of_stops_actual = 0
        try:
            if os.path.exists(geocoded_file):
                 geocoded_df = pd.read_csv(geocoded_file)
                 geocoded_df.replace([np.nan, np.inf, -np.inf], None, inplace=True)
                 for _, row in geocoded_df.iterrows():
                     point_data = row.to_dict()
                     geocoded_data.append(point_data) # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
                     # –î–æ–±–∞–≤–ª—è–µ–º –≤ route_points —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                     if 'lon' in point_data and 'lat' in point_data and point_data['lon'] is not None and point_data['lat'] is not None:
                        try:
                             lat = float(point_data['lat'])
                             lon = float(point_data['lon'])
                             if -90 <= lat <= 90 and -180 <= lon <= 180:
                                route_points.append({
                                     'lon': lon,
                                     'lat': lat,
                                     # –ò—Å–ø–æ–ª—å–∑—É–µ–º description –¥–ª—è –∞–¥—Ä–µ—Å–∞ –Ω–∞ –∫–∞—Ä—Ç–µ, input –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ
                                     'address': point_data.get('description', point_data.get('input', '')),
                                     'original_address': point_data.get('input', '')
                                 })
                        except (ValueError, TypeError):
                             print(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ geocoded_file –¥–ª—è {original_route_name}: {point_data.get('lat')}, {point_data.get('lon')}")


                 number_of_stops_actual = len(route_points) # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ—á–∫–∏ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏

                 # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤ summary, –µ—Å–ª–∏ –æ–Ω–æ —Ä–∞—Å—Ö–æ–¥–∏—Ç—Å—è –∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º
                 if file_name in route_data.summary: 
                     if route_data.summary[file_name].get("number_of_stops") != number_of_stops_actual:
                         print(f"‚ö†Ô∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–ª-–≤–∞ —Ç–æ—á–µ–∫ –¥–ª—è {original_route_name} —Å {route_data.summary[file_name].get('number_of_stops')} –Ω–∞ {number_of_stops_actual}")
                         route_data.summary[file_name]["number_of_stops"] = number_of_stops_actual
                         route_data._recalculate_summary_fields(file_name)
                         route_data.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                         summary_item = route_data.summary.get(file_name, {}) # –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π summary_item
                 else:
                     logging.warning(f"Route {original_route_name} (sanitized: {file_name}) not found in summary data.")

            else:
                 logging.warning(f"Could not find geocoded file for route {original_route_name}")
                 number_of_stops_actual = 0
                 geocoded_data = []
                 route_points = []
        except Exception as e:
             logging.error(f"Error reading geocoding data for {original_route_name}: {e}")
             geocoded_data = []
             route_points = []
             number_of_stops_actual = 0

        # --- –î–û–ë–ê–í–õ–ï–ù–ò–ï –û–§–ò–°–ê –†–¢–ö –í –ù–ê–ß–ê–õ–û –ò –ö–û–ù–ï–¶ –°–ü–ò–°–ö–û–í –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê ---
        try:
            office_loc = config.OFFICE_LOCATION
            if office_loc and "lat" in office_loc and "lon" in office_loc:
                office_lat = office_loc["lat"]
                office_lon = office_loc["lon"]
                office_name = office_loc.get("name", "–û—Ñ–∏—Å –†–¢–ö")

                # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã geocoded_data
                office_geocoded_repr = {
                    "excel_row": "–°–¢–ê–†–¢",
                    "route_name": original_route_name,
                    "input": office_name,
                    "found": True,
                    "type": "office",
                    "description": office_name,
                    "lat": office_lat,
                    "lon": office_lon,
                    "error": None
                }
                # –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞—Ä—Ç—ã route_points
                office_route_point_repr = {
                    "lat": office_lat,
                    "lon": office_lon,
                    "address": office_name,
                    "original_address": office_name
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ
                geocoded_data.insert(0, office_geocoded_repr)
                route_points.insert(0, office_route_point_repr)

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü (–∫–æ–ø–∏—Ä—É–µ–º, —á—Ç–æ–±—ã excel_row –º–æ–∂–Ω–æ –±—ã–ª–æ –∏–∑–º–µ–Ω–∏—Ç—å)
                office_geocoded_repr_end = office_geocoded_repr.copy()
                office_geocoded_repr_end["excel_row"] = "–§–ò–ù–ò–®"
                geocoded_data.append(office_geocoded_repr_end)
                route_points.append(office_route_point_repr) # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–µ –∂–µ

                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –æ—Ñ–∏—Å –†–¢–ö –≤ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {original_route_name}")

            else:
                print("‚ö†Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã OFFICE_LOCATION –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã –≤ config.py. –û—Ñ–∏—Å –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω.")
        except Exception as e_office:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –æ—Ñ–∏—Å–∞ –†–¢–ö: {e_office}")
        # --- –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø –û–§–ò–°–ê ---


        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ, –≤–∫–ª—é—á–∞—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∏ –Ω–æ–≤—ã–µ –ø–æ–ª—è
        return {
            "route_name": original_route_name,
            "geocoder_output": geocoded_data, # <--- –¢–µ–ø–µ—Ä—å —Å –æ—Ñ–∏—Å–æ–º
            "route_points": route_points,     # <--- –¢–µ–ø–µ—Ä—å —Å –æ—Ñ–∏—Å–æ–º
            "distance_data": distance_data,
            "number_of_stops": summary_item.get("number_of_stops", number_of_stops_actual), 
            "total_route_time_formatted": summary_item.get("total_route_time_formatted", "–ù/–î"),
            "global_service_time_minutes": route_data.global_service_time_minutes
        }
    except Exception as e:
        logging.error(f"Error in get_route_data_endpoint for {original_route_name}: {e}")
        # import traceback
        # traceback.print_exc()
        return {"error": True, "message": str(e), "route_name": original_route_name}

@app.get("/api/summary")
def get_summary_endpoint():
    summary = route_data.get_summary() # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Ç–µ–ø–µ—Ä—å —Å–∞–º –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç
    result = []
    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π route_data.summary –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ get_summary()
    for norm_name, data in route_data.summary.items():
        result.append({
            "route_name": data.get("original_name", norm_name),
            "driver_name": data.get("driver_name", "‚Äî"),
            "distance": data.get("distance", "–ù/–î"),
            "duration_seconds": data.get("duration_seconds"), # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏ (—Å–µ–∫)
            "duration": data.get("duration_formatted", "–ù/–î"), # –í—Ä–µ–º—è –≤ –ø—É—Ç–∏ (—Ñ–æ—Ä–º–∞—Ç)
            "report_distance": data.get("report_distance"),
            "report_duration_hours": data.get("report_duration_hours"),
            "report_duration_minutes": data.get("report_duration_minutes"),
            "distance_difference": data.get("distance_difference"),
            "time_difference_formatted": data.get("time_difference_formatted"),
            "time_difference_seconds": data.get("time_difference_seconds"), # <-- –î–û–ë–ê–í–õ–ï–ù–û
            "total_route_time_seconds": data.get("total_route_time_seconds"), # <-- –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            "total_route_time_formatted": data.get("total_route_time_formatted", "–ù/–î"), # –í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ (—Ñ–æ—Ä–º–∞—Ç)
            "number_of_stops": data.get("number_of_stops", "–ù/–î") # <--- –î–û–ë–ê–í–õ–ï–ù–û –ö–û–õ-–í–û –¢–û–ß–ï–ö
        })
    # –î–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É –≤ –æ—Ç–≤–µ—Ç
    return {
        "summary": result, # <<< –£–ë–†–ê–ù–ê –°–û–†–¢–ò–†–û–í–ö–ê
        "global_service_time_minutes": route_data.global_service_time_minutes
     }

@app.post("/api/upload")
async def upload_excel(file: UploadFile, service_time_per_stop_minutes: int = Form(0)): # <--- –ò–ó–ú–ï–ù–ï–ù–ê –°–ò–ì–ù–ê–¢–£–†–ê
    save_path = os.path.join(UPLOAD_FOLDER, file.filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
    route_data.current_file = file.filename

    # --- –ü–µ—á–∞—Ç–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ---
    print(f"--- Received time per stop in /api/upload: {service_time_per_stop_minutes} (type: {type(service_time_per_stop_minutes)}) ---")
    # --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

    # --- –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ—á–∫—É ---
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ None, —Ç–∞–∫ –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ int
    # time_to_set = service_time_per_stop_minutes if service_time_per_stop_minutes is not None else 0
    route_data.set_global_service_time(service_time_per_stop_minutes)
    # --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

    try:
        # --- –ß—Ç–µ–Ω–∏–µ Excel –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–æ–≤ --- 
        df = pd.read_excel(save_path)
        all_routes_addresses = {} # –°–ª–æ–≤–∞—Ä—å: route_name -> [(row_num, address), ...]
        route_names = []          # –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω –º–∞—Ä—à—Ä—É—Ç–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Ö –ø–æ—è–≤–ª–µ–Ω–∏—è
        current_route = None
        seen_kontragents_in_route = set() # <-- –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ –≤ –¢–ï–ö–£–©–ï–ú –º–∞—Ä—à—Ä—É—Ç–µ
        
        # --- –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª --- 
        if df.empty:
             raise ValueError("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π Excel —Ñ–∞–π–ª –ø—É—Å—Ç.")
        # --- –ö–æ–Ω–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏ --- 

        # --- –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ parsing_route.py) --- 
        region_col_name = None
        address_col_name = "–ê–¥—Ä–µ—Å –¥–æ—Å—Ç–∞–≤–∫–∏"
        kontragent_col_name = None # <-- –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤
        driver_col_name = None # <--- –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ –≤–æ–¥–∏—Ç–µ–ª—è
        
        for col in df.columns:
            col_str = str(col).strip()
            if region_col_name is None and col_str.startswith("–†–µ–≥–∏–æ–Ω/–ú–∞—Ä—à—Ä—É—Ç"):
                region_col_name = col_str
            if kontragent_col_name is None and col_str.startswith("–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤"):
                 kontragent_col_name = col_str
            if driver_col_name is None and col_str.startswith("–í–æ–¥–∏—Ç–µ–ª—å"): # <--- –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É –í–æ–¥–∏—Ç–µ–ª—å
                 driver_col_name = col_str
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        missing_cols = []
        if region_col_name is None: missing_cols.append("–∫–æ–ª–æ–Ω–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å '–†–µ–≥–∏–æ–Ω/–ú–∞—Ä—à—Ä—É—Ç'")
        if address_col_name not in df.columns: missing_cols.append(f"–∫–æ–ª–æ–Ω–∫–∞ '{address_col_name}'")
        if kontragent_col_name is None: missing_cols.append("–∫–æ–ª–æ–Ω–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å '–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤'")
        if driver_col_name is None: missing_cols.append("–∫–æ–ª–æ–Ω–∫–∞, –Ω–∞—á–∏–Ω–∞—é—â–∞—è—Å—è —Å '–í–æ–¥–∏—Ç–µ–ª—å'") # <--- –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–æ–Ω–∫—É –í–æ–¥–∏—Ç–µ–ª—å
        
        if missing_cols:
             raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: { ' –∏ '.join(missing_cols) }.")
        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: '{region_col_name}', '{address_col_name}', '{kontragent_col_name}', '{driver_col_name}'") # <--- –î–æ–±–∞–≤–∏–ª–∏ –≤ –ª–æ–≥
        # --- –ö–æ–Ω–µ—Ü –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ --- 
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –≤–æ–¥–∏—Ç–µ–ª—è—Ö –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        route_data.drivers = {}
        print("  ‚ÑπÔ∏è –°–ª–æ–≤–∞—Ä—å –≤–æ–¥–∏—Ç–µ–ª–µ–π –æ—á–∏—â–µ–Ω –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞.")

        for idx, row in df.iterrows():
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
            region = row.get(region_col_name)
            address = row.get(address_col_name)
            kontragent = row.get(kontragent_col_name) # <-- –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞
            driver = row.get(driver_col_name) # <--- –ü–æ–ª—É—á–∞–µ–º –≤–æ–¥–∏—Ç–µ–ª—è
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
            is_new_route_marker = False
            if pd.notna(region) and isinstance(region, str) and region.strip():
                potential_new_route = region.strip()
                if pd.isna(address) or not str(address).strip() or current_route is None or potential_new_route != current_route:
                     is_new_route_marker = True
                     current_route = potential_new_route
                     if current_route not in route_names: # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è –ù–ï–ü–£–°–¢–´–• –º–∞—Ä—à—Ä—É—Ç–æ–≤
                         route_names.append(current_route)
                     if current_route not in all_routes_addresses:
                         all_routes_addresses[current_route] = []
                     seen_kontragents_in_route.clear() # <-- –û—á–∏—â–∞–µ–º —Å–µ—Ç –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
                     # driver_found_for_current_route = False # <-- –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ (–ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–¥—Ä–µ—Å –∫ –¢–ï–ö–£–©–ï–ú–£ –º–∞—Ä—à—Ä—É—Ç—É, –µ—Å–ª–∏:
            # 1. –ú–∞—Ä—à—Ä—É—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
            # 2. –ê–¥—Ä–µ—Å –µ—Å—Ç—å
            # 3. –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –µ—Å—Ç—å –∏ –æ–Ω –µ—â–µ –ù–ï –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –≤ –≠–¢–û–ú –º–∞—Ä—à—Ä—É—Ç–µ
            if current_route and pd.notna(address) and isinstance(address, str) and address.strip():
                excel_row = idx + 2 # +1 –∑–∞ 0-–∏–Ω–¥–µ–∫—Å, +1 –∑–∞ —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞
                if pd.notna(kontragent) and isinstance(kontragent, str) and kontragent.strip():
                    kontragent_key = kontragent.strip()
                    if kontragent_key not in seen_kontragents_in_route:
                        seen_kontragents_in_route.add(kontragent_key) # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ –≤ —Å–µ—Ç
                        all_routes_addresses[current_route].append((excel_row, address.strip()))
                        
                        # --- –°–û–•–†–ê–ù–ï–ù–ò–ï –í–û–î–ò–¢–ï–õ–Ø --- 
                        sanitized_route_name = sanitize_filename(current_route)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–æ–¥–∏—Ç–µ–ª—å –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ –ò —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–æ–¥–∏—Ç–µ–ª—è –≤–∞–ª–∏–¥–Ω–æ
                        if sanitized_route_name and sanitized_route_name not in route_data.drivers:
                            if pd.notna(driver) and isinstance(driver, str) and driver.strip():
                                driver_name = driver.strip()
                                route_data.drivers[sanitized_route_name] = driver_name
                                print(f"    üßë –ù–∞–π–¥–µ–Ω –≤–æ–¥–∏—Ç–µ–ª—å –¥–ª—è '{current_route}': {driver_name}")
                        # --- –ö–û–ù–ï–¶ –°–û–•–†–ê–ù–ï–ù–ò–Ø –í–û–î–ò–¢–ï–õ–Ø ---
                        
                    # else: # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                        # print(f"  [upload] –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {excel_row}: –¥—É–±–ª—å –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ '{kontragent_key}' –≤ '{current_route}'")
                # else: # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                     # print(f"  [upload] –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ {excel_row}: –Ω–µ—Ç –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞ –≤ '{current_route}'")
        
        # –£–¥–∞–ª—è–µ–º –º–∞—Ä—à—Ä—É—Ç—ã –±–µ–∑ –∞–¥—Ä–µ—Å–æ–≤ –∏–∑ –æ–±–æ–∏—Ö —Å–ø–∏—Å–∫–æ–≤
        route_names = [r for r in route_names if all_routes_addresses.get(r)]
        all_routes_addresses = {r: adds for r, adds in all_routes_addresses.items() if adds}

        if not route_names:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ —Å –∞–¥—Ä–µ—Å–∞–º–∏ –≤ —Ñ–∞–π–ª–µ.")
            
        print(f"‚úÖ –í —Ñ–∞–π–ª–µ –Ω–∞–π–¥–µ–Ω–æ –º–∞—Ä—à—Ä—É—Ç–æ–≤ —Å –∞–¥—Ä–µ—Å–∞–º–∏: {len(route_names)}")
        
        # --- –°–æ—Ö—Ä–∞–Ω—è–µ–º route_data —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –≤–æ–¥–∏—Ç–µ–ª—è–º–∏ –ü–ï–†–ï–î –∑–∞–ø—É—Å–∫–æ–º –ø–∞—Ä—Å–∏–Ω–≥–∞ --- 
        if route_data.drivers: # –°–æ—Ö—Ä–∞–Ω—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –≤–æ–¥–∏—Ç–µ–ª—è
            print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º route_data —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–æ–¥–∏—Ç–µ–ª—è—Ö...")
            route_data.save_to_disk()
        # -----------------------------------------------------------------------------
        
        # --- –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –∫–µ—à–∞ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ --- 
        print("\nüßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞...")
        routes_cleaned_count = 0
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—á–∏—Å—Ç–∫—É summary CSV, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        summary_csv_path = os.path.join(SUMMARY_CSV_FOLDER, "current_summary.csv")
        # –û—á–∏—â–∞–µ–º –µ–≥–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ –¥–æ —ç—Ç–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞
        # (–õ—É—á—à–µ –æ—á–∏—â–∞—Ç—å –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤)
        # if os.path.exists(summary_csv_path):
        #     try:
        #         os.remove(summary_csv_path)
        #         print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–≤–æ–¥–∫–∏: {os.path.basename(summary_csv_path)}")
        #     except OSError as e:
        #         print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {summary_csv_path}: {e}")

        for route_name_to_clean in route_names:
            file_name = sanitize_filename(route_name_to_clean)
            if not file_name:
                 continue
                 
            # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            parsed_path = os.path.join(PARSED_ADDRESSES_FOLDER, f"parsed_addresses_{file_name}.csv")
            geocoded_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{file_name}.csv")
            route_results_path = os.path.join(ROUTE_RESULTS_FOLDER, f"route_results_{file_name}.json")
            
            files_to_delete = [parsed_path, geocoded_path, route_results_path]
            deleted_something_for_route = False

            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
            for file_path in files_to_delete:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {os.path.basename(file_path)} (–¥–ª—è '{route_name_to_clean}')")
                        deleted_something_for_route = True
                except OSError as e:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –∫–µ—à–∞ (summary –∏ routes)
            cache_key = sanitize_filename(route_name_to_clean) # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ –∂–µ —Å–∞–º–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            route_popped = route_data.routes.pop(cache_key, None)
            summary_popped = route_data.summary.pop(cache_key, None)
            
            if route_popped is not None:
                 print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å –∏–∑ route_data.routes –¥–ª—è '{route_name_to_clean}'")
                 deleted_something_for_route = True
            if summary_popped is not None:
                 print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å –∏–∑ route_data.summary –¥–ª—è '{route_name_to_clean}'")
                 deleted_something_for_route = True
                 
            if deleted_something_for_route:
                routes_cleaned_count += 1

        if routes_cleaned_count > 0:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π route_data...")
            route_data.save_to_disk() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–µ—à–µ (—É–¥–∞–ª–µ–Ω–∏–µ)
        else:
            print("‚ÑπÔ∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—á–∏—Å—Ç–∫–∏.")
            
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ï –∏–º–µ–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ –¢–ï–ö–£–©–ï–ì–û —Ñ–∞–π–ª–∞
        routes_file = os.path.join(DATA_FOLDER, "original_route_names.json")
        with open(routes_file, 'w', encoding='utf-8') as f:
            json.dump({"routes": route_names}, f, ensure_ascii=False, indent=2)
        print(f"üíæ –ê–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {os.path.basename(routes_file)}")
        
        # --- –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ --- 
        all_exceptions = []
        processed_route_names = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤
        parsing_failed_routes = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤, –≥–¥–µ –ø–∞—Ä—Å–∏–Ω–≥ —É–ø–∞–ª
        print("\nüöö –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –º–∞—Ä—à—Ä—É—Ç–æ–≤...")
        
        # --- –®–ê–ì 1: –¢–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥ –∏ —Å–±–æ—Ä –∏—Å–∫–ª—é—á–µ–Ω–∏–π --- 
        for route_name in route_names:
            addresses_with_rows = all_routes_addresses[route_name]
            print(f"\n--- –ü–∞—Ä—Å–∏–Ω–≥ –º–∞—Ä—à—Ä—É—Ç–∞: {route_name} ---")
            
            # 1. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ LLM
            print(f"  üí¨ –ó–∞–ø—É—Å–∫ parsing_route.py...")
            openrouter_key = os.getenv("OPENROUTER_API_KEY", "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")
            if not openrouter_key:
                print("  ‚ùå –û–®–ò–ë–ö–ê: –ö–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω (OPENROUTER_API_KEY).")
                raise ValueError("–ö–ª—é—á OpenRouter API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

            parsing_cmd = [
                 sys.executable, 
                 os.path.abspath(os.path.join(BASE_DIR, "..", "parsing_route.py")),
                 "--excel", save_path,
                 "--openrouter_key", openrouter_key, 
                 "--model", "google/gemini-flash-1.5",
                 "--route", route_name
            ]
            cmd_str = ' '.join(parsing_cmd)
            print(f"  –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É: {cmd_str}")
            parsing_result = subprocess.run(parsing_cmd, capture_output=True, text=True, cwd=ROOT_DIR)
            
            if parsing_result.returncode != 0:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è parsing_route.py –¥–ª—è '{route_name}'")
                print(f"  Stderr:\n{parsing_result.stderr}")
                parsing_failed_routes.append(route_name) # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ –ø–∞—Ä—Å–∏–Ω–≥ —É–ø–∞–ª
                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä –∏—Å–∫–ª—é—á–µ–Ω–∏–π –¥–ª—è —ç—Ç–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
            else:
                print(f"  ‚úÖ parsing_route.py –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
                # --- –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê –ò–°–ö–õ–Æ–ß–ï–ù–ò–ô –ò–ó STDOUT --- 
                lines = parsing_result.stdout.splitlines()
                route_exceptions = [] # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                
                for line in lines:
                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ù–û–í–û–ú–£ —Ñ–æ—Ä–º–∞—Ç—É –≤—ã–≤–æ–¥–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                    match = re.match(r"–ú–∞—Ä—à—Ä—É—Ç\s+'(.*?)',\s+–°—Ç—Ä–æ–∫–∞\s+(\d+):\s*(.*)", line.strip(), re.IGNORECASE)
                    if match:
                        route_nm_parsed = match.group(1).strip()
                        row_num_str = match.group(2)
                        original_address_parsed = match.group(3).strip()
                        
                        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –ø–æ –∫—Ä–∞—è–º –∞–¥—Ä–µ—Å–∞
                        if (original_address_parsed.startswith("'") and original_address_parsed.endswith("'")) or \
                           (original_address_parsed.startswith('"') and original_address_parsed.endswith('"')):
                            original_address_parsed = original_address_parsed[1:-1]
                        
                        try:
                            row_num = int(row_num_str)
                            # –ò—â–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≠–¢–û–ì–û –º–∞—Ä—à—Ä—É—Ç–∞
                            # –í–∞–∂–Ω–æ: route_name –∑–¥–µ—Å—å - —ç—Ç–æ –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∏–∑ —Ç–µ–∫—É—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –≤–Ω–µ—à–Ω–µ–≥–æ —Ü–∏–∫–ª–∞!
                            # –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π addresses_with_rows –¥–ª—è route_nm_parsed
                            current_route_addresses_rows = all_routes_addresses.get(route_nm_parsed)
                            if current_route_addresses_rows:
                                original_address_excel = next((addr for r, addr in current_route_addresses_rows if r == row_num), original_address_parsed)
                            else:
                                original_address_excel = original_address_parsed # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞
                                
                            route_exceptions.append({
                                "row": row_num,
                                "address": original_address_excel,
                                "route": route_nm_parsed, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞
                                "corrected": ""
                            })
                            print(f"    ‚úÖ [–ò–∑ stdout] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: –ú–∞—Ä—à—Ä—É—Ç '{route_nm_parsed}', –°—Ç—Ä–æ–∫–∞ {row_num}, –ê–¥—Ä–µ—Å: '{original_address_excel}'")
                        except ValueError:
                            print(f"    ‚ö†Ô∏è [–ò–∑ stdout] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –≤ –∏—Å–∫–ª—é—á–µ–Ω–∏–∏: {line.strip()}")
                        except Exception as e_inner:
                             print(f"    ‚ö†Ô∏è [–ò–∑ stdout] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è '{line.strip()}': {e_inner}")
                             
                # –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–∏–∑ route_exceptions) –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                all_exceptions.extend(route_exceptions)
                # --- –ö–û–ù–ï–¶ –û–ë–ù–û–í–õ–ï–ù–ù–û–ô –õ–û–ì–ò–ö–ò –ü–ê–†–°–ò–ù–ì–ê --- 

        # --- –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏ —Ä–µ—à–µ–Ω–∏–µ --- 
        if all_exceptions:
            print("\n‚ùóÔ∏è –ù–∞–π–¥–µ–Ω—ã –∞–¥—Ä–µ—Å–∞, —Ç—Ä–µ–±—É—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏. –û—Ç–ø—Ä–∞–≤–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥.")
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –ù–ï –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ/—Ä–∞—Å—á–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            return JSONResponse({
                "status": "needs_correction", 
                "exceptions": all_exceptions,
                "routes": route_names # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –∏–º–µ–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤, —á—Ç–æ–±—ã —Å–µ–ª–µ–∫—Ç–æ—Ä –æ–±–Ω–æ–≤–∏–ª—Å—è
            })
        else:
            print("\n‚úÖ –ê–¥—Ä–µ—Å–∞ –Ω–µ —Ç—Ä–µ–±—É—é—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å—á–µ—Ç...")
            # –ï—Å–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –ù–ï–¢, –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å—á–µ—Ç –¥–ª—è –í–°–ï–• –º–∞—Ä—à—Ä—É—Ç–æ–≤
            # (–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ, –≥–¥–µ —É–ø–∞–ª –ø–∞—Ä—Å–∏–Ω–≥, –µ—Å–ª–∏ —Ç–∞–∫–∏–µ –±—ã–ª–∏)
            for route_name in route_names:
                if route_name in parsing_failed_routes:
                    print(f"  ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è/—Ä–∞—Å—á–µ—Ç–∞ –¥–ª—è '{route_name}', —Ç.–∫. –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è.")
                    continue
                
                print(f"\n--- –ì–µ–æ–∫–æ–¥+–†–∞—Å—á–µ—Ç –¥–ª—è: {route_name} ---")
                process_success = process_route(route_name) 
                if process_success:
                    print(f"  ‚úÖ –ú–∞—Ä—à—Ä—É—Ç '{route_name}' —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
                    processed_route_names.append(route_name)
                else:
                    print(f"  ‚ö†Ô∏è –ú–∞—Ä—à—Ä—É—Ç '{route_name}' –Ω–µ –±—ã–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω (–æ—à–∏–±–∫–∞ –≤ process_route).")
            
            # –û—á–∏—â–∞–µ–º CSV —Å–≤–æ–¥–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã
            if processed_route_names and os.path.exists(summary_csv_path):
                 try:
                     os.remove(summary_csv_path)
                     print(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å–≤–æ–¥–∫–∏: {os.path.basename(summary_csv_path)} (—Ç.–∫. –µ—Å—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)")
                 except OSError as e:
                     print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {summary_csv_path}: {e}")
                     
            print("\nüèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π).")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å processed –∏ —Å–ø–∏—Å–æ–∫ –£–°–ü–ï–®–ù–û –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤
            return JSONResponse({
                "status": "processed", 
                "exceptions": [], # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                "routes": processed_route_names 
            })

    except ValueError as ve:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ (ValueError): {ve}")
        # import traceback # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        # traceback.print_exc()
        return JSONResponse(status_code=400, content={"error": "–û—à–∏–±–∫–∞ –≤ –¥–∞–Ω–Ω—ã—Ö Excel", "details": str(ve)})
    except subprocess.CalledProcessError as cpe:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –ø–æ–¥–ø—Ä–æ—Ü–µ—Å—Å–∞: {cpe}")
        print(f"   Stderr: {cpe.stderr}")
        return JSONResponse(status_code=500, content={"error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä—à—Ä—É—Ç–∞", "details": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–∏–Ω –∏–∑ —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."}) 
    except Exception as e:
        print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        import traceback # –í–∞–∂–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞", "details": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞."}) 

@app.post("/api/submit-corrections")
async def submit_corrections(data: dict = Body(...)):
    corrections = data.get("corrections", [])
    print("üì• –ü–æ–ª—É—á–µ–Ω—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:", corrections)

    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º –ø–æ *–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É* route_name –∏ excel_row
    corrections_map = {}
    original_names_map = {} # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É
    routes_to_process_normalized = set() # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

    for corr in corrections:
        original_route = corr.get("route", "")
        if not original_route:
            continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–µ–∑ –∏–º–µ–Ω–∏ –º–∞—Ä—à—Ä—É—Ç–∞
            
        normalized_route = sanitize_filename(original_route)
        if not normalized_route:
             continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –∏–º—è —Å—Ç–∞–ª–æ –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
             
        routes_to_process_normalized.add(normalized_route)
        original_names_map[normalized_route] = original_route # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è
        
        row_num_str = str(corr["row"])
        if normalized_route not in corrections_map:
            corrections_map[normalized_route] = {}
        corrections_map[normalized_route][row_num_str] = corr["corrected"]

    # --- Loop 1: Modify parsed_addresses_*.csv files --- 
    processed_routes_in_loop1 = set()
    for normalized_route in routes_to_process_normalized:
        original_name = original_names_map[normalized_route]
        parsed_path = os.path.join(PARSED_ADDRESSES_FOLDER, f"parsed_addresses_{normalized_route}.csv")
        
        if not os.path.exists(parsed_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª {parsed_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ '{original_name}' –≤ —Ü–∏–∫–ª–µ 1")
            continue

        try:
            with open(parsed_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                rows = list(reader)
                fieldnames = reader.fieldnames or ["excel_row", "route_name", "normalized_address"]

            # –í–Ω–æ—Å–∏–º –ø—Ä–∞–≤–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞
            route_corrections_for_file = corrections_map.get(normalized_route, {})
            modified = False
            for row in rows:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ CSV –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                row_original_name = row.get('route_name')
                if sanitize_filename(row_original_name) == normalized_route:
                    row_num_str = row.get("excel_row")
                    if row_num_str in route_corrections_for_file:
                        corrected_address = route_corrections_for_file[row_num_str]
                        if row.get('normalized_address') != corrected_address:
                             print(f"‚úèÔ∏è [–§–∞–π–ª {original_name}] –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É {row_num_str}: '{row.get('normalized_address')}' -> '{corrected_address}'")
                             row['normalized_address'] = corrected_address
                             modified = True
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            if modified:
                with open(parsed_path, "w", encoding="utf-8", newline="") as f:
                      writer = csv.DictWriter(f, fieldnames=fieldnames)
                      writer.writeheader()
                      writer.writerows(rows)
                      print(f"üíæ –§–∞–π–ª {parsed_path} –æ–±–Ω–æ–≤–ª–µ–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏.")
                 
            processed_routes_in_loop1.add(normalized_route) # –û—Ç–º–µ—á–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {parsed_path}: {e}")

    # --- Loop 2: Geocode and Calculate Distance FOR ALL ROUTES --- 
    print("\n--- –ó–∞–ø—É—Å–∫ –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –í–°–ï–• –º–∞—Ä—à—Ä—É—Ç–æ–≤ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π ---")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ü–û–õ–ù–´–ô —Å–ø–∏—Å–æ–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞
    try:
        with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
            original_names_data = json.load(f)
            all_original_route_names = original_names_data.get("routes", [])
            print(f"  –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –º–∞—Ä—à—Ä—É—Ç—ã: {', '.join(all_original_route_names)}")
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ original_route_names.json: {e}")
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å, –ø—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ö–æ—Ç—è –±—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
        all_original_route_names = [original_names_map[norm_name] for norm_name in routes_to_process_normalized if norm_name in original_names_map]
        print(f"  ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤: {', '.join(all_original_route_names)}")
        if not all_original_route_names:
             return JSONResponse(status_code=500, content={"error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏", "details": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π."}) 

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –í–°–ï –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    for original_name in all_original_route_names:
        normalized_route = sanitize_filename(original_name)
        if not normalized_route: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –∏–º—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

        parsed_path = os.path.join(PARSED_ADDRESSES_FOLDER, f"parsed_addresses_{normalized_route}.csv")
        geocoded_path = os.path.join(GEOCODED_RESULTS_FOLDER, f"geocoded_results_{normalized_route}.csv")

        if not os.path.exists(parsed_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª {os.path.basename(parsed_path)} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ '{original_name}' –≤ —Ü–∏–∫–ª–µ 2. –ü—Ä–æ–ø—É—Å–∫.")
            continue
        
        # –í—ã–∑—ã–≤–∞–µ–º process_route, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∏ –≥–µ–æ–∫–æ–¥, –∏ —Ä–∞—Å—á–µ—Ç, –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ route_data
        print(f"\n--- –û–±—Ä–∞–±–æ—Ç–∫–∞ (process_route): {original_name} ---")
        try:
            process_success = process_route(original_name)
            if process_success:
                 print(f"‚úÖ –ú–∞—Ä—à—Ä—É—Ç '{original_name}' —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —á–µ—Ä–µ–∑ process_route.")
            else:
                 print(f"‚ö†Ô∏è –ú–∞—Ä—à—Ä—É—Ç '{original_name}' –Ω–µ –±—ã–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω —á–µ—Ä–µ–∑ process_route.")
        except Exception as e_proc:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ process_route –¥–ª—è '{original_name}': {e_proc}")
            # import traceback # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏
            # traceback.print_exc()

    # –ü–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞)
    try:
        routes_response = get_routes() # get_routes —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
        routes_list = routes_response.get("routes", [])
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤: {str(e)}")
        routes_list = []
        
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å –æ–± —É—Å–ø–µ—à–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
    return JSONResponse(status_code=200, content={"status": "saved", "routes": routes_list})

@app.post("/api/summary/update")
async def update_summary_endpoint(data: dict = Body(...)):
    original_route_name = data.get("route_name")
    report_distance = data.get("report_distance")
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç—á–µ—Ç–∞
    report_hours = data.get("report_duration_hours")
    report_minutes = data.get("report_duration_minutes")

    # !!! –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ service_time_per_stop_minutes –ù–ï –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –∏ –ù–ï –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ update_summary_item !!!
    # –≠—Ç–æ –ø–æ–ª–µ —Ç–µ–ø–µ—Ä—å –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ /api/upload

    # <<< –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö >>>
    print(f"--- Received /api/summary/update for: {original_route_name}")
    print(f"    report_distance: '{report_distance}'")
    print(f"    report_duration_hours: '{report_hours}'")
    print(f"    report_duration_minutes: '{report_minutes}'")
    # <<< –ö–æ–Ω–µ—Ü –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è >>>

    if not original_route_name:
        raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –∏–º—è –º–∞—Ä—à—Ä—É—Ç–∞")

    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ route_data, –≤—ã–∑—ã–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—é –¢–û–õ–¨–ö–û —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç—á–µ—Ç–∞
    updated = route_data.update_summary_item(
        name=original_route_name,
        report_distance=report_distance,
        report_hours=report_hours,
        report_minutes=report_minutes
        # service_time_per_stop_minutes –ù–ï –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è
    )

    if updated:
        # CSV –ø–æ–∫–∞ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –ø–æ –≤–∞—à–µ–º—É —É–∫–∞–∑–∞–Ω–∏—é
        # csv_path = save_summary_to_csv(route_data.summary)
        # print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {csv_path}")
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è '{original_route_name}' –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ –ø–∞–º—è—Ç–∏.")
    else:
        print(f"‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ '{original_route_name}' –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å.")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ–π —Å–≤–æ–¥–∫–∏
    summary_response = get_summary_endpoint() # –í—ã–∑—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å "ok" –∫ –æ—Ç–≤–µ—Ç—É –æ—Ç get_summary_endpoint
    return {"status": "ok", **summary_response}

# --- –ù–û–í–´–ô ENDPOINT –î–õ–Ø –≠–ö–°–ü–û–†–¢–ê –°–í–û–î–ö–ò --- 
@app.post("/api/export-summary")
async def export_summary_endpoint():
    print("-- Export summary requested --")
    global route_data # <<< –ò–°–ü–†–ê–í–õ–ï–ù–û: route_data –≤–º–µ—Å—Ç–æ route_processor
    if not route_data or not route_data.summary: # <<< –ò–°–ü–†–ê–í–õ–ï–ù–û
        print("   No summary data found for export.")
        raise HTTPException(status_code=404, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏.")

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ get_summary() —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ route_data
        summary_data = route_data.get_summary() # <<< –ò–ó–ú–ï–ù–ï–ù–û –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –ò–°–ü–†–ê–í–õ–ï–ù–û
        print(f"   Got {len(summary_data)} items for summary export.")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ get_summary() –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ (–æ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å)
        if not summary_data: 
             print("   get_summary() returned empty data.")
             raise HTTPException(status_code=404, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏ (–º–µ—Ç–æ–¥ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ).")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è DataFrame
        summary_values_list = list(summary_data.values())
        if not summary_values_list:
            print("   Summary dictionary is empty after getting values.")
            raise HTTPException(status_code=404, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–≤–æ–¥–∫–∏ (—Å–ª–æ–≤–∞—Ä—å –ø—É—Å—Ç).")

        # 1. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤ DataFrame
        df = pd.DataFrame(summary_values_list)

        # --- –°–û–†–¢–ò–†–û–í–ö–ê DataFrame –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É –º–∞—Ä—à—Ä—É—Ç–æ–≤ --- 
        original_route_order = []
        try:
            with open(os.path.join(DATA_FOLDER, "original_route_names.json"), 'r', encoding='utf-8') as f:
                original_names_data = json.load(f)
                original_route_order = original_names_data.get("routes", [])
            
            if original_route_order and 'original_name' in df.columns:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É original_name –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø —Å –Ω—É–∂–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º
                df['original_name'] = pd.Categorical(df['original_name'], categories=original_route_order, ordered=True)
                df = df.sort_values('original_name')
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
                df = df.reset_index(drop=True)
                print(f"   DataFrame –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É: {original_route_order}")
            else:
                print("   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DataFrame –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É (—Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç –∏–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ original_name).")
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏/—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ –ø–æ original_route_names.json: {e}")
        # --- –ö–û–ù–ï–¶ –°–û–†–¢–ò–†–û–í–ö–ò --- 

        # --- –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –í–†–ï–ú–ï–ù–ò –û–¢–ß–ï–¢–ê --- 
        def format_report_time(row):
            hours = row.get('report_duration_hours')
            minutes = row.get('report_duration_minutes')
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN/None –∫–∞–∫ 0, –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ None
            has_hours = hours is not None and pd.notna(hours)
            has_minutes = minutes is not None and pd.notna(minutes)
            
            if not has_hours and not has_minutes:
                return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, –µ—Å–ª–∏ –æ–±–∞ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
                
            h = int(hours) if has_hours else 0
            m = int(minutes) if has_minutes else 0
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, —Ö–æ—Ç—è –Ω–∞ –±—ç–∫–µ —É–∂–µ –µ—Å—Ç—å)
            if h < 0: h = 0
            if m < 0: m = 0
            if m >= 60: m = 59 
            
            return f"{h} —á {m} –º–∏–Ω"

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏
        if 'report_duration_hours' in df.columns and 'report_duration_minutes' in df.columns:
            df['report_duration_formatted'] = df.apply(format_report_time, axis=1)
            print("   Column 'report_duration_formatted' created.")
        else:
             print("   Warning: Columns 'report_duration_hours' or 'report_duration_minutes' not found in df. Skipping report time formatting.")
             df['report_duration_formatted'] = None # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ –Ω–∏–∂–µ
        # --- –ö–û–ù–ï–¶ –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø --- 

        # --- –í—ã–±–∏—Ä–∞–µ–º –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ --- 
        columns_to_export = {
            "original_name": "–ú–∞—Ä—à—Ä—É—Ç",
            "driver_name": "–§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è",
            "distance": "–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º)",
            "total_route_time_formatted": "–í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ",
            "report_distance": "–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç—á–µ—Ç)",
            "report_duration_formatted": "–í—Ä–µ–º—è (–æ—Ç—á–µ—Ç)", # <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É
            # "report_duration_hours": "–í—Ä–µ–º—è (–æ—Ç—á–µ—Ç) –ß–∞—Å—ã", # <-- –£–¥–∞–ª–µ–Ω–æ
            # "report_duration_minutes": "–í—Ä–µ–º—è (–æ—Ç—á–µ—Ç) –ú–∏–Ω—É—Ç—ã", # <-- –£–¥–∞–ª–µ–Ω–æ
            "distance_difference": "–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)",
            "time_difference_formatted": "–†–∞–∑–Ω–∏—Ü–∞ (–≤—Ä–µ–º—è)",
            "number_of_stops": "–ö–æ–ª-–≤–æ —Ç–æ—á–µ–∫"
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –ø–µ—Ä–µ–¥ —ç–∫—Å–ø–æ—Ä—Ç–æ–º
        export_df = pd.DataFrame()
        ordered_columns = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        for original_col, new_name in columns_to_export.items():
            ordered_columns.append(new_name) # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –∫–∞–∫ –æ–Ω–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ
            if original_col in df.columns:
                export_df[new_name] = df[original_col]
            else:
                print(f"   Warning: Column '{original_col}' not found in summary data for export.")
                export_df[new_name] = None # –ò–ª–∏ pd.NA –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ DataFrame
        export_df = export_df[ordered_columns]

        # --- –û—á–∏—Å—Ç–∫–∞ —è—á–µ–µ–∫ —Ä–∞–∑–Ω–∏—Ü—ã, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞ --- 
        # –ó–∞–º–µ–Ω—è–µ–º NaN –∏ None –Ω–∞ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ pd.isna()
        # –ù—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å SettingWithCopyWarning
        export_df_copy = export_df.copy()

        # –î–ª—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        export_df_copy.loc[pd.isna(export_df_copy['–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç—á–µ—Ç)']), '–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)'] = None

        # –î–ª—è –≤—Ä–µ–º–µ–Ω–∏ (–ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ df)
        report_time_is_empty_in_source = pd.isna(df['report_duration_hours']) & pd.isna(df['report_duration_minutes'])
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –∫ export_df_copy, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω–¥–µ–∫—Å—ã –∏–∑ df
        export_df_copy.loc[report_time_is_empty_in_source, '–†–∞–∑–Ω–∏—Ü–∞ (–≤—Ä–µ–º—è)'] = None
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–Ω—É—é –∫–æ–ø–∏—é –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        export_df = export_df_copy 
        # --- –ö–æ–Ω–µ—Ü –æ—á–∏—Å—Ç–∫–∏ --- 

        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        # export_df['–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)'] = export_df['–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)'].apply(lambda x: f"{'+' if x>0 else ''}{x:.2f}" if pd.notna(x) else '')
        
        print(f"   DataFrame prepared for export with columns: {list(export_df.columns)}")

        # 2. –°–æ–∑–¥–∞–µ–º Excel –≤ –ø–∞–º—è—Ç–∏
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            export_df.to_excel(writer, index=False, sheet_name='–°–≤–æ–¥–∫–∞')
            
            # --- –£–°–õ–û–í–ù–û–ï –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –°–¢–†–û–ö --- 
            workbook = writer.book
            worksheet = writer.sheets['–°–≤–æ–¥–∫–∞']
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∏–ª—å –∑–∞–ª–∏–≤–∫–∏ (—Å–≤–µ—Ç–ª–æ-–∫—Ä–∞—Å–Ω—ã–π)
            light_red_fill = PatternFill(start_color='FFFFCCCC',
                                       end_color='FFFFCCCC',
                                       fill_type='solid')
                                       
            # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –ø–æ—Ä–æ–≥–æ–≤
            DISTANCE_THRESHOLD = -40
            TIME_THRESHOLD_SECONDS = -5400 # -1 —á–∞—Å 30 –º–∏–Ω—É—Ç
            
            # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ —Å—Ç—Ä–æ–∫–∞–º –¥–∞–Ω–Ω—ã—Ö –ª–∏—Å—Ç–∞ Excel (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ - row 1)
            for row_idx in range(2, worksheet.max_row + 1):
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ DataFrame df (–∫–æ—Ç–æ—Ä—ã–π –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω)
                df_idx = row_idx - 2
                
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–∑–Ω–∏—Ü—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ df
                    dist_diff_val = df.loc[df_idx, 'distance_difference']
                    time_diff_sec_val = df.loc[df_idx, 'time_difference_seconds']
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏—è
                    highlight_row = False
                    
                    # –£—Å–ª–æ–≤–∏–µ 1: –†–∞–∑–Ω–∏—Ü–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è <= -40 –∫–º
                    if dist_diff_val is not None and pd.notna(dist_diff_val):
                        try:
                            if float(dist_diff_val) <= DISTANCE_THRESHOLD:
                                highlight_row = True
                        except (ValueError, TypeError):
                            pass # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
                            
                    # –£—Å–ª–æ–≤–∏–µ 2: –†–∞–∑–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏ <= -1—á 30–º–∏–Ω (–µ—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —É—Å–ª–æ–≤–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ)
                    if not highlight_row and time_diff_sec_val is not None and pd.notna(time_diff_sec_val):
                         try:
                             if int(time_diff_sec_val) <= TIME_THRESHOLD_SECONDS:
                                 highlight_row = True
                         except (ValueError, TypeError):
                            pass # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è

                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–ª–∏–≤–∫—É –∫–æ –≤—Å–µ–π —Å—Ç—Ä–æ–∫–µ, –µ—Å–ª–∏ —É—Å–ª–æ–≤–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
                    if highlight_row:
                        # print(f"   Highlighting row {row_idx}...") # –õ–æ–≥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                        for col_idx in range(1, worksheet.max_column + 1):
                            cell = worksheet.cell(row=row_idx, column=col_idx)
                            cell.fill = light_red_fill
                            
                except KeyError as ke:
                     print(f"   Warning: Column {ke} not found in original DataFrame df for index {df_idx}. Skipping formatting for row {row_idx}.")
                except IndexError:
                     print(f"   Warning: Index {df_idx} out of bounds for original DataFrame df. Skipping formatting for row {row_idx}.")
            
            print(f"   Conditional formatting applied based on difference thresholds.")
            # --- –ö–û–ù–ï–¶ –£–°–õ–û–í–ù–û–ì–û –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø --- 

            # --- –ù–ê–°–¢–†–û–ô–ö–ê –ì–†–ê–ù–ò–¶ --- 
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∏–ª–∏ –≥—Ä–∞–Ω–∏—Ü
            thin_black_border = Border(left=Side(style='thin', color='FF000000'), 
                                     right=Side(style='thin', color='FF000000'), 
                                     top=Side(style='thin', color='FF000000'), 
                                     bottom=Side(style='thin', color='FF000000'))
            thin_gray_border = Border(left=Side(style='thin', color='FFA9A9A9'),  # <<< –ò–∑–º–µ–Ω–µ–Ω —Ü–≤–µ—Ç –Ω–∞ –±–æ–ª–µ–µ —Ç–µ–º–Ω—ã–π —Å–µ—Ä—ã–π
                                    right=Side(style='thin', color='FFA9A9A9'), 
                                    top=Side(style='thin', color='FFA9A9A9'), 
                                    bottom=Side(style='thin', color='FFA9A9A9'))

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
            for cell in worksheet["1:1"]: # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞
                 cell.border = thin_black_border
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∫ —è—á–µ–π–∫–∞–º –¥–∞–Ω–Ω—ã—Ö
            for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):
                for cell in row:
                    cell.border = thin_gray_border
            print(f"   Borders applied to header and data cells.")
            # --- –ö–û–ù–ï–¶ –ù–ê–°–¢–†–û–ô–ö–ò –ì–†–ê–ù–ò–¶ --- 

            # --- –ù–ê–°–¢–†–û–ô–ö–ê –®–ò–†–ò–ù–´ –ò –ü–ï–†–ï–ù–û–°–ê --- 
            # workbook = writer.book # –£–∂–µ –ø–æ–ª—É—á–µ–Ω–æ –≤—ã—à–µ
            column_widths_px = {
                '–ú–∞—Ä—à—Ä—É—Ç': 380,
                '–§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è': 300, # <--- –ó–ê–î–ê–ù–ê –®–ò–†–ò–ù–ê
                '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º)': 140,
                '–í—Ä–µ–º—è –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–µ': 140,
                '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç—á–µ—Ç)': 140,
                '–í—Ä–µ–º—è (–æ—Ç—á–µ—Ç)': 140, # <-- –î–æ–±–∞–≤–ª–µ–Ω–æ
                '–†–∞–∑–Ω–∏—Ü–∞ (–∫–º)': 120,
                '–†–∞–∑–Ω–∏—Ü–∞ (–≤—Ä–µ–º—è)': 120,
                '–ö–æ–ª-–≤–æ —Ç–æ—á–µ–∫': 120
            }
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —à–∏—Ä–∏–Ω—É
            for i, column_name in enumerate(export_df.columns):
                column_letter = get_column_letter(i + 1) # +1 —Ç.–∫. –Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1
                width_px = column_widths_px.get(column_name, 100) # –®–∏—Ä–∏–Ω–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100px
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –ø–∏–∫—Å–µ–ª–µ–π –≤ —à–∏—Ä–∏–Ω—É Excel
                excel_width = width_px / 9.0 
                worksheet.column_dimensions[column_letter].width = excel_width
                print(f"   Set width for column '{column_name}' ({column_letter}) to {excel_width:.2f}")
                
            # –í–∫–ª—é—á–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫
            wrap_alignment = Alignment(wrap_text=True, vertical='top') # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –≤–µ—Ä—Ö—É
            for row in worksheet.iter_rows():
                for cell in row:
                    cell.alignment = wrap_alignment
            print("   Applied text wrap to all cells.")
            # --- –ö–û–ù–ï–¶ –ù–ê–°–¢–†–û–ô–ö–ò –®–ò–†–ò–ù–´ –ò –ü–ï–†–ï–ù–û–°–ê ---

        buffer.seek(0)
        print("   Excel buffer created.")

        # 3. –ì–æ—Ç–æ–≤–∏–º –∏–º—è —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"summary_export_{timestamp}.xlsx"
        headers = {
            'Content-Disposition': f'attachment; filename="{filename}"'
        }
        
        print(f"   Returning file: {filename}")
        return StreamingResponse(
            buffer,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            headers=headers
        )

    except Exception as e:
        import traceback
        print(f"!!! Error during summary export: {e}")
        print(traceback.format_exc()) # –ü–µ—á–∞—Ç–∞–µ–º –ø–æ–ª–Ω—ã–π traceback –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}")

# --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û ENDPOINT'–ê ---

if __name__ == "__main__":
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)
